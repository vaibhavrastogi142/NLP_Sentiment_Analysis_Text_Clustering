<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />

<title>Neural Network 1</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>



<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.7.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.7.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.7.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff2?v=4.7.0') format('woff2'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.7.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.7.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.7.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.fa-pull-left {
  float: left;
}
.fa-pull-right {
  float: right;
}
.fa.fa-pull-left {
  margin-right: .3em;
}
.fa.fa-pull-right {
  margin-left: .3em;
}
/* Deprecated as of 4.4.0 */
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
.fa-pulse {
  -webkit-animation: fa-spin 1s infinite steps(8);
  animation: fa-spin 1s infinite steps(8);
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=1)";
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2)";
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=3)";
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1)";
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1)";
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook-f:before,
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-feed:before,
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before,
.fa-gratipay:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper-pp:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-resistance:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-y-combinator-square:before,
.fa-yc-square:before,
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
.fa-buysellads:before {
  content: "\f20d";
}
.fa-connectdevelop:before {
  content: "\f20e";
}
.fa-dashcube:before {
  content: "\f210";
}
.fa-forumbee:before {
  content: "\f211";
}
.fa-leanpub:before {
  content: "\f212";
}
.fa-sellsy:before {
  content: "\f213";
}
.fa-shirtsinbulk:before {
  content: "\f214";
}
.fa-simplybuilt:before {
  content: "\f215";
}
.fa-skyatlas:before {
  content: "\f216";
}
.fa-cart-plus:before {
  content: "\f217";
}
.fa-cart-arrow-down:before {
  content: "\f218";
}
.fa-diamond:before {
  content: "\f219";
}
.fa-ship:before {
  content: "\f21a";
}
.fa-user-secret:before {
  content: "\f21b";
}
.fa-motorcycle:before {
  content: "\f21c";
}
.fa-street-view:before {
  content: "\f21d";
}
.fa-heartbeat:before {
  content: "\f21e";
}
.fa-venus:before {
  content: "\f221";
}
.fa-mars:before {
  content: "\f222";
}
.fa-mercury:before {
  content: "\f223";
}
.fa-intersex:before,
.fa-transgender:before {
  content: "\f224";
}
.fa-transgender-alt:before {
  content: "\f225";
}
.fa-venus-double:before {
  content: "\f226";
}
.fa-mars-double:before {
  content: "\f227";
}
.fa-venus-mars:before {
  content: "\f228";
}
.fa-mars-stroke:before {
  content: "\f229";
}
.fa-mars-stroke-v:before {
  content: "\f22a";
}
.fa-mars-stroke-h:before {
  content: "\f22b";
}
.fa-neuter:before {
  content: "\f22c";
}
.fa-genderless:before {
  content: "\f22d";
}
.fa-facebook-official:before {
  content: "\f230";
}
.fa-pinterest-p:before {
  content: "\f231";
}
.fa-whatsapp:before {
  content: "\f232";
}
.fa-server:before {
  content: "\f233";
}
.fa-user-plus:before {
  content: "\f234";
}
.fa-user-times:before {
  content: "\f235";
}
.fa-hotel:before,
.fa-bed:before {
  content: "\f236";
}
.fa-viacoin:before {
  content: "\f237";
}
.fa-train:before {
  content: "\f238";
}
.fa-subway:before {
  content: "\f239";
}
.fa-medium:before {
  content: "\f23a";
}
.fa-yc:before,
.fa-y-combinator:before {
  content: "\f23b";
}
.fa-optin-monster:before {
  content: "\f23c";
}
.fa-opencart:before {
  content: "\f23d";
}
.fa-expeditedssl:before {
  content: "\f23e";
}
.fa-battery-4:before,
.fa-battery:before,
.fa-battery-full:before {
  content: "\f240";
}
.fa-battery-3:before,
.fa-battery-three-quarters:before {
  content: "\f241";
}
.fa-battery-2:before,
.fa-battery-half:before {
  content: "\f242";
}
.fa-battery-1:before,
.fa-battery-quarter:before {
  content: "\f243";
}
.fa-battery-0:before,
.fa-battery-empty:before {
  content: "\f244";
}
.fa-mouse-pointer:before {
  content: "\f245";
}
.fa-i-cursor:before {
  content: "\f246";
}
.fa-object-group:before {
  content: "\f247";
}
.fa-object-ungroup:before {
  content: "\f248";
}
.fa-sticky-note:before {
  content: "\f249";
}
.fa-sticky-note-o:before {
  content: "\f24a";
}
.fa-cc-jcb:before {
  content: "\f24b";
}
.fa-cc-diners-club:before {
  content: "\f24c";
}
.fa-clone:before {
  content: "\f24d";
}
.fa-balance-scale:before {
  content: "\f24e";
}
.fa-hourglass-o:before {
  content: "\f250";
}
.fa-hourglass-1:before,
.fa-hourglass-start:before {
  content: "\f251";
}
.fa-hourglass-2:before,
.fa-hourglass-half:before {
  content: "\f252";
}
.fa-hourglass-3:before,
.fa-hourglass-end:before {
  content: "\f253";
}
.fa-hourglass:before {
  content: "\f254";
}
.fa-hand-grab-o:before,
.fa-hand-rock-o:before {
  content: "\f255";
}
.fa-hand-stop-o:before,
.fa-hand-paper-o:before {
  content: "\f256";
}
.fa-hand-scissors-o:before {
  content: "\f257";
}
.fa-hand-lizard-o:before {
  content: "\f258";
}
.fa-hand-spock-o:before {
  content: "\f259";
}
.fa-hand-pointer-o:before {
  content: "\f25a";
}
.fa-hand-peace-o:before {
  content: "\f25b";
}
.fa-trademark:before {
  content: "\f25c";
}
.fa-registered:before {
  content: "\f25d";
}
.fa-creative-commons:before {
  content: "\f25e";
}
.fa-gg:before {
  content: "\f260";
}
.fa-gg-circle:before {
  content: "\f261";
}
.fa-tripadvisor:before {
  content: "\f262";
}
.fa-odnoklassniki:before {
  content: "\f263";
}
.fa-odnoklassniki-square:before {
  content: "\f264";
}
.fa-get-pocket:before {
  content: "\f265";
}
.fa-wikipedia-w:before {
  content: "\f266";
}
.fa-safari:before {
  content: "\f267";
}
.fa-chrome:before {
  content: "\f268";
}
.fa-firefox:before {
  content: "\f269";
}
.fa-opera:before {
  content: "\f26a";
}
.fa-internet-explorer:before {
  content: "\f26b";
}
.fa-tv:before,
.fa-television:before {
  content: "\f26c";
}
.fa-contao:before {
  content: "\f26d";
}
.fa-500px:before {
  content: "\f26e";
}
.fa-amazon:before {
  content: "\f270";
}
.fa-calendar-plus-o:before {
  content: "\f271";
}
.fa-calendar-minus-o:before {
  content: "\f272";
}
.fa-calendar-times-o:before {
  content: "\f273";
}
.fa-calendar-check-o:before {
  content: "\f274";
}
.fa-industry:before {
  content: "\f275";
}
.fa-map-pin:before {
  content: "\f276";
}
.fa-map-signs:before {
  content: "\f277";
}
.fa-map-o:before {
  content: "\f278";
}
.fa-map:before {
  content: "\f279";
}
.fa-commenting:before {
  content: "\f27a";
}
.fa-commenting-o:before {
  content: "\f27b";
}
.fa-houzz:before {
  content: "\f27c";
}
.fa-vimeo:before {
  content: "\f27d";
}
.fa-black-tie:before {
  content: "\f27e";
}
.fa-fonticons:before {
  content: "\f280";
}
.fa-reddit-alien:before {
  content: "\f281";
}
.fa-edge:before {
  content: "\f282";
}
.fa-credit-card-alt:before {
  content: "\f283";
}
.fa-codiepie:before {
  content: "\f284";
}
.fa-modx:before {
  content: "\f285";
}
.fa-fort-awesome:before {
  content: "\f286";
}
.fa-usb:before {
  content: "\f287";
}
.fa-product-hunt:before {
  content: "\f288";
}
.fa-mixcloud:before {
  content: "\f289";
}
.fa-scribd:before {
  content: "\f28a";
}
.fa-pause-circle:before {
  content: "\f28b";
}
.fa-pause-circle-o:before {
  content: "\f28c";
}
.fa-stop-circle:before {
  content: "\f28d";
}
.fa-stop-circle-o:before {
  content: "\f28e";
}
.fa-shopping-bag:before {
  content: "\f290";
}
.fa-shopping-basket:before {
  content: "\f291";
}
.fa-hashtag:before {
  content: "\f292";
}
.fa-bluetooth:before {
  content: "\f293";
}
.fa-bluetooth-b:before {
  content: "\f294";
}
.fa-percent:before {
  content: "\f295";
}
.fa-gitlab:before {
  content: "\f296";
}
.fa-wpbeginner:before {
  content: "\f297";
}
.fa-wpforms:before {
  content: "\f298";
}
.fa-envira:before {
  content: "\f299";
}
.fa-universal-access:before {
  content: "\f29a";
}
.fa-wheelchair-alt:before {
  content: "\f29b";
}
.fa-question-circle-o:before {
  content: "\f29c";
}
.fa-blind:before {
  content: "\f29d";
}
.fa-audio-description:before {
  content: "\f29e";
}
.fa-volume-control-phone:before {
  content: "\f2a0";
}
.fa-braille:before {
  content: "\f2a1";
}
.fa-assistive-listening-systems:before {
  content: "\f2a2";
}
.fa-asl-interpreting:before,
.fa-american-sign-language-interpreting:before {
  content: "\f2a3";
}
.fa-deafness:before,
.fa-hard-of-hearing:before,
.fa-deaf:before {
  content: "\f2a4";
}
.fa-glide:before {
  content: "\f2a5";
}
.fa-glide-g:before {
  content: "\f2a6";
}
.fa-signing:before,
.fa-sign-language:before {
  content: "\f2a7";
}
.fa-low-vision:before {
  content: "\f2a8";
}
.fa-viadeo:before {
  content: "\f2a9";
}
.fa-viadeo-square:before {
  content: "\f2aa";
}
.fa-snapchat:before {
  content: "\f2ab";
}
.fa-snapchat-ghost:before {
  content: "\f2ac";
}
.fa-snapchat-square:before {
  content: "\f2ad";
}
.fa-pied-piper:before {
  content: "\f2ae";
}
.fa-first-order:before {
  content: "\f2b0";
}
.fa-yoast:before {
  content: "\f2b1";
}
.fa-themeisle:before {
  content: "\f2b2";
}
.fa-google-plus-circle:before,
.fa-google-plus-official:before {
  content: "\f2b3";
}
.fa-fa:before,
.fa-font-awesome:before {
  content: "\f2b4";
}
.fa-handshake-o:before {
  content: "\f2b5";
}
.fa-envelope-open:before {
  content: "\f2b6";
}
.fa-envelope-open-o:before {
  content: "\f2b7";
}
.fa-linode:before {
  content: "\f2b8";
}
.fa-address-book:before {
  content: "\f2b9";
}
.fa-address-book-o:before {
  content: "\f2ba";
}
.fa-vcard:before,
.fa-address-card:before {
  content: "\f2bb";
}
.fa-vcard-o:before,
.fa-address-card-o:before {
  content: "\f2bc";
}
.fa-user-circle:before {
  content: "\f2bd";
}
.fa-user-circle-o:before {
  content: "\f2be";
}
.fa-user-o:before {
  content: "\f2c0";
}
.fa-id-badge:before {
  content: "\f2c1";
}
.fa-drivers-license:before,
.fa-id-card:before {
  content: "\f2c2";
}
.fa-drivers-license-o:before,
.fa-id-card-o:before {
  content: "\f2c3";
}
.fa-quora:before {
  content: "\f2c4";
}
.fa-free-code-camp:before {
  content: "\f2c5";
}
.fa-telegram:before {
  content: "\f2c6";
}
.fa-thermometer-4:before,
.fa-thermometer:before,
.fa-thermometer-full:before {
  content: "\f2c7";
}
.fa-thermometer-3:before,
.fa-thermometer-three-quarters:before {
  content: "\f2c8";
}
.fa-thermometer-2:before,
.fa-thermometer-half:before {
  content: "\f2c9";
}
.fa-thermometer-1:before,
.fa-thermometer-quarter:before {
  content: "\f2ca";
}
.fa-thermometer-0:before,
.fa-thermometer-empty:before {
  content: "\f2cb";
}
.fa-shower:before {
  content: "\f2cc";
}
.fa-bathtub:before,
.fa-s15:before,
.fa-bath:before {
  content: "\f2cd";
}
.fa-podcast:before {
  content: "\f2ce";
}
.fa-window-maximize:before {
  content: "\f2d0";
}
.fa-window-minimize:before {
  content: "\f2d1";
}
.fa-window-restore:before {
  content: "\f2d2";
}
.fa-times-rectangle:before,
.fa-window-close:before {
  content: "\f2d3";
}
.fa-times-rectangle-o:before,
.fa-window-close-o:before {
  content: "\f2d4";
}
.fa-bandcamp:before {
  content: "\f2d5";
}
.fa-grav:before {
  content: "\f2d6";
}
.fa-etsy:before {
  content: "\f2d7";
}
.fa-imdb:before {
  content: "\f2d8";
}
.fa-ravelry:before {
  content: "\f2d9";
}
.fa-eercast:before {
  content: "\f2da";
}
.fa-microchip:before {
  content: "\f2db";
}
.fa-snowflake-o:before {
  content: "\f2dc";
}
.fa-superpowers:before {
  content: "\f2dd";
}
.fa-wpexplorer:before {
  content: "\f2de";
}
.fa-meetup:before {
  content: "\f2e0";
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
div.traceback-wrapper pre.traceback {
  max-height: 600px;
  overflow: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  display: flex;
  flex-direction: row;
  justify-content: space-between;
  padding: 5px;
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
[dir="rtl"] #ipython_notebook {
  margin-right: 10px;
  margin-left: 0;
}
[dir="rtl"] #ipython_notebook.pull-left {
  float: right !important;
  float: right;
}
.flex-spacer {
  flex: 1;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#kernel_logo_widget {
  margin: 0 10px;
}
span#login_widget {
  float: right;
}
[dir="rtl"] span#login_widget {
  float: left;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
.modal-header {
  cursor: move;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
[dir="rtl"] .center-nav form.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] .center-nav .navbar-text {
  float: right;
}
[dir="rtl"] .navbar-inner {
  text-align: right;
}
[dir="rtl"] div.text-left {
  text-align: right;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  position: absolute;
  display: block;
  width: 100%;
  height: 100%;
  overflow: hidden;
  cursor: pointer;
  opacity: 0;
  z-index: 2;
}
.alternate_upload .btn-xs > input.fileinput {
  margin: -1px -5px;
}
.alternate_upload .btn-upload {
  position: relative;
  height: 22px;
}
::-webkit-file-upload-button {
  cursor: pointer;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
ul#tabs {
  margin-bottom: 4px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
[dir="rtl"] ul#tabs.nav-tabs > li {
  float: right;
}
[dir="rtl"] ul#tabs.nav.nav-tabs {
  padding-right: 0;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons .pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .list_toolbar .col-sm-4,
[dir="rtl"] .list_toolbar .col-sm-8 {
  float: right;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: text-bottom;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
[dir="rtl"] .list_item > div input {
  margin-right: 0;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_modified {
  margin-right: 7px;
  margin-left: 7px;
}
[dir="rtl"] .item_modified.pull-right {
  float: left !important;
  float: left;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
[dir="rtl"] .item_buttons.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .item_buttons .kernel-name {
  margin-left: 7px;
  float: right;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
.sort_button {
  display: inline-block;
  padding-left: 7px;
}
[dir="rtl"] .sort_button.pull-right {
  float: left !important;
  float: left;
}
#tree-selector {
  padding-right: 0px;
}
#button-select-all {
  min-width: 50px;
}
[dir="rtl"] #button-select-all.btn {
  float: right ;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
  margin-top: 2px;
  height: 16px;
}
[dir="rtl"] #select-all.pull-left {
  float: right !important;
  float: right;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.fa-pull-left {
  margin-right: .3em;
}
.folder_icon:before.fa-pull-right {
  margin-left: .3em;
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.fa-pull-left {
  margin-right: .3em;
}
.file_icon:before.fa-pull-right {
  margin-left: .3em;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
#new-menu .dropdown-header {
  font-size: 10px;
  border-bottom: 1px solid #e5e5e5;
  padding: 0 0 3px;
  margin: -3px 20px 0;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.move-button {
  display: none;
}
.download-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
.CodeMirror-dialog {
  background-color: #fff;
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI escape sequences */
/* The color values are a mix of
   http://www.xcolors.net/dl/baskerville-ivorylight and
   http://www.xcolors.net/dl/euphrasia */
.ansi-black-fg {
  color: #3E424D;
}
.ansi-black-bg {
  background-color: #3E424D;
}
.ansi-black-intense-fg {
  color: #282C36;
}
.ansi-black-intense-bg {
  background-color: #282C36;
}
.ansi-red-fg {
  color: #E75C58;
}
.ansi-red-bg {
  background-color: #E75C58;
}
.ansi-red-intense-fg {
  color: #B22B31;
}
.ansi-red-intense-bg {
  background-color: #B22B31;
}
.ansi-green-fg {
  color: #00A250;
}
.ansi-green-bg {
  background-color: #00A250;
}
.ansi-green-intense-fg {
  color: #007427;
}
.ansi-green-intense-bg {
  background-color: #007427;
}
.ansi-yellow-fg {
  color: #DDB62B;
}
.ansi-yellow-bg {
  background-color: #DDB62B;
}
.ansi-yellow-intense-fg {
  color: #B27D12;
}
.ansi-yellow-intense-bg {
  background-color: #B27D12;
}
.ansi-blue-fg {
  color: #208FFB;
}
.ansi-blue-bg {
  background-color: #208FFB;
}
.ansi-blue-intense-fg {
  color: #0065CA;
}
.ansi-blue-intense-bg {
  background-color: #0065CA;
}
.ansi-magenta-fg {
  color: #D160C4;
}
.ansi-magenta-bg {
  background-color: #D160C4;
}
.ansi-magenta-intense-fg {
  color: #A03196;
}
.ansi-magenta-intense-bg {
  background-color: #A03196;
}
.ansi-cyan-fg {
  color: #60C6C8;
}
.ansi-cyan-bg {
  background-color: #60C6C8;
}
.ansi-cyan-intense-fg {
  color: #258F8F;
}
.ansi-cyan-intense-bg {
  background-color: #258F8F;
}
.ansi-white-fg {
  color: #C5C1B4;
}
.ansi-white-bg {
  background-color: #C5C1B4;
}
.ansi-white-intense-fg {
  color: #A1A6B2;
}
.ansi-white-intense-bg {
  background-color: #A1A6B2;
}
.ansi-default-inverse-fg {
  color: #FFFFFF;
}
.ansi-default-inverse-bg {
  background-color: #000000;
}
.ansi-bold {
  font-weight: bold;
}
.ansi-underline {
  text-decoration: underline;
}
/* The following styles are deprecated an will be removed in a future version */
.ansibold {
  font-weight: bold;
}
.ansi-inverse {
  outline: 0.5px dotted;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  position: relative;
  overflow: visible;
}
div.cell:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: transparent;
}
div.cell.jupyter-soft-selected {
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected,
div.cell.selected.jupyter-soft-selected {
  border-color: #ababab;
}
div.cell.selected:before,
div.cell.selected.jupyter-soft-selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #42A5F5;
}
@media print {
  div.cell.selected,
  div.cell.selected.jupyter-soft-selected {
    border-color: transparent;
  }
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
}
.edit_mode div.cell.selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #66BB6A;
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  /* Note that this should set vertical padding only, since CodeMirror assumes
       that horizontal padding will be set on CodeMirror pre */
  padding: 0.4em 0;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only,
    use .CodeMirror-lines for vertical */
  padding: 0 0.4em;
  border: 0;
  border-radius: 0;
}
.CodeMirror-cursor {
  border-left: 1.4px solid black;
}
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .CodeMirror-cursor {
    border-left: 2px solid black;
  }
}
@media screen and (min-width: 4320px) {
  .CodeMirror-cursor {
    border-left: 4px solid black;
  }
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
div.output_area .mglyph > img {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 1px 0 1px 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul:not(.list-inline),
.rendered_html ol:not(.list-inline) {
  padding-left: 2em;
}
.rendered_html ul {
  list-style: disc;
}
.rendered_html ul ul {
  list-style: square;
  margin-top: 0;
}
.rendered_html ul ul ul {
  list-style: circle;
}
.rendered_html ol {
  list-style: decimal;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin-top: 0;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
  padding: 0px;
  background-color: #fff;
}
.rendered_html code {
  background-color: #eff0f1;
}
.rendered_html p code {
  padding: 1px 5px;
}
.rendered_html pre code {
  background-color: #fff;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  color: #000;
  font-size: 100%;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
.rendered_html .alert {
  margin-bottom: initial;
}
.rendered_html * + .alert {
  margin-top: 1em;
}
[dir="rtl"] .rendered_html p {
  text-align: right;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.rendered .rendered_html tr,
.text_cell.rendered .rendered_html th,
.text_cell.rendered .rendered_html td {
  max-width: none;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.text_cell .dropzone .input_area {
  border: 2px dashed #bababa;
  margin: -1px;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
.jupyter-keybindings {
  padding: 1px;
  line-height: 24px;
  border-bottom: 1px solid gray;
}
.jupyter-keybindings input {
  margin: 0;
  padding: 0;
  border: none;
}
.jupyter-keybindings i {
  padding: 6px;
}
.well code {
  background-color: #ffffff;
  border-color: #ababab;
  border-width: 1px;
  border-style: solid;
  padding: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.tags_button_container {
  width: 100%;
  display: flex;
}
.tag-container {
  display: flex;
  flex-direction: row;
  flex-grow: 1;
  overflow: hidden;
  position: relative;
}
.tag-container > * {
  margin: 0 4px;
}
.remove-tag-btn {
  margin-left: 4px;
}
.tags-input {
  display: flex;
}
.cell-tag:last-child:after {
  content: "";
  position: absolute;
  right: 0;
  width: 40px;
  height: 100%;
  /* Fade to background color of cell toolbar */
  background: linear-gradient(to right, rgba(0, 0, 0, 0), #EEE);
}
.tags-input > * {
  margin-left: 4px;
}
.cell-tag,
.tags-input input,
.tags-input button {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  box-shadow: none;
  width: inherit;
  font-size: inherit;
  height: 22px;
  line-height: 22px;
  padding: 0px 4px;
  display: inline-block;
}
.cell-tag:focus,
.tags-input input:focus,
.tags-input button:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.cell-tag::-moz-placeholder,
.tags-input input::-moz-placeholder,
.tags-input button::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.cell-tag:-ms-input-placeholder,
.tags-input input:-ms-input-placeholder,
.tags-input button:-ms-input-placeholder {
  color: #999;
}
.cell-tag::-webkit-input-placeholder,
.tags-input input::-webkit-input-placeholder,
.tags-input button::-webkit-input-placeholder {
  color: #999;
}
.cell-tag::-ms-expand,
.tags-input input::-ms-expand,
.tags-input button::-ms-expand {
  border: 0;
  background-color: transparent;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
.cell-tag[readonly],
.tags-input input[readonly],
.tags-input button[readonly],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  background-color: #eeeeee;
  opacity: 1;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  cursor: not-allowed;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button {
  height: auto;
}
select.cell-tag,
select.tags-input input,
select.tags-input button {
  height: 30px;
  line-height: 30px;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button,
select[multiple].cell-tag,
select[multiple].tags-input input,
select[multiple].tags-input button {
  height: auto;
}
.cell-tag,
.tags-input button {
  padding: 0px 4px;
}
.cell-tag {
  background-color: #fff;
  white-space: nowrap;
}
.tags-input input[type=text]:focus {
  outline: none;
  box-shadow: none;
  border-color: #ccc;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
[dir="rtl"] #kernel_logo_widget {
  float: left !important;
  float: left;
}
.modal .modal-body .move-path {
  display: flex;
  flex-direction: row;
  justify-content: space;
  align-items: center;
}
.modal .modal-body .move-path .server-root {
  padding-right: 20px;
}
.modal .modal-body .move-path .path-input {
  flex: 1;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
[dir="rtl"] #menubar .navbar-toggle {
  float: right;
}
[dir="rtl"] #menubar .navbar-collapse {
  clear: right;
}
[dir="rtl"] #menubar .navbar-nav {
  float: right;
}
[dir="rtl"] #menubar .nav {
  padding-right: 0px;
}
[dir="rtl"] #menubar .navbar-nav > li {
  float: right;
}
[dir="rtl"] #menubar .navbar-right {
  float: left !important;
}
[dir="rtl"] ul.dropdown-menu {
  text-align: right;
  left: auto;
}
[dir="rtl"] ul#new-menu.dropdown-menu {
  right: auto;
  left: 0;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
[dir="rtl"] i.menu-icon.pull-right {
  float: left !important;
  float: left;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
[dir="rtl"] ul#help_menu li a {
  padding-left: 2.2em;
}
[dir="rtl"] ul#help_menu li a i {
  margin-right: 0;
  margin-left: -1.2em;
}
[dir="rtl"] ul#help_menu li a i.pull-right {
  float: left !important;
  float: left;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
[dir="rtl"] .dropdown-submenu > .dropdown-menu {
  right: 100%;
  margin-right: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.fa-pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.fa-pull-right {
  margin-left: .3em;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
[dir="rtl"] .dropdown-submenu > a:after {
  float: left;
  content: "\f0d9";
  margin-right: 0;
  margin-left: -10px;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
[dir="rtl"] #notification_area {
  float: left !important;
  float: left;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] .indicator_area {
  float: left !important;
  float: left;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
[dir="rtl"] #kernel_indicator {
  float: left !important;
  float: left;
  border-left: 0;
  border-right: 1px solid;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] #modal_indicator {
  float: left !important;
  float: left;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  height: 30px;
  margin-top: 4px;
  display: flex;
  justify-content: flex-start;
  align-items: baseline;
  width: 50%;
  flex: 1;
}
span.save_widget span.filename {
  height: 100%;
  line-height: 1em;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
[dir="rtl"] span.save_widget.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] span.save_widget span.filename {
  margin-left: 0;
  margin-right: 16px;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
  white-space: nowrap;
  padding: 0 5px;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
    padding: 0 0 0 5px;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
.toolbar-btn-label {
  margin-left: 6px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
[dir="rtl"] .btn-group > .btn,
.btn-group-vertical > .btn {
  float: right;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
[dir="rtl"] ul.typeahead-list i {
  margin-left: 0;
  margin-right: -10px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
ul.typeahead-list  > li > a.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .typeahead-list {
  text-align: right;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  min-width: 20px;
  color: transparent;
}
[dir="rtl"] .no-shortcut.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .command-shortcut.pull-right {
  float: left !important;
  float: left;
}
.command-shortcut:before {
  content: "(command mode)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
[dir="rtl"] .edit-shortcut.pull-right {
  float: left !important;
  float: left;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
[dir="ltr"] #find-and-replace .input-group-btn + .form-control {
  border-left: none;
}
[dir="rtl"] #find-and-replace .input-group-btn + .form-control {
  border-right: none;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Data-Preparation">Data Preparation<a class="anchor-link" href="#Data-Preparation">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#loading in the data</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">hotel_reviews</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;Hotel_Reviews_2.csv&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#reading the data</span>
<span class="n">hotel_reviews</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[4]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Hotel_Address</th>
      <th>Additional_Number_of_Scoring</th>
      <th>Review_Date</th>
      <th>Average_Score</th>
      <th>Hotel_Name</th>
      <th>Reviewer_Nationality</th>
      <th>Negative_Review</th>
      <th>neg_count</th>
      <th>Review_Total_Negative_Word_Counts</th>
      <th>Total_Number_of_Reviews</th>
      <th>Positive_Review</th>
      <th>pos_count</th>
      <th>Review_Total_Positive_Word_Counts</th>
      <th>Total_Number_of_Reviews_Reviewer_Has_Given</th>
      <th>Reviewer_Score</th>
      <th>Tags</th>
      <th>days_since_review</th>
      <th>lat</th>
      <th>lng</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>
      <td>194</td>
      <td>08-03-2017</td>
      <td>7.7</td>
      <td>Hotel Arena</td>
      <td>Russia</td>
      <td>i am so angry that i made this post available...</td>
      <td>0</td>
      <td>397</td>
      <td>1403</td>
      <td>only the park outside of the hotel was beauti...</td>
      <td>1</td>
      <td>11</td>
      <td>7</td>
      <td>2.9</td>
      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>
      <td>0 days</td>
      <td>52.360576</td>
      <td>4.915968</td>
    </tr>
    <tr>
      <th>1</th>
      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>
      <td>194</td>
      <td>08-03-2017</td>
      <td>7.7</td>
      <td>Hotel Arena</td>
      <td>Ireland</td>
      <td>no negative</td>
      <td>1</td>
      <td>0</td>
      <td>1403</td>
      <td>no real complaints the hotel was great great ...</td>
      <td>1</td>
      <td>105</td>
      <td>7</td>
      <td>7.5</td>
      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>
      <td>0 days</td>
      <td>52.360576</td>
      <td>4.915968</td>
    </tr>
    <tr>
      <th>2</th>
      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>
      <td>194</td>
      <td>7/31/2017</td>
      <td>7.7</td>
      <td>Hotel Arena</td>
      <td>Australia</td>
      <td>rooms are nice but for elderly a bit difficul...</td>
      <td>0</td>
      <td>42</td>
      <td>1403</td>
      <td>location was good and staff were ok it is cut...</td>
      <td>1</td>
      <td>21</td>
      <td>9</td>
      <td>7.1</td>
      <td>[' Leisure trip ', ' Family with young childre...</td>
      <td>3 days</td>
      <td>52.360576</td>
      <td>4.915968</td>
    </tr>
    <tr>
      <th>3</th>
      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>
      <td>194</td>
      <td>7/31/2017</td>
      <td>7.7</td>
      <td>Hotel Arena</td>
      <td>United Kingdom</td>
      <td>my room was dirty and i was afraid to walk ba...</td>
      <td>0</td>
      <td>210</td>
      <td>1403</td>
      <td>great location in nice surroundings the bar a...</td>
      <td>1</td>
      <td>26</td>
      <td>1</td>
      <td>3.8</td>
      <td>[' Leisure trip ', ' Solo traveler ', ' Duplex...</td>
      <td>3 days</td>
      <td>52.360576</td>
      <td>4.915968</td>
    </tr>
    <tr>
      <th>4</th>
      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>
      <td>194</td>
      <td>7/24/2017</td>
      <td>7.7</td>
      <td>Hotel Arena</td>
      <td>New Zealand</td>
      <td>you when i booked with your company on line y...</td>
      <td>0</td>
      <td>140</td>
      <td>1403</td>
      <td>amazing location and building romantic setting</td>
      <td>1</td>
      <td>8</td>
      <td>3</td>
      <td>6.7</td>
      <td>[' Leisure trip ', ' Couple ', ' Suite ', ' St...</td>
      <td>10 days</td>
      <td>52.360576</td>
      <td>4.915968</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#shape of the information</span>
<span class="n">hotel_reviews</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[5]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(515738, 19)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dfmain</span> <span class="o">=</span> <span class="n">hotel_reviews</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dfmain</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[7]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(515211, 19)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dfmain</span><span class="p">[</span><span class="s1">&#39;neg_word_count&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dfmain</span><span class="p">[</span><span class="s1">&#39;Negative_Review&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\vaibh\Anaconda3x\lib\site-packages\ipykernel_launcher.py:1: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  &#34;&#34;&#34;Entry point for launching an IPython kernel.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pos_reviews</span> <span class="o">=</span> <span class="n">dfmain</span><span class="p">[</span><span class="s1">&#39;Positive_Review&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">pos_reviews</span> <span class="o">=</span> <span class="n">pos_reviews</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">neg_reviews</span> <span class="o">=</span> <span class="n">dfmain</span><span class="p">[</span><span class="s1">&#39;Negative_Review&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">neg_reviews</span> <span class="o">=</span> <span class="n">neg_reviews</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">pos_reviews</span><span class="o">+</span><span class="n">neg_reviews</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dfmain</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[10]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Hotel_Address</th>
      <th>Additional_Number_of_Scoring</th>
      <th>Review_Date</th>
      <th>Average_Score</th>
      <th>Hotel_Name</th>
      <th>Reviewer_Nationality</th>
      <th>Negative_Review</th>
      <th>neg_count</th>
      <th>Review_Total_Negative_Word_Counts</th>
      <th>Total_Number_of_Reviews</th>
      <th>Positive_Review</th>
      <th>pos_count</th>
      <th>Review_Total_Positive_Word_Counts</th>
      <th>Total_Number_of_Reviews_Reviewer_Has_Given</th>
      <th>Reviewer_Score</th>
      <th>Tags</th>
      <th>days_since_review</th>
      <th>lat</th>
      <th>lng</th>
      <th>neg_word_count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>
      <td>194</td>
      <td>08-03-2017</td>
      <td>7.7</td>
      <td>Hotel Arena</td>
      <td>Russia</td>
      <td>i am so angry that i made this post available...</td>
      <td>0</td>
      <td>397</td>
      <td>1403</td>
      <td>only the park outside of the hotel was beauti...</td>
      <td>1</td>
      <td>11</td>
      <td>7</td>
      <td>2.9</td>
      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>
      <td>0 days</td>
      <td>52.360576</td>
      <td>4.915968</td>
      <td>397</td>
    </tr>
    <tr>
      <th>1</th>
      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>
      <td>194</td>
      <td>08-03-2017</td>
      <td>7.7</td>
      <td>Hotel Arena</td>
      <td>Ireland</td>
      <td>no negative</td>
      <td>1</td>
      <td>0</td>
      <td>1403</td>
      <td>no real complaints the hotel was great great ...</td>
      <td>1</td>
      <td>105</td>
      <td>7</td>
      <td>7.5</td>
      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>
      <td>0 days</td>
      <td>52.360576</td>
      <td>4.915968</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>
      <td>194</td>
      <td>7/31/2017</td>
      <td>7.7</td>
      <td>Hotel Arena</td>
      <td>Australia</td>
      <td>rooms are nice but for elderly a bit difficul...</td>
      <td>0</td>
      <td>42</td>
      <td>1403</td>
      <td>location was good and staff were ok it is cut...</td>
      <td>1</td>
      <td>21</td>
      <td>9</td>
      <td>7.1</td>
      <td>[' Leisure trip ', ' Family with young childre...</td>
      <td>3 days</td>
      <td>52.360576</td>
      <td>4.915968</td>
      <td>42</td>
    </tr>
    <tr>
      <th>3</th>
      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>
      <td>194</td>
      <td>7/31/2017</td>
      <td>7.7</td>
      <td>Hotel Arena</td>
      <td>United Kingdom</td>
      <td>my room was dirty and i was afraid to walk ba...</td>
      <td>0</td>
      <td>210</td>
      <td>1403</td>
      <td>great location in nice surroundings the bar a...</td>
      <td>1</td>
      <td>26</td>
      <td>1</td>
      <td>3.8</td>
      <td>[' Leisure trip ', ' Solo traveler ', ' Duplex...</td>
      <td>3 days</td>
      <td>52.360576</td>
      <td>4.915968</td>
      <td>210</td>
    </tr>
    <tr>
      <th>4</th>
      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>
      <td>194</td>
      <td>7/24/2017</td>
      <td>7.7</td>
      <td>Hotel Arena</td>
      <td>New Zealand</td>
      <td>you when i booked with your company on line y...</td>
      <td>0</td>
      <td>140</td>
      <td>1403</td>
      <td>amazing location and building romantic setting</td>
      <td>1</td>
      <td>8</td>
      <td>3</td>
      <td>6.7</td>
      <td>[' Leisure trip ', ' Couple ', ' Suite ', ' St...</td>
      <td>10 days</td>
      <td>52.360576</td>
      <td>4.915968</td>
      <td>140</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pos_reviews</span> <span class="o">=</span> <span class="n">dfmain</span><span class="p">[</span><span class="s1">&#39;Positive_Review&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">pos_reviews</span> <span class="o">=</span> <span class="n">pos_reviews</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">neg_reviews</span> <span class="o">=</span> <span class="n">dfmain</span><span class="p">[</span><span class="s1">&#39;Negative_Review&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">neg_reviews</span> <span class="o">=</span> <span class="n">neg_reviews</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">reviews</span> <span class="o">=</span> <span class="n">pos_reviews</span><span class="o">+</span><span class="n">neg_reviews</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pos_count</span> <span class="o">=</span> <span class="n">dfmain</span><span class="p">[</span><span class="s1">&#39;pos_count&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">pos_count</span> <span class="o">=</span> <span class="n">pos_count</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">neg_count</span> <span class="o">=</span> <span class="n">dfmain</span><span class="p">[</span><span class="s1">&#39;neg_count&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">neg_count</span> <span class="o">=</span> <span class="n">neg_count</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">pos_count</span><span class="o">+</span><span class="n">neg_count</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As you can see, common words like "the" appear very often in both positive and negative reviews. Instead of finding the most common words in positive or negative reviews, what you really want are the words found in positive reviews more often than in negative reviews, and vice versa. To accomplish this, you'll need to calculate the ratios of word usage between positive and negative reviews.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">reviews</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[13]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>1030422</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">reviews</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[14]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39; only the park outside of the hotel was beautiful &#39;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">labels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[15]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>1</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">reviews</span><span class="p">[</span><span class="mi">904633</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[16]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39; only whole milk no skimmed or semi skilled called said they would send some up and then got whole again phoned back and said they gone none not good enough for 125 i had to go out and buy a cup of tea also no biscuts and bit rude &#39;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">labels</span><span class="p">[</span><span class="mi">904633</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[17]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">positive_counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
<span class="n">negative_counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
<span class="n">total_counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">reviews</span><span class="p">)):</span>
    <span class="k">if</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">reviews</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
            <span class="n">positive_counts</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">total_counts</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">reviews</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
            <span class="n">negative_counts</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">total_counts</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">positive_counts</span><span class="o">.</span><span class="n">most_common</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[10]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[(&#39;&#39;, 762862),
 (&#39;the&#39;, 515074),
 (&#39;and&#39;, 420251),
 (&#39;was&#39;, 236631),
 (&#39;staff&#39;, 194368),
 (&#39;location&#39;, 192638),
 (&#39;very&#39;, 192545),
 (&#39;to&#39;, 187863),
 (&#39;a&#39;, 164900),
 (&#39;room&#39;, 140704),
 (&#39;no&#39;, 137001),
 (&#39;negative&#39;, 127995),
 (&#39;hotel&#39;, 125183),
 (&#39;in&#39;, 113924),
 (&#39;good&#39;, 112205),
 (&#39;of&#39;, 106712),
 (&#39;great&#39;, 105533),
 (&#39;is&#39;, 102362),
 (&#39;for&#39;, 91019),
 (&#39;were&#39;, 90800),
 (&#39;friendly&#39;, 85270),
 (&#39;breakfast&#39;, 84572),
 (&#39;helpful&#39;, 76100),
 (&#39;nice&#39;, 69375),
 (&#39;we&#39;, 68842),
 (&#39;clean&#39;, 66860),
 (&#39;with&#39;, 65874),
 (&#39;excellent&#39;, 62222),
 (&#39;i&#39;, 61207),
 (&#39;comfortable&#39;, 59907),
 (&#39;it&#39;, 57593),
 (&#39;bed&#39;, 49874),
 (&#39;from&#39;, 43774),
 (&#39;rooms&#39;, 40338),
 (&#39;at&#39;, 37021),
 (&#39;on&#39;, 35523),
 (&#39;lovely&#39;, 35070),
 (&#39;all&#39;, 34533),
 (&#39;you&#39;, 32488),
 (&#39;are&#39;, 32374),
 (&#39;stay&#39;, 32021),
 (&#39;but&#39;, 31915),
 (&#39;our&#39;, 31684),
 (&#39;close&#39;, 30942),
 (&#39;station&#39;, 29270),
 (&#39;really&#39;, 28206),
 (&#39;had&#39;, 28058),
 (&#39;so&#39;, 27679),
 (&#39;this&#39;, 27628),
 (&#39;everything&#39;, 27140),
 (&#39;as&#39;, 27122),
 (&#39;perfect&#39;, 25974),
 (&#39;service&#39;, 25811),
 (&#39;well&#39;, 23751),
 (&#39;not&#39;, 23381),
 (&#39;my&#39;, 23174),
 (&#39;quiet&#39;, 21888),
 (&#39;nothing&#39;, 21822),
 (&#39;amazing&#39;, 21637),
 (&#39;comfy&#39;, 21341),
 (&#39;there&#39;, 20879),
 (&#39;walk&#39;, 20449),
 (&#39;that&#39;, 20316),
 (&#39;have&#39;, 20117),
 (&#39;bar&#39;, 19579),
 (&#39;they&#39;, 18872),
 (&#39;us&#39;, 18516),
 (&#39;would&#39;, 18173),
 (&#39;also&#39;, 17678),
 (&#39;which&#39;, 17622),
 (&#39;bathroom&#39;, 17410),
 (&#39;t&#39;, 17321),
 (&#39;view&#39;, 17241),
 (&#39;modern&#39;, 16876),
 (&#39;london&#39;, 16664),
 (&#39;just&#39;, 16580),
 (&#39;s&#39;, 16360),
 (&#39;food&#39;, 16350),
 (&#39;metro&#39;, 16035),
 (&#39;fantastic&#39;, 15980),
 (&#39;an&#39;, 15913),
 (&#39;reception&#39;, 15885),
 (&#39;free&#39;, 15830),
 (&#39;area&#39;, 15805),
 (&#39;facilities&#39;, 15622),
 (&#39;spacious&#39;, 15457),
 (&#39;city&#39;, 15282),
 (&#39;out&#39;, 15094),
 (&#39;be&#39;, 14914),
 (&#39;easy&#39;, 14768),
 (&#39;beds&#39;, 14685),
 (&#39;again&#39;, 14212),
 (&#39;beautiful&#39;, 14087),
 (&#39;central&#39;, 13589),
 (&#39;restaurant&#39;, 13303),
 (&#39;near&#39;, 13133),
 (&#39;by&#39;, 13003),
 (&#39;restaurants&#39;, 12804),
 (&#39;loved&#39;, 12756),
 (&#39;shower&#39;, 12727),
 (&#39;big&#39;, 12070),
 (&#39;one&#39;, 11666),
 (&#39;small&#39;, 11665),
 (&#39;will&#39;, 11547),
 (&#39;tube&#39;, 11490),
 (&#39;walking&#39;, 11463),
 (&#39;like&#39;, 11398),
 (&#39;extremely&#39;, 11282),
 (&#39;value&#39;, 11197),
 (&#39;best&#39;, 11175),
 (&#39;too&#39;, 10867),
 (&#39;check&#39;, 10817),
 (&#39;place&#39;, 10812),
 (&#39;if&#39;, 10641),
 (&#39;when&#39;, 10324),
 (&#39;size&#39;, 10257),
 (&#39;definitely&#39;, 9969),
 (&#39;only&#39;, 9919),
 (&#39;time&#39;, 9845),
 (&#39;next&#39;, 9815),
 (&#39;get&#39;, 9745),
 (&#39;large&#39;, 9690),
 (&#39;wonderful&#39;, 9666),
 (&#39;coffee&#39;, 9595),
 (&#39;can&#39;, 9389),
 (&#39;distance&#39;, 9377),
 (&#39;could&#39;, 9371),
 (&#39;convenient&#39;, 9319),
 (&#39;super&#39;, 9299),
 (&#39;day&#39;, 9159),
 (&#39;night&#39;, 9127),
 (&#39;minutes&#39;, 9067),
 (&#39;back&#39;, 8968),
 (&#39;about&#39;, 8870),
 (&#39;right&#39;, 8815),
 (&#39;price&#39;, 8718),
 (&#39;train&#39;, 8687),
 (&#39;stayed&#39;, 8578),
 (&#39;recommend&#39;, 8514),
 (&#39;street&#39;, 8473),
 (&#39;made&#39;, 8457),
 (&#39;money&#39;, 8405),
 (&#39;pleasant&#39;, 8387),
 (&#39;around&#39;, 8308),
 (&#39;more&#39;, 8296),
 (&#39;pool&#39;, 8241),
 (&#39;here&#39;, 7988),
 (&#39;me&#39;, 7946),
 (&#39;even&#39;, 7931),
 (&#39;away&#39;, 7888),
 (&#39;much&#39;, 7866),
 (&#39;located&#39;, 7865),
 (&#39;centre&#39;, 7849),
 (&#39;or&#39;, 7819),
 (&#39;5&#39;, 7769),
 (&#39;welcoming&#39;, 7664),
 (&#39;little&#39;, 7454),
 (&#39;front&#39;, 7449),
 (&#39;access&#39;, 7444),
 (&#39;always&#39;, 7423),
 (&#39;polite&#39;, 7422),
 (&#39;wifi&#39;, 7261),
 (&#39;quality&#39;, 7083),
 (&#39;2&#39;, 7079),
 (&#39;every&#39;, 7068),
 (&#39;decor&#39;, 7057),
 (&#39;quite&#39;, 7038),
 (&#39;choice&#39;, 6976),
 (&#39;liked&#39;, 6865),
 (&#39;park&#39;, 6851),
 (&#39;most&#39;, 6593),
 (&#39;10&#39;, 6472),
 (&#39;has&#39;, 6458),
 (&#39;design&#39;, 6454),
 (&#39;especially&#39;, 6433),
 (&#39;than&#39;, 6393),
 (&#39;floor&#39;, 6384),
 (&#39;after&#39;, 6301),
 (&#39;center&#39;, 6234),
 (&#39;bus&#39;, 6229),
 (&#39;superb&#39;, 6189),
 (&#39;go&#39;, 6175),
 (&#39;many&#39;, 6128),
 (&#39;up&#39;, 6069),
 (&#39;extra&#39;, 6045),
 (&#39;shopping&#39;, 5999),
 (&#39;enough&#39;, 5870),
 (&#39;some&#39;, 5841),
 (&#39;underground&#39;, 5828),
 (&#39;tram&#39;, 5819),
 (&#39;desk&#39;, 5814),
 (&#39;within&#39;, 5769),
 (&#39;kind&#39;, 5706),
 (&#39;new&#39;, 5632),
 (&#39;parking&#39;, 5604),
 (&#39;brilliant&#39;, 5588),
 (&#39;lots&#39;, 5585),
 (&#39;paris&#39;, 5575),
 (&#39;top&#39;, 5569),
 (&#39;professional&#39;, 5546),
 (&#39;feel&#39;, 5517),
 (&#39;views&#39;, 5473),
 (&#39;where&#39;, 5459),
 (&#39;overall&#39;, 5454),
 (&#39;what&#39;, 5430),
 (&#39;attentive&#39;, 5420),
 (&#39;tea&#39;, 5377),
 (&#39;welcome&#39;, 5377),
 (&#39;water&#39;, 5368),
 (&#39;your&#39;, 5351),
 (&#39;help&#39;, 5344),
 (&#39;other&#39;, 5321),
 (&#39;got&#39;, 5269),
 (&#39;cleanliness&#39;, 5220),
 (&#39;minute&#39;, 5177),
 (&#39;who&#39;, 5173),
 (&#39;been&#39;, 5168),
 (&#39;buffet&#39;, 5113),
 (&#39;airport&#39;, 5102),
 (&#39;enjoyed&#39;, 5006),
 (&#39;efficient&#39;, 5000),
 (&#39;upgraded&#39;, 4996),
 (&#39;nearby&#39;, 4991),
 (&#39;short&#39;, 4984),
 (&#39;do&#39;, 4947),
 (&#39;didn&#39;, 4890),
 (&#39;comfort&#39;, 4873),
 (&#39;etc&#39;, 4860),
 (&#39;transport&#39;, 4856),
 (&#39;main&#39;, 4834),
 (&#39;experience&#39;, 4804),
 (&#39;hotels&#39;, 4781),
 (&#39;atmosphere&#39;, 4772),
 (&#39;visit&#39;, 4770),
 (&#39;outside&#39;, 4752),
 (&#39;suite&#39;, 4712),
 (&#39;shops&#39;, 4679),
 (&#39;two&#39;, 4636),
 (&#39;high&#39;, 4632),
 (&#39;few&#39;, 4628),
 (&#39;lobby&#39;, 4609),
 (&#39;warm&#39;, 4598),
 (&#39;way&#39;, 4593),
 (&#39;did&#39;, 4588),
 (&#39;fabulous&#39;, 4585),
 (&#39;first&#39;, 4555),
 (&#39;use&#39;, 4552),
 (&#39;delicious&#39;, 4544),
 (&#39;attractions&#39;, 4493),
 (&#39;birthday&#39;, 4480),
 (&#39;over&#39;, 4463),
 (&#39;fresh&#39;, 4460),
 (&#39;need&#39;, 4432),
 (&#39;their&#39;, 4425),
 (&#39;any&#39;, 4399),
 (&#39;3&#39;, 4368),
 (&#39;arrival&#39;, 4331),
 (&#39;plenty&#39;, 4319),
 (&#39;better&#39;, 4318),
 (&#39;couldn&#39;, 4314),
 (&#39;needed&#39;, 4281),
 (&#39;min&#39;, 4252),
 (&#39;upgrade&#39;, 4249),
 (&#39;special&#39;, 4246),
 (&#39;spa&#39;, 4210),
 (&#39;public&#39;, 4193),
 (&#39;lounge&#39;, 4188),
 (&#39;stop&#39;, 4177),
 (&#39;amsterdam&#39;, 4162),
 (&#39;being&#39;, 4151),
 (&#39;love&#39;, 4127),
 (&#39;building&#39;, 4081),
 (&#39;ever&#39;, 4051),
 (&#39;happy&#39;, 4041),
 (&#39;make&#39;, 4037),
 (&#39;its&#39;, 4031),
 (&#39;bit&#39;, 4029),
 (&#39;tower&#39;, 4025),
 (&#39;old&#39;, 4013),
 (&#39;selection&#39;, 4011),
 (&#39;concierge&#39;, 3988),
 (&#39;people&#39;, 3969),
 (&#39;early&#39;, 3954),
 (&#39;into&#39;, 3925),
 (&#39;complimentary&#39;, 3912),
 (&#39;thank&#39;, 3891),
 (&#39;although&#39;, 3885),
 (&#39;highly&#39;, 3885),
 (&#39;available&#39;, 3879),
 (&#39;went&#39;, 3846),
 (&#39;space&#39;, 3841),
 (&#39;pillows&#39;, 3801),
 (&#39;far&#39;, 3800),
 (&#39;places&#39;, 3795),
 (&#39;door&#39;, 3788),
 (&#39;lot&#39;, 3761),
 (&#39;ok&#39;, 3723),
 (&#39;absolutely&#39;, 3713),
 (&#39;huge&#39;, 3671),
 (&#39;terrace&#39;, 3656),
 (&#39;bath&#39;, 3584),
 (&#39;ideal&#39;, 3579),
 (&#39;hot&#39;, 3520),
 (&#39;decorated&#39;, 3507),
 (&#39;drinks&#39;, 3494),
 (&#39;style&#39;, 3463),
 (&#39;barcelona&#39;, 3459),
 (&#39;accommodating&#39;, 3446),
 (&#39;touch&#39;, 3439),
 (&#39;air&#39;, 3433),
 (&#39;come&#39;, 3429),
 (&#39;standard&#39;, 3409),
 (&#39;though&#39;, 3409),
 (&#39;tv&#39;, 3408),
 (&#39;booked&#39;, 3402),
 (&#39;trip&#39;, 3389),
 (&#39;before&#39;, 3376),
 (&#39;staying&#39;, 3373),
 (&#39;roof&#39;, 3363),
 (&#39;bedroom&#39;, 3362),
 (&#39;morning&#39;, 3350),
 (&#39;across&#39;, 3327),
 (&#39;mins&#39;, 3311),
 (&#39;arrived&#39;, 3299),
 (&#39;find&#39;, 3244),
 (&#39;position&#39;, 3240),
 (&#39;road&#39;, 3224),
 (&#39;see&#39;, 3216),
 (&#39;ve&#39;, 3212),
 (&#39;them&#39;, 3203),
 (&#39;family&#39;, 3189),
 (&#39;4&#39;, 3188),
 (&#39;both&#39;, 3182),
 (&#39;balcony&#39;, 3132),
 (&#39;want&#39;, 3130),
 (&#39;off&#39;, 3113),
 (&#39;bars&#39;, 3099),
 (&#39;gave&#39;, 3093),
 (&#39;return&#39;, 3038),
 (&#39;15&#39;, 3030),
 (&#39;english&#39;, 3005),
 (&#39;stuff&#39;, 3004),
 (&#39;felt&#39;, 2995),
 (&#39;awesome&#39;, 2984),
 (&#39;stations&#39;, 2966),
 (&#39;provided&#39;, 2961),
 (&#39;thing&#39;, 2953),
 (&#39;such&#39;, 2925),
 (&#39;areas&#39;, 2923),
 (&#39;evening&#39;, 2892),
 (&#39;machine&#39;, 2886),
 (&#39;booking&#39;, 2878),
 (&#39;rooftop&#39;, 2839),
 (&#39;safe&#39;, 2817),
 (&#39;stylish&#39;, 2800),
 (&#39;home&#39;, 2800),
 (&#39;sleep&#39;, 2771),
 (&#39;variety&#39;, 2710),
 (&#39;amenities&#39;, 2703),
 (&#39;equipped&#39;, 2699),
 (&#39;cool&#39;, 2693),
 (&#39;late&#39;, 2693),
 (&#39;noise&#39;, 2691),
 (&#39;hyde&#39;, 2690),
 (&#39;because&#39;, 2688),
 (&#39;take&#39;, 2673),
 (&#39;able&#39;, 2668),
 (&#39;st&#39;, 2664),
 (&#39;1&#39;, 2660),
 (&#39;dinner&#39;, 2651),
 (&#39;worth&#39;, 2645),
 (&#39;included&#39;, 2644),
 (&#39;courteous&#39;, 2621),
 (&#39;vienna&#39;, 2620),
 (&#39;garden&#39;, 2619),
 (&#39;decent&#39;, 2616),
 (&#39;eat&#39;, 2605),
 (&#39;during&#39;, 2595),
 (&#39;cosy&#39;, 2594),
 (&#39;without&#39;, 2587),
 (&#39;customer&#39;, 2581),
 (&#39;car&#39;, 2575),
 (&#39;double&#39;, 2550),
 (&#39;going&#39;, 2538),
 (&#39;whole&#39;, 2511),
 (&#39;square&#39;, 2496),
 (&#39;business&#39;, 2494),
 (&#39;how&#39;, 2483),
 (&#39;asked&#39;, 2482),
 (&#39;given&#39;, 2477),
 (&#39;gym&#39;, 2457),
 (&#39;plus&#39;, 2456),
 (&#39;d&#39;, 2438),
 (&#39;local&#39;, 2433),
 (&#39;nicely&#39;, 2424),
 (&#39;nights&#39;, 2419),
 (&#39;corner&#39;, 2414),
 (&#39;interior&#39;, 2402),
 (&#39;left&#39;, 2402),
 (&#39;tidy&#39;, 2397),
 (&#39;towels&#39;, 2387),
 (&#39;wanted&#39;, 2383),
 (&#39;subway&#39;, 2380),
 (&#39;fast&#39;, 2373),
 (&#39;down&#39;, 2364),
 (&#39;quick&#39;, 2362),
 (&#39;pretty&#39;, 2358),
 (&#39;reasonable&#39;, 2356),
 (&#39;town&#39;, 2355),
 (&#39;outstanding&#39;, 2350),
 (&#39;property&#39;, 2348),
 (&#39;expensive&#39;, 2343),
 (&#39;fine&#39;, 2334),
 (&#39;handy&#39;, 2324),
 (&#39;taxi&#39;, 2317),
 (&#39;full&#39;, 2315),
 (&#39;proximity&#39;, 2305),
 (&#39;de&#39;, 2303),
 (&#39;busy&#39;, 2297),
 (&#39;times&#39;, 2286),
 (&#39;line&#39;, 2286),
 (&#39;he&#39;, 2285),
 (&#39;exceptional&#39;, 2279),
 (&#39;bonus&#39;, 2277),
 (&#39;milan&#39;, 2267),
 (&#39;appointed&#39;, 2260),
 (&#39;having&#39;, 2254),
 (&#39;mini&#39;, 2254),
 (&#39;needs&#39;, 2230),
 (&#39;paddington&#39;, 2228),
 (&#39;tourist&#39;, 2222),
 (&#39;luggage&#39;, 2221),
 (&#39;things&#39;, 2201),
 (&#39;found&#39;, 2186),
 (&#39;thanks&#39;, 2185),
 (&#39;toiletries&#39;, 2175),
 (&#39;museums&#39;, 2168),
 (&#39;helpfull&#39;, 2168),
 (&#39;travel&#39;, 2164),
 (&#39;star&#39;, 2163),
 (&#39;20&#39;, 2156),
 (&#39;looking&#39;, 2152),
 (&#39;long&#39;, 2150),
 (&#39;problem&#39;, 2147),
 (&#39;helped&#39;, 2141),
 (&#39;offered&#39;, 2131),
 (&#39;window&#39;, 2107),
 (&#39;drink&#39;, 2104),
 (&#39;fab&#39;, 2096),
 (&#39;looked&#39;, 2084),
 (&#39;second&#39;, 2081),
 (&#39;eiffel&#39;, 2065),
 (&#39;open&#39;, 2061),
 (&#39;staffs&#39;, 2058),
 (&#39;situated&#39;, 2053),
 (&#39;end&#39;, 2052),
 (&#39;book&#39;, 2051),
 (&#39;relaxing&#39;, 2049),
 (&#39;including&#39;, 2039),
 (&#39;still&#39;, 2034),
 (&#39;sure&#39;, 2026),
 (&#39;stops&#39;, 2014),
 (&#39;recommended&#39;, 2014),
 (&#39;work&#39;, 2005),
 (&#39;each&#39;, 2002),
 (&#39;river&#39;, 2002),
 (&#39;sized&#39;, 1991),
 (&#39;cozy&#39;, 1988),
 (&#39;everyone&#39;, 1985),
 (&#39;making&#39;, 1980),
 (&#39;fridge&#39;, 1977),
 (&#39;trouble&#39;, 1976),
 (&#39;boutique&#39;, 1969),
 (&#39;don&#39;, 1955),
 (&#39;options&#39;, 1946),
 (&#39;tasty&#39;, 1944),
 (&#39;ready&#39;, 1940),
 (&#39;receptionist&#39;, 1935),
 (&#39;different&#39;, 1930),
 (&#39;executive&#39;, 1930),
 (&#39;friendliness&#39;, 1926),
 (&#39;part&#39;, 1914),
 (&#39;weekend&#39;, 1902),
 (&#39;heart&#39;, 1890),
 (&#39;museum&#39;, 1889),
 (&#39;fault&#39;, 1886),
 (&#39;beach&#39;, 1885),
 (&#39;itself&#39;, 1875),
 (&#39;spotless&#39;, 1875),
 (&#39;beautifully&#39;, 1871),
 (&#39;fruit&#39;, 1861),
 (&#39;look&#39;, 1851),
 (&#39;however&#39;, 1848),
 (&#39;wine&#39;, 1846),
 (&#39;same&#39;, 1843),
 (&#39;appreciated&#39;, 1823),
 (&#39;last&#39;, 1818),
 (&#39;oxford&#39;, 1810),
 (&#39;everywhere&#39;, 1809),
 (&#39;gorgeous&#39;, 1807),
 (&#39;then&#39;, 1807),
 (&#39;throughout&#39;, 1793),
 (&#39;breakfasts&#39;, 1792),
 (&#39;attention&#39;, 1778),
 (&#39;getting&#39;, 1774),
 (&#39;cafes&#39;, 1772),
 (&#39;days&#39;, 1765),
 (&#39;re&#39;, 1764),
 (&#39;side&#39;, 1763),
 (&#39;while&#39;, 1762),
 (&#39;la&#39;, 1762),
 (&#39;swimming&#39;, 1756),
 (&#39;bottle&#39;, 1755),
 (&#39;she&#39;, 1755),
 (&#39;class&#39;, 1746),
 (&#39;duomo&#39;, 1746),
 (&#39;designed&#39;, 1745),
 (&#39;luxurious&#39;, 1744),
 (&#39;easily&#39;, 1735),
 (&#39;manager&#39;, 1724),
 (&#39;anything&#39;, 1716),
 (&#39;hall&#39;, 1703),
 (&#39;never&#39;, 1698),
 (&#39;general&#39;, 1688),
 (&#39;m&#39;, 1683),
 (&#39;through&#39;, 1683),
 (&#39;guests&#39;, 1676),
 (&#39;took&#39;, 1673),
 (&#39;above&#39;, 1668),
 (&#39;surprise&#39;, 1666),
 (&#39;bad&#39;, 1657),
 (&#39;sights&#39;, 1655),
 (&#39;windows&#39;, 1654),
 (&#39;checked&#39;, 1652),
 (&#39;visiting&#39;, 1649),
 (&#39;stunning&#39;, 1645),
 (&#39;house&#39;, 1640),
 (&#39;perfectly&#39;, 1624),
 (&#39;her&#39;, 1624),
 (&#39;worked&#39;, 1623),
 (&#39;luxury&#39;, 1623),
 (&#39;internet&#39;, 1616),
 (&#39;transportation&#39;, 1612),
 (&#39;wasn&#39;, 1612),
 (&#39;cake&#39;, 1610),
 (&#39;decoration&#39;, 1602),
 (&#39;services&#39;, 1601),
 (&#39;expected&#39;, 1588),
 (&#39;couple&#39;, 1585),
 (&#39;thought&#39;, 1582),
 (&#39;real&#39;, 1580),
 (&#39;facility&#39;, 1572),
 (&#39;kensington&#39;, 1570),
 (&#39;light&#39;, 1568),
 (&#39;say&#39;, 1566),
 (&#39;personal&#39;, 1563),
 (&#39;o2&#39;, 1562),
 (&#39;leave&#39;, 1560),
 (&#39;friends&#39;, 1555),
 (&#39;major&#39;, 1552),
 (&#39;incredibly&#39;, 1552),
 (&#39;soft&#39;, 1545),
 (&#39;came&#39;, 1544),
 (&#39;choices&#39;, 1543),
 (&#39;particularly&#39;, 1541),
 (&#39;single&#39;, 1535),
 (&#39;yet&#39;, 1531),
 (&#39;am&#39;, 1528),
 (&#39;round&#39;, 1522),
 (&#39;charge&#39;, 1520),
 (&#39;dining&#39;, 1508),
 (&#39;conditioning&#39;, 1507),
 (&#39;working&#39;, 1498),
 (&#39;neighborhood&#39;, 1496),
 (&#39;charming&#39;, 1493),
 (&#39;less&#39;, 1491),
 (&#39;think&#39;, 1486),
 (&#39;wi&#39;, 1484),
 (&#39;continental&#39;, 1482),
 (&#39;enjoy&#39;, 1477),
 (&#39;fi&#39;, 1475),
 (&#39;slept&#39;, 1469),
 (&#39;bathrooms&#39;, 1466),
 (&#39;ask&#39;, 1466),
 (&#39;club&#39;, 1458),
 (&#39;used&#39;, 1458),
 (&#39;personnel&#39;, 1453),
 (&#39;year&#39;, 1453),
 (&#39;served&#39;, 1428),
 (&#39;cold&#39;, 1426),
 (&#39;offer&#39;, 1425),
 (&#39;snacks&#39;, 1414),
 (&#39;team&#39;, 1414),
 (&#39;another&#39;, 1405),
 (&#39;incredible&#39;, 1402),
 (&#39;sightseeing&#39;, 1401),
 (&#39;palace&#39;, 1398),
 (&#39;opposite&#39;, 1397),
 (&#39;exceptionally&#39;, 1397),
 (&#39;ambience&#39;, 1394),
 (&#39;done&#39;, 1392),
 (&#39;almost&#39;, 1392),
 (&#39;cost&#39;, 1390),
 (&#39;reach&#39;, 1379),
 (&#39;several&#39;, 1375),
 (&#39;enjoyable&#39;, 1375),
 (&#39;30&#39;, 1374),
 (&#39;canal&#39;, 1358),
 (&#39;lady&#39;, 1357),
 (&#39;fact&#39;, 1356),
 (&#39;wembley&#39;, 1344),
 (&#39;anniversary&#39;, 1343),
 (&#39;theatre&#39;, 1335),
 (&#39;inside&#39;, 1333),
 (&#39;cleaning&#39;, 1328),
 (&#39;detail&#39;, 1324),
 (&#39;interesting&#39;, 1317),
 (&#39;afternoon&#39;, 1308),
 (&#39;sites&#39;, 1303),
 (&#39;entrance&#39;, 1296),
 (&#39;kept&#39;, 1291),
 (&#39;phone&#39;, 1289),
 (&#39;priced&#39;, 1287),
 (&#39;7&#39;, 1285),
 (&#39;choose&#39;, 1282),
 (&#39;bridge&#39;, 1282),
 (&#39;champagne&#39;, 1280),
 (&#39;victoria&#39;, 1280),
 (&#39;hours&#39;, 1276),
 (&#39;his&#39;, 1267),
 (&#39;quirky&#39;, 1266),
 (&#39;eggs&#39;, 1265),
 (&#39;young&#39;, 1262),
 (&#39;relaxed&#39;, 1262),
 (&#39;card&#39;, 1256),
 (&#39;smart&#39;, 1247),
 (&#39;should&#39;, 1246),
 (&#39;king&#39;, 1245),
 (&#39;request&#39;, 1244),
 (&#39;start&#39;, 1243),
 (&#39;bags&#39;, 1241),
 (&#39;hour&#39;, 1239),
 (&#39;spot&#39;, 1232),
 (&#39;v&#39;, 1231),
 (&#39;market&#39;, 1227),
 (&#39;24&#39;, 1225),
 (&#39;cooked&#39;, 1224),
 (&#39;cocktails&#39;, 1224),
 (&#39;ride&#39;, 1218),
 (&#39;until&#39;, 1216),
 (&#39;due&#39;, 1215),
 (&#39;rate&#39;, 1215),
 (&#39;beyond&#39;, 1214),
 (&#39;buses&#39;, 1213),
 (&#39;nespresso&#39;, 1213),
 (&#39;middle&#39;, 1212),
 (&#39;shuttle&#39;, 1212),
 (&#39;touches&#39;, 1211),
 (&#39;links&#39;, 1210),
 (&#39;paid&#39;, 1210),
 (&#39;despite&#39;, 1195),
 (&#39;albert&#39;, 1193),
 (&#39;sky&#39;, 1192),
 (&#39;know&#39;, 1189),
 (&#39;overlooking&#39;, 1187),
 (&#39;connection&#39;, 1187),
 (&#39;meal&#39;, 1184),
 (&#39;presented&#39;, 1184),
 (&#39;court&#39;, 1183),
 (&#39;renovated&#39;, 1181),
 (&#39;smile&#39;, 1177),
 (&#39;put&#39;, 1176),
 (&#39;district&#39;, 1174),
 (&#39;anyone&#39;, 1170),
 (&#39;reasonably&#39;, 1170),
 (&#39;menu&#39;, 1162),
 (&#39;level&#39;, 1162),
 (&#39;cleaned&#39;, 1160),
 (&#39;hop&#39;, 1160),
 (&#39;gare&#39;, 1160),
 (&#39;wide&#39;, 1159),
 (&#39;kids&#39;, 1158),
 (&#39;travelling&#39;, 1157),
 (&#39;own&#39;, 1152),
 (&#39;makes&#39;, 1149),
 (&#39;anywhere&#39;, 1146),
 (&#39;cafe&#39;, 1137),
 (&#39;arena&#39;, 1137),
 (&#39;accommodation&#39;, 1136),
 (&#39;noisy&#39;, 1135),
 (&#39;accessible&#39;, 1134),
 (&#39;upon&#39;, 1119),
 (&#39;supermarket&#39;, 1115),
 (&#39;hard&#39;, 1114),
 (&#39;set&#39;, 1113),
 (&#39;tour&#39;, 1113),
 (&#39;furnished&#39;, 1113),
 (&#39;sauna&#39;, 1111),
 (&#39;checking&#39;, 1110),
 (&#39;coming&#39;, 1109),
 (&#39;world&#39;, 1108),
 (&#39;cookies&#39;, 1106),
 (&#39;try&#39;, 1105),
 (&#39;stadium&#39;, 1104),
 (&#39;give&#39;, 1103),
 (&#39;peaceful&#39;, 1103),
 (&#39;person&#39;, 1100),
 (&#39;certainly&#39;, 1096),
 (&#39;fun&#39;, 1092),
 (&#39;else&#39;, 1089),
 (&#39;chocolate&#39;, 1086),
 (&#39;site&#39;, 1083),
 (&#39;glass&#39;, 1078),
 (&#39;three&#39;, 1078),
 (&#39;ll&#39;, 1075),
 (&#39;furniture&#39;, 1074),
 (&#39;kitchen&#39;, 1073),
 (&#39;confortable&#39;, 1070),
 (&#39;royal&#39;, 1068),
 (&#39;pay&#39;, 1063),
 (&#39;bright&#39;, 1055),
 (&#39;since&#39;, 1055),
 (&#39;change&#39;, 1055),
 (&#39;wait&#39;, 1050),
 (&#39;range&#39;, 1047),
 (&#39;something&#39;, 1047),
 (&#39;received&#39;, 1047),
 (&#39;walked&#39;, 1045),
 (&#39;west&#39;, 1045),
 (&#39;elegant&#39;, 1045),
 (&#39;care&#39;, 1043),
 (&#39;treat&#39;, 1040),
 (&#39;willing&#39;, 1038),
 (&#39;covent&#39;, 1037),
 (&#39;spotlessly&#39;, 1031),
 (&#39;relax&#39;, 1026),
 (&#39;lighting&#39;, 1023),
 (&#39;daily&#39;, 1022),
 (&#39;steps&#39;, 1021),
 (&#39;adequate&#39;, 1021),
 (&#39;housekeeping&#39;, 1021),
 (&#39;soon&#39;, 1021),
 (&#39;expect&#39;, 1019),
 (&#39;u&#39;, 1018),
 (&#39;useful&#39;, 1017),
 (&#39;order&#39;, 1015),
 (&#39;unique&#39;, 1014),
 (&#39;seeing&#39;, 1014),
 (&#39;deal&#39;, 1010),
 (&#39;guest&#39;, 1010),
 (&#39;toilet&#39;, 1008),
 (&#39;hospitality&#39;, 1006),
 (&#39;junior&#39;, 1006),
 (&#39;once&#39;, 1005),
 (&#39;via&#39;, 1003),
 (&#39;daughter&#39;, 1002),
 (&#39;wife&#39;, 1001),
 (&#39;convenience&#39;, 1000),
 (&#39;apartment&#39;, 1000),
 (&#39;member&#39;, 999),
 (&#39;superior&#39;, 997),
 (&#39;years&#39;, 995),
 (&#39;requested&#39;, 994),
 (&#39;children&#39;, 992),
 (&#39;takes&#39;, 987),
 (&#39;impressed&#39;, 986),
 (&#39;ramblas&#39;, 983),
 (&#39;cheap&#39;, 981),
 (&#39;rather&#39;, 980),
 (&#39;6&#39;, 971),
 (&#39;actually&#39;, 969),
 (&#39;generally&#39;, 966),
 (&#39;must&#39;, 966),
 (&#39;directly&#39;, 962),
 (&#39;maintained&#39;, 962),
 (&#39;cannot&#39;, 959),
 (&#39;added&#39;, 959),
 (&#39;between&#39;, 959),
 (&#39;cathedral&#39;, 956),
 (&#39;except&#39;, 954),
 (&#39;simple&#39;, 953),
 (&#39;downstairs&#39;, 946),
 (&#39;let&#39;, 943),
 (&#39;literally&#39;, 940),
 (&#39;along&#39;, 936),
 (&#39;railway&#39;, 935),
 (&#39;standards&#39;, 935),
 (&#39;linen&#39;, 934),
 (&#39;name&#39;, 933),
 (&#39;allowed&#39;, 932),
 (&#39;milano&#39;, 930),
 (&#39;refurbished&#39;, 927),
 (&#39;rest&#39;, 925),
 (&#39;thames&#39;, 924),
 (&#39;n&#39;, 919),
 (&#39;kettle&#39;, 918),
 (&#39;option&#39;, 917),
 (&#39;tickets&#39;, 916),
 (&#39;foot&#39;, 915),
 (&#39;per&#39;, 914),
 (&#39;prices&#39;, 910),
 (&#39;conveniently&#39;, 905),
 (&#39;quickly&#39;, 900),
 (&#39;bedding&#39;, 900),
 (&#39;cookie&#39;, 900),
 (&#39;lines&#39;, 896),
 (&#39;smiling&#39;, 894),
 (&#39;12&#39;, 894),
 (&#39;euston&#39;, 893),
 (&#39;100&#39;, 892),
 (&#39;con&#39;, 889),
 (&#39;break&#39;, 889),
 (&#39;calm&#39;, 889),
 (&#39;art&#39;, 887),
 (&#39;opera&#39;, 886),
 (&#39;fairly&#39;, 882),
 (&#39;those&#39;, 880),
 (&#39;directions&#39;, 879),
 (&#39;flight&#39;, 879),
 (&#39;table&#39;, 878),
 (&#39;met&#39;, 878),
 (&#39;chocolates&#39;, 875),
 (&#39;possible&#39;, 874),
 (&#39;moment&#39;, 871),
 (&#39;told&#39;, 871),
 (&#39;five&#39;, 870),
 (&#39;history&#39;, 868),
 (&#39;husband&#39;, 868),
 (&#39;bigger&#39;, 866),
 (&#39;shop&#39;, 865),
 (&#39;environment&#39;, 860),
 (&#39;wish&#39;, 854),
 (&#39;lift&#39;, 854),
 (&#39;concert&#39;, 853),
 (&#39;private&#39;, 853),
 (&#39;vibe&#39;, 850),
 (&#39;keep&#39;, 848),
 (&#39;information&#39;, 848),
 (&#39;wharf&#39;, 847),
 (&#39;issue&#39;, 846),
 (&#39;looks&#39;, 845),
 (&#39;cross&#39;, 845),
 (&#39;ambiance&#39;, 841),
 (&#39;croissants&#39;, 839),
 (&#39;minibar&#39;, 839),
 (&#39;problems&#39;, 836),
 (&#39;run&#39;, 835),
 (&#39;point&#39;, 835),
 (&#39;extras&#39;, 833),
 (&#39;checkout&#39;, 832),
 (&#39;impressive&#39;, 830),
 (&#39;products&#39;, 830),
 (&#39;wedding&#39;, 829),
 (&#39;canary&#39;, 828),
 (&#39;eye&#39;, 827),
 (&#39;iron&#39;, 826),
 (&#39;centrally&#39;, 825),
 (&#39;exploring&#39;, 824),
 (&#39;important&#39;, 821),
 (&#39;rambla&#39;, 821),
 (&#39;now&#39;, 819),
 (&#39;explore&#39;, 818),
 (&#39;neighbourhood&#39;, 817),
 (&#39;store&#39;, 817),
 (&#39;requests&#39;, 817),
 (&#39;mall&#39;, 817),
 (&#39;champs&#39;, 816),
 (&#39;number&#39;, 814),
 (&#39;seemed&#39;, 813),
 (&#39;basic&#39;, 811),
 (&#39;separate&#39;, 810),
 (&#39;simply&#39;, 805),
 (&#39;spoke&#39;, 805),
 (&#39;considering&#39;, 805),
 (&#39;immaculate&#39;, 803),
 (&#39;system&#39;, 802),
 (&#39;returning&#39;, 799),
 (&#39;heathrow&#39;, 799),
 (&#39;gardens&#39;, 798),
 (&#39;straight&#39;, 797),
 (&#39;brand&#39;, 796),
 (&#39;poor&#39;, 796),
 (&#39;using&#39;, 793),
 (&#39;exactly&#39;, 790),
 (&#39;du&#39;, 790),
 (&#39;questions&#39;, 789),
 (&#39;courtyard&#39;, 789),
 (&#39;others&#39;, 789),
 (&#39;details&#39;, 787),
 (&#39;knowledgeable&#39;, 787),
 (&#39;feeling&#39;, 785),
 (&#39;direct&#39;, 785),
 (&#39;recently&#39;, 784),
 (&#39;ground&#39;, 782),
 (&#39;immediately&#39;, 782),
 (&#39;louvre&#39;, 782),
 (&#39;man&#39;, 781),
 (&#39;waiting&#39;, 780),
 (&#39;e&#39;, 778),
 (&#39;particular&#39;, 777),
 (&#39;expectations&#39;, 777),
 (&#39;8&#39;, 777),
 (&#39;amazingly&#39;, 775),
 (&#39;trains&#39;, 774),
 (&#39;newly&#39;, 773),
 (&#39;said&#39;, 771),
 (&#39;layout&#39;, 769),
 (&#39;recommendations&#39;, 768),
 (&#39;juice&#39;, 768),
 (&#39;bedrooms&#39;, 767),
 (&#39;pub&#39;, 766),
 (&#39;theatres&#39;, 766),
 (&#39;changed&#39;, 764),
 (&#39;truly&#39;, 763),
 (&#39;nord&#39;, 762),
 (&#39;eating&#39;, 760),
 (&#39;sound&#39;, 757),
 (&#39;com&#39;, 757),
 (&#39;secure&#39;, 756),
 (&#39;idea&#39;, 755),
 (&#39;greeted&#39;, 755),
 (&#39;slippers&#39;, 754),
 (&#39;members&#39;, 753),
 (&#39;music&#39;, 750),
 (&#39;locations&#39;, 748),
 (&#39;already&#39;, 746),
 (&#39;pubs&#39;, 746),
 (&#39;cheerful&#39;, 745),
 (&#39;called&#39;, 740),
 (&#39;twin&#39;, 739),
 (&#39;delightful&#39;, 738),
 (&#39;provide&#39;, 738),
 (&#39;streets&#39;, 737),
 (&#39;plaza&#39;, 731),
 (&#39;helpfulness&#39;, 730),
 (&#39;traffic&#39;, 729),
 (&#39;probably&#39;, 728),
 (&#39;works&#39;, 726),
 (&#39;items&#39;, 723),
 (&#39;situation&#39;, 723),
 (&#39;trams&#39;, 722),
 (&#39;character&#39;, 718),
 (&#39;deluxe&#39;, 718),
 (&#39;complementary&#39;, 718),
 (&#39;dam&#39;, 714),
 (&#39;attitude&#39;, 714),
 (&#39;french&#39;, 714),
 (&#39;quarter&#39;, 712),
 (&#39;generous&#39;, 710),
 (&#39;block&#39;, 706),
 (&#39;italian&#39;, 705),
 (&#39;compared&#39;, 704),
 (&#39;massive&#39;, 703),
 (&#39;british&#39;, 703),
 (&#39;future&#39;, 702),
 (&#39;seen&#39;, 701),
 (&#39;usual&#39;, 699),
 (&#39;facing&#39;, 699),
 (&#39;south&#39;, 699),
 (&#39;neat&#39;, 696),
 (&#39;dlr&#39;, 696),
 (&#39;under&#39;, 695),
 (&#39;fair&#39;, 695),
 (&#39;four&#39;, 694),
 (&#39;express&#39;, 694),
 (&#39;relatively&#39;, 693),
 (&#39;funky&#39;, 692),
 (&#39;behind&#39;, 690),
 (&#39;may&#39;, 689),
 (&#39;curtains&#39;, 687),
 (&#39;mile&#39;, 687),
 (&#39;beside&#39;, 684),
 (&#39;longer&#39;, 682),
 (&#39;grand&#39;, 681),
 (&#39;pleased&#39;, 680),
 (&#39;holiday&#39;, 677),
 (&#39;mattress&#39;, 676),
 (&#39;westminster&#39;, 676),
 (&#39;trendy&#39;, 675),
 (&#39;downtown&#39;, 674),
 (&#39;terrific&#39;, 673),
 (&#39;surprised&#39;, 672),
 (&#39;tiny&#39;, 668),
 (&#39;catalunya&#39;, 668),
 (&#39;partner&#39;, 667),
 (&#39;later&#39;, 667),
 (&#39;whilst&#39;, 665),
 (&#39;bottles&#39;, 665),
 (&#39;job&#39;, 664),
 (&#39;euros&#39;, 661),
 (&#39;brought&#39;, 661),
 (&#39;lights&#39;, 660),
 (&#39;centrale&#39;, 659),
 (&#39;sit&#39;, 658),
 (&#39;stars&#39;, 658),
 (&#39;tried&#39;, 658),
 (&#39;larger&#39;, 657),
 (&#39;everyday&#39;, 657),
 (&#39;arranged&#39;, 656),
 (&#39;channels&#39;, 653),
 ...]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">negative_counts</span><span class="o">.</span><span class="n">most_common</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[12]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[(&#39;&#39;, 595699),
 (&#39;the&#39;, 530599),
 (&#39;was&#39;, 236473),
 (&#39;a&#39;, 229956),
 (&#39;to&#39;, 228575),
 (&#39;and&#39;, 219273),
 (&#39;room&#39;, 175745),
 (&#39;in&#39;, 167786),
 (&#39;not&#39;, 125498),
 (&#39;i&#39;, 122137),
 (&#39;of&#39;, 120489),
 (&#39;for&#39;, 117484),
 (&#39;it&#39;, 106973),
 (&#39;no&#39;, 105755),
 (&#39;we&#39;, 99210),
 (&#39;is&#39;, 82062),
 (&#39;very&#39;, 80501),
 (&#39;but&#39;, 75550),
 (&#39;hotel&#39;, 74656),
 (&#39;t&#39;, 72373),
 (&#39;on&#39;, 68686),
 (&#39;were&#39;, 61630),
 (&#39;at&#39;, 61076),
 (&#39;had&#39;, 60064),
 (&#39;that&#39;, 58784),
 (&#39;breakfast&#39;, 58362),
 (&#39;have&#39;, 54638),
 (&#39;with&#39;, 51946),
 (&#39;small&#39;, 49814),
 (&#39;there&#39;, 46440),
 (&#39;be&#39;, 45199),
 (&#39;as&#39;, 44048),
 (&#39;they&#39;, 42570),
 (&#39;you&#39;, 40539),
 (&#39;from&#39;, 40183),
 (&#39;this&#39;, 39648),
 (&#39;staff&#39;, 39485),
 (&#39;so&#39;, 39235),
 (&#39;my&#39;, 38724),
 (&#39;positive&#39;, 36140),
 (&#39;rooms&#39;, 34755),
 (&#39;our&#39;, 33966),
 (&#39;would&#39;, 32258),
 (&#39;could&#39;, 32027),
 (&#39;when&#39;, 30917),
 (&#39;bed&#39;, 29818),
 (&#39;are&#39;, 29342),
 (&#39;all&#39;, 29081),
 (&#39;too&#39;, 28753),
 (&#39;one&#39;, 28048),
 (&#39;only&#39;, 28007),
 (&#39;bit&#39;, 27486),
 (&#39;out&#39;, 27009),
 (&#39;bathroom&#39;, 26563),
 (&#39;didn&#39;, 26423),
 (&#39;which&#39;, 26018),
 (&#39;night&#39;, 24041),
 (&#39;nothing&#39;, 23552),
 (&#39;little&#39;, 22485),
 (&#39;like&#39;, 22421),
 (&#39;or&#39;, 22350),
 (&#39;if&#39;, 21302),
 (&#39;shower&#39;, 21278),
 (&#39;an&#39;, 20860),
 (&#39;good&#39;, 20784),
 (&#39;more&#39;, 20311),
 (&#39;been&#39;, 20292),
 (&#39;us&#39;, 20204),
 (&#39;did&#39;, 20088),
 (&#39;get&#39;, 19477),
 (&#39;up&#39;, 19467),
 (&#39;service&#39;, 19293),
 (&#39;bar&#39;, 19100),
 (&#39;s&#39;, 18631),
 (&#39;me&#39;, 18479),
 (&#39;time&#39;, 17440),
 (&#39;stay&#39;, 17396),
 (&#39;reception&#39;, 16622),
 (&#39;really&#39;, 16531),
 (&#39;expensive&#39;, 16493),
 (&#39;also&#39;, 16448),
 (&#39;just&#39;, 16241),
 (&#39;some&#39;, 16221),
 (&#39;poor&#39;, 16095),
 (&#39;even&#39;, 15405),
 (&#39;check&#39;, 15340),
 (&#39;by&#39;, 15297),
 (&#39;price&#39;, 15236),
 (&#39;day&#39;, 15131),
 (&#39;floor&#39;, 14941),
 (&#39;can&#39;, 14475),
 (&#39;water&#39;, 14251),
 (&#39;wasn&#39;, 14151),
 (&#39;noisy&#39;, 13923),
 (&#39;2&#39;, 13841),
 (&#39;after&#39;, 13263),
 (&#39;air&#39;, 13230),
 (&#39;about&#39;, 13184),
 (&#39;work&#39;, 12935),
 (&#39;coffee&#39;, 12731),
 (&#39;other&#39;, 12611),
 (&#39;wifi&#39;, 12586),
 (&#39;door&#39;, 12522),
 (&#39;hot&#39;, 12132),
 (&#39;better&#39;, 12044),
 (&#39;quite&#39;, 12003),
 (&#39;noise&#39;, 11798),
 (&#39;than&#39;, 11788),
 (&#39;much&#39;, 11554),
 (&#39;booking&#39;, 11506),
 (&#39;food&#39;, 11440),
 (&#39;two&#39;, 11179),
 (&#39;what&#39;, 11128),
 (&#39;location&#39;, 11002),
 (&#39;area&#39;, 10915),
 (&#39;asked&#39;, 10734),
 (&#39;old&#39;, 10627),
 (&#39;restaurant&#39;, 10599),
 (&#39;should&#39;, 10571),
 (&#39;do&#39;, 10527),
 (&#39;4&#39;, 10353),
 (&#39;bad&#39;, 10343),
 (&#39;got&#39;, 10337),
 (&#39;told&#39;, 10184),
 (&#39;booked&#39;, 10113),
 (&#39;next&#39;, 10047),
 (&#39;great&#39;, 9963),
 (&#39;view&#39;, 9959),
 (&#39;cold&#39;, 9914),
 (&#39;nice&#39;, 9881),
 (&#39;people&#39;, 9866),
 (&#39;first&#39;, 9636),
 (&#39;morning&#39;, 9612),
 (&#39;everything&#39;, 9607),
 (&#39;need&#39;, 9598),
 (&#39;window&#39;, 9552),
 (&#39;back&#39;, 9486),
 (&#39;tea&#39;, 9348),
 (&#39;over&#39;, 9293),
 (&#39;3&#39;, 9251),
 (&#39;double&#39;, 9206),
 (&#39;because&#39;, 9154),
 (&#39;off&#39;, 9095),
 (&#39;parking&#39;, 9019),
 (&#39;made&#39;, 8877),
 (&#39;pay&#39;, 8607),
 (&#39;use&#39;, 8582),
 (&#39;down&#39;, 8573),
 (&#39;your&#39;, 8542),
 (&#39;open&#39;, 8491),
 (&#39;clean&#39;, 8487),
 (&#39;then&#39;, 8439),
 (&#39;any&#39;, 8375),
 (&#39;them&#39;, 8302),
 (&#39;facilities&#39;, 8244),
 (&#39;being&#39;, 8147),
 (&#39;far&#39;, 8074),
 (&#39;around&#39;, 8004),
 (&#39;well&#39;, 7985),
 (&#39;pool&#39;, 7912),
 (&#39;outside&#39;, 7848),
 (&#39;5&#39;, 7788),
 (&#39;enough&#39;, 7718),
 (&#39;again&#39;, 7691),
 (&#39;free&#39;, 7657),
 (&#39;paid&#39;, 7647),
 (&#39;money&#39;, 7642),
 (&#39;go&#39;, 7633),
 (&#39;couldn&#39;, 7566),
 (&#39;beds&#39;, 7559),
 (&#39;working&#39;, 7529),
 (&#39;tv&#39;, 7519),
 (&#39;star&#39;, 7447),
 (&#39;don&#39;, 7278),
 (&#39;before&#39;, 7257),
 (&#39;bath&#39;, 7186),
 (&#39;extra&#39;, 7182),
 (&#39;will&#39;, 7143),
 (&#39;stayed&#39;, 7126),
 (&#39;still&#39;, 7093),
 (&#39;slow&#39;, 7018),
 (&#39;though&#39;, 6978),
 (&#39;sleep&#39;, 6948),
 (&#39;toilet&#39;, 6930),
 (&#39;size&#39;, 6885),
 (&#39;tiny&#39;, 6874),
 (&#39;hard&#39;, 6810),
 (&#39;way&#39;, 6716),
 (&#39;however&#39;, 6714),
 (&#39;long&#39;, 6676),
 (&#39;1&#39;, 6615),
 (&#39;said&#39;, 6598),
 (&#39;think&#39;, 6464),
 (&#39;problem&#39;, 6464),
 (&#39;front&#39;, 6437),
 (&#39;available&#39;, 6429),
 (&#39;into&#39;, 6386),
 (&#39;their&#39;, 6363),
 (&#39;find&#39;, 6355),
 (&#39;never&#39;, 6256),
 (&#39;dirty&#39;, 6208),
 (&#39;took&#39;, 6135),
 (&#39;times&#39;, 6110),
 (&#39;although&#39;, 6092),
 (&#39;given&#39;, 6074),
 (&#39;during&#39;, 6059),
 (&#39;put&#39;, 6033),
 (&#39;desk&#39;, 6012),
 (&#39;walk&#39;, 5955),
 (&#39;lift&#39;, 5953),
 (&#39;guests&#39;, 5904),
 (&#39;space&#39;, 5884),
 (&#39;has&#39;, 5881),
 (&#39;same&#39;, 5865),
 (&#39;another&#39;, 5838),
 (&#39;city&#39;, 5813),
 (&#39;having&#39;, 5789),
 (&#39;left&#39;, 5784),
 (&#39;every&#39;, 5772),
 (&#39;where&#39;, 5763),
 (&#39;windows&#39;, 5746),
 (&#39;place&#39;, 5733),
 (&#39;arrived&#39;, 5728),
 (&#39;make&#39;, 5697),
 (&#39;hotels&#39;, 5692),
 (&#39;lot&#39;, 5674),
 (&#39;street&#39;, 5661),
 (&#39;early&#39;, 5631),
 (&#39;needs&#39;, 5623),
 (&#39;days&#39;, 5621),
 (&#39;london&#39;, 5615),
 (&#39;uncomfortable&#39;, 5599),
 (&#39;conditioning&#39;, 5545),
 (&#39;comfortable&#39;, 5526),
 (&#39;card&#39;, 5473),
 (&#39;he&#39;, 5406),
 (&#39;high&#39;, 5377),
 (&#39;thing&#39;, 5362),
 (&#39;pillows&#39;, 5361),
 (&#39;single&#39;, 5344),
 (&#39;without&#39;, 5337),
 (&#39;included&#39;, 5319),
 (&#39;ask&#39;, 5301),
 (&#39;charge&#39;, 5244),
 (&#39;went&#39;, 5240),
 (&#39;side&#39;, 5229),
 (&#39;close&#39;, 5227),
 (&#39;who&#39;, 5225),
 (&#39;found&#39;, 5191),
 (&#39;late&#39;, 5180),
 (&#39;rather&#39;, 5166),
 (&#39;away&#39;, 5130),
 (&#39;rude&#39;, 5113),
 (&#39;needed&#39;, 5107),
 (&#39;due&#39;, 5094),
 (&#39;building&#39;, 5086),
 (&#39;felt&#39;, 5069),
 (&#39;10&#39;, 5041),
 (&#39;hear&#39;, 5041),
 (&#39;bedroom&#39;, 5033),
 (&#39;minutes&#39;, 5019),
 (&#39;take&#39;, 5017),
 (&#39;standard&#39;, 5009),
 (&#39;big&#39;, 4977),
 (&#39;anything&#39;, 4933),
 (&#39;wait&#39;, 4924),
 (&#39;smell&#39;, 4915),
 (&#39;quality&#39;, 4906),
 (&#39;tired&#39;, 4753),
 (&#39;ok&#39;, 4743),
 (&#39;going&#39;, 4733),
 (&#39;difficult&#39;, 4729),
 (&#39;light&#39;, 4700),
 (&#39;com&#39;, 4683),
 (&#39;friendly&#39;, 4634),
 (&#39;few&#39;, 4622),
 (&#39;extremely&#39;, 4598),
 (&#39;while&#39;, 4589),
 (&#39;until&#39;, 4533),
 (&#39;per&#39;, 4513),
 (&#39;cost&#39;, 4507),
 (&#39;expected&#39;, 4491),
 (&#39;charged&#39;, 4480),
 (&#39;car&#39;, 4475),
 (&#39;came&#39;, 4473),
 (&#39;most&#39;, 4460),
 (&#39;its&#39;, 4447),
 (&#39;through&#39;, 4401),
 (&#39;30&#39;, 4391),
 (&#39;many&#39;, 4387),
 (&#39;warm&#39;, 4385),
 (&#39;helpful&#39;, 4380),
 (&#39;cleaning&#39;, 4376),
 (&#39;person&#39;, 4370),
 (&#39;full&#39;, 4363),
 (&#39;she&#39;, 4361),
 (&#39;how&#39;, 4352),
 (&#39;am&#39;, 4336),
 (&#39;see&#39;, 4330),
 (&#39;change&#39;, 4322),
 (&#39;nights&#39;, 4313),
 (&#39;arrival&#39;, 4292),
 (&#39;know&#39;, 4255),
 (&#39;limited&#39;, 4245),
 (&#39;etc&#39;, 4220),
 (&#39;used&#39;, 4205),
 (&#39;station&#39;, 4200),
 (&#39;dark&#39;, 4193),
 (&#39;towels&#39;, 4181),
 (&#39;experience&#39;, 4137),
 (&#39;feel&#39;, 4127),
 (&#39;broken&#39;, 4121),
 (&#39;drinks&#39;, 4117),
 (&#39;wall&#39;, 4081),
 (&#39;internet&#39;, 4052),
 (&#39;evening&#39;, 4014),
 (&#39;lobby&#39;, 3905),
 (&#39;hours&#39;, 3862),
 (&#39;especially&#39;, 3841),
 (&#39;english&#39;, 3833),
 (&#39;properly&#39;, 3810),
 (&#39;each&#39;, 3779),
 (&#39;say&#39;, 3769),
 (&#39;want&#39;, 3757),
 (&#39;loud&#39;, 3710),
 (&#39;issue&#39;, 3709),
 (&#39;value&#39;, 3706),
 (&#39;offered&#39;, 3676),
 (&#39;closed&#39;, 3655),
 (&#39;making&#39;, 3650),
 (&#39;seemed&#39;, 3648),
 (&#39;table&#39;, 3648),
 (&#39;here&#39;, 3618),
 (&#39;second&#39;, 3600),
 (&#39;wanted&#39;, 3599),
 (&#39;checked&#39;, 3590),
 (&#39;busy&#39;, 3577),
 (&#39;things&#39;, 3559),
 (&#39;come&#39;, 3541),
 (&#39;lack&#39;, 3534),
 (&#39;walls&#39;, 3511),
 (&#39;thought&#39;, 3509),
 (&#39;such&#39;, 3491),
 (&#39;elevator&#39;, 3488),
 (&#39;luggage&#39;, 3465),
 (&#39;help&#39;, 3452),
 (&#39;looked&#39;, 3444),
 (&#39;always&#39;, 3443),
 (&#39;heating&#39;, 3426),
 (&#39;dated&#39;, 3403),
 (&#39;order&#39;, 3400),
 (&#39;cleaned&#39;, 3393),
 (&#39;kept&#39;, 3387),
 (&#39;right&#39;, 3383),
 (&#39;terrible&#39;, 3375),
 (&#39;basic&#39;, 3363),
 (&#39;20&#39;, 3351),
 (&#39;fridge&#39;, 3336),
 (&#39;disappointing&#39;, 3327),
 (&#39;hour&#39;, 3321),
 (&#39;main&#39;, 3317),
 (&#39;something&#39;, 3316),
 (&#39;top&#39;, 3303),
 (&#39;choice&#39;, 3302),
 (&#39;receptionist&#39;, 3301),
 (&#39;mini&#39;, 3283),
 (&#39;con&#39;, 3261),
 (&#39;spa&#39;, 3252),
 (&#39;disappointed&#39;, 3250),
 (&#39;15&#39;, 3243),
 (&#39;expect&#39;, 3210),
 (&#39;call&#39;, 3193),
 (&#39;gave&#39;, 3193),
 (&#39;staying&#39;, 3174),
 (&#39;furniture&#39;, 3173),
 (&#39;menu&#39;, 3162),
 (&#39;look&#39;, 3161),
 (&#39;perfect&#39;, 3160),
 (&#39;ve&#39;, 3157),
 (&#39;new&#39;, 3152),
 (&#39;park&#39;, 3152),
 (&#39;carpet&#39;, 3139),
 (&#39;taxi&#39;, 3132),
 (&#39;maybe&#39;, 3116),
 (&#39;worth&#39;, 3114),
 (&#39;road&#39;, 3112),
 (&#39;access&#39;, 3107),
 (&#39;ready&#39;, 3105),
 (&#39;liked&#39;, 3097),
 (&#39;drink&#39;, 3089),
 (&#39;both&#39;, 3089),
 (&#39;gym&#39;, 3080),
 (&#39;near&#39;, 3079),
 (&#39;fact&#39;, 3057),
 (&#39;fine&#39;, 3055),
 (&#39;someone&#39;, 3052),
 (&#39;leave&#39;, 3047),
 (&#39;phone&#39;, 3036),
 (&#39;overall&#39;, 3034),
 (&#39;best&#39;, 3027),
 (&#39;provided&#39;, 3027),
 (&#39;doors&#39;, 3025),
 (&#39;fault&#39;, 2989),
 (&#39;centre&#39;, 2989),
 (&#39;stairs&#39;, 2985),
 (&#39;different&#39;, 2982),
 (&#39;requested&#39;, 2979),
 (&#39;sure&#39;, 2973),
 (&#39;last&#39;, 2963),
 (&#39;manager&#39;, 2961),
 (&#39;twin&#39;, 2960),
 (&#39;m&#39;, 2947),
 (&#39;getting&#39;, 2936),
 (&#39;under&#39;, 2914),
 (&#39;d&#39;, 2889),
 (&#39;center&#39;, 2873),
 (&#39;give&#39;, 2873),
 (&#39;able&#39;, 2870),
 (&#39;waiting&#39;, 2850),
 (&#39;buffet&#39;, 2829),
 (&#39;sink&#39;, 2820),
 (&#39;above&#39;, 2809),
 (&#39;wouldn&#39;, 2801),
 (&#39;system&#39;, 2798),
 (&#39;slightly&#39;, 2797),
 (&#39;instead&#39;, 2794),
 (&#39;checking&#39;, 2790),
 (&#39;despite&#39;, 2783),
 (&#39;temperature&#39;, 2779),
 (&#39;prices&#39;, 2778),
 (&#39;why&#39;, 2778),
 (&#39;bigger&#39;, 2776),
 (&#39;done&#39;, 2773),
 (&#39;looking&#39;, 2759),
 (&#39;move&#39;, 2754),
 (&#39;glass&#39;, 2751),
 (&#39;changed&#39;, 2742),
 (&#39;end&#39;, 2726),
 (&#39;inside&#39;, 2720),
 (&#39;couple&#39;, 2717),
 (&#39;re&#39;, 2710),
 (&#39;offer&#39;, 2702),
 (&#39;euros&#39;, 2693),
 (&#39;upgrade&#39;, 2692),
 (&#39;kettle&#39;, 2690),
 (&#39;ever&#39;, 2675),
 (&#39;whole&#39;, 2671),
 (&#39;between&#39;, 2669),
 (&#39;almost&#39;, 2648),
 (&#39;sound&#39;, 2639),
 (&#39;eat&#39;, 2632),
 (&#39;mattress&#39;, 2613),
 (&#39;large&#39;, 2603),
 (&#39;tried&#39;, 2599),
 (&#39;milk&#39;, 2596),
 (&#39;twice&#39;, 2592),
 (&#39;book&#39;, 2586),
 (&#39;half&#39;, 2585),
 (&#39;else&#39;, 2576),
 (&#39;metro&#39;, 2556),
 (&#39;called&#39;, 2549),
 (&#39;none&#39;, 2545),
 (&#39;coming&#39;, 2540),
 (&#39;overpriced&#39;, 2538),
 (&#39;hair&#39;, 2538),
 (&#39;soft&#39;, 2527),
 (&#39;eggs&#39;, 2520),
 (&#39;pretty&#39;, 2502),
 (&#39;actually&#39;, 2492),
 (&#39;weren&#39;, 2484),
 (&#39;later&#39;, 2481),
 (&#39;once&#39;, 2480),
 (&#39;machine&#39;, 2478),
 (&#39;50&#39;, 2473),
 (&#39;three&#39;, 2469),
 (&#39;smaller&#39;, 2469),
 (&#39;guest&#39;, 2463),
 (&#39;either&#39;, 2458),
 (&#39;wi&#39;, 2455),
 (&#39;let&#39;, 2446),
 (&#39;rate&#39;, 2444),
 (&#39;lifts&#39;, 2442),
 (&#39;less&#39;, 2434),
 (&#39;00&#39;, 2433),
 (&#39;suite&#39;, 2432),
 (&#39;key&#39;, 2427),
 (&#39;fi&#39;, 2415),
 (&#39;lighting&#39;, 2413),
 (&#39;her&#39;, 2404),
 (&#39;housekeeping&#39;, 2404),
 (&#39;decor&#39;, 2403),
 (&#39;euro&#39;, 2400),
 (&#39;moved&#39;, 2399),
 (&#39;dinner&#39;, 2398),
 (&#39;fresh&#39;, 2385),
 (&#39;request&#39;, 2377),
 (&#39;does&#39;, 2373),
 (&#39;excellent&#39;, 2364),
 (&#39;didnt&#39;, 2357),
 (&#39;n&#39;, 2353),
 (&#39;business&#39;, 2346),
 (&#39;lovely&#39;, 2343),
 (&#39;stars&#39;, 2341),
 (&#39;lounge&#39;, 2338),
 (&#39;awful&#39;, 2335),
 (&#39;central&#39;, 2325),
 (&#39;doesn&#39;, 2321),
 (&#39;definitely&#39;, 2319),
 (&#39;unfortunately&#39;, 2310),
 (&#39;thin&#39;, 2299),
 (&#39;low&#39;, 2286),
 (&#39;6&#39;, 2283),
 (&#39;since&#39;, 2283),
 (&#39;walking&#39;, 2276),
 (&#39;recommend&#39;, 2272),
 (&#39;together&#39;, 2271),
 (&#39;keep&#39;, 2269),
 (&#39;customer&#39;, 2256),
 (&#39;least&#39;, 2248),
 (&#39;entrance&#39;, 2245),
 (&#39;ac&#39;, 2241),
 (&#39;swimming&#39;, 2219),
 (&#39;may&#39;, 2206),
 (&#39;options&#39;, 2192),
 (&#39;paying&#39;, 2184),
 (&#39;non&#39;, 2182),
 (&#39;pricey&#39;, 2162),
 (&#39;bottle&#39;, 2159),
 (&#39;these&#39;, 2155),
 (&#39;7&#39;, 2154),
 (&#39;wrong&#39;, 2153),
 (&#39;member&#39;, 2149),
 (&#39;construction&#39;, 2136),
 (&#39;cramped&#39;, 2127),
 (&#39;fan&#39;, 2114),
 (&#39;nearby&#39;, 2105),
 (&#39;quiet&#39;, 2102),
 (&#39;level&#39;, 2095),
 (&#39;turn&#39;, 2082),
 (&#39;probably&#39;, 2079),
 (&#39;already&#39;, 2078),
 (&#39;lights&#39;, 2073),
 (&#39;complain&#39;, 2069),
 (&#39;basement&#39;, 2042),
 (&#39;train&#39;, 2035),
 (&#39;credit&#39;, 2033),
 (&#39;connection&#39;, 2022),
 (&#39;problems&#39;, 2020),
 (&#39;option&#39;, 2019),
 (&#39;family&#39;, 2015),
 (&#39;worst&#39;, 2006),
 (&#39;bags&#39;, 1992),
 (&#39;average&#39;, 1985),
 (&#39;served&#39;, 1983),
 (&#39;meant&#39;, 1979),
 (&#39;happy&#39;, 1974),
 (&#39;ordered&#39;, 1972),
 (&#39;point&#39;, 1965),
 (&#39;minor&#39;, 1956),
 (&#39;head&#39;, 1953),
 (&#39;short&#39;, 1950),
 (&#39;several&#39;, 1942),
 (&#39;understand&#39;, 1928),
 (&#39;12&#39;, 1916),
 (&#39;corridor&#39;, 1916),
 (&#39;complimentary&#39;, 1916),
 (&#39;fixed&#39;, 1913),
 (&#39;cooked&#39;, 1912),
 (&#39;amount&#39;, 1911),
 (&#39;restaurants&#39;, 1905),
 (&#39;issues&#39;, 1898),
 (&#39;site&#39;, 1897),
 (&#39;8&#39;, 1890),
 (&#39;seem&#39;, 1889),
 (&#39;middle&#39;, 1885),
 (&#39;information&#39;, 1882),
 (&#39;otherwise&#39;, 1878),
 (&#39;smoking&#39;, 1876),
 (&#39;opened&#39;, 1872),
 (&#39;superior&#39;, 1872),
 (&#39;paris&#39;, 1871),
 (&#39;using&#39;, 1869),
 (&#39;turned&#39;, 1862),
 (&#39;airport&#39;, 1858),
 (&#39;annoying&#39;, 1857),
 (&#39;set&#39;, 1855),
 (&#39;selection&#39;, 1853),
 (&#39;lots&#39;, 1849),
 (&#39;kind&#39;, 1848),
 (&#39;executive&#39;, 1842),
 (&#39;iron&#39;, 1840),
 (&#39;mins&#39;, 1840),
 (&#39;ground&#39;, 1835),
 (&#39;safe&#39;, 1831),
 (&#39;upon&#39;, 1829),
 (&#39;deposit&#39;, 1821),
 (&#39;part&#39;, 1820),
 (&#39;own&#39;, 1817),
 (&#39;four&#39;, 1814),
 (&#39;lady&#39;, 1814),
 (&#39;website&#39;, 1795),
 (&#39;sometimes&#39;, 1787),
 (&#39;informed&#39;, 1782),
 (&#39;traffic&#39;, 1781),
 (&#39;curtains&#39;, 1773),
 (&#39;channels&#39;, 1767),
 (&#39;rest&#39;, 1766),
 (&#39;trying&#39;, 1765),
 (&#39;might&#39;, 1759),
 (&#39;roof&#39;, 1757),
 (&#39;mirror&#39;, 1753),
 (&#39;renovation&#39;, 1753),
 (&#39;items&#39;, 1751),
 (&#39;absolutely&#39;, 1750),
 (&#39;bill&#39;, 1745),
 (&#39;corridors&#39;, 1743),
 (&#39;cannot&#39;, 1736),
 (&#39;easy&#39;, 1731),
 (&#39;trip&#39;, 1728),
 (&#39;located&#39;, 1719),
 (&#39;longer&#39;, 1706),
 (&#39;taken&#39;, 1698),
 (&#39;worn&#39;, 1684),
 (&#39;places&#39;, 1662),
 (&#39;now&#39;, 1660),
 (&#39;isn&#39;, 1656),
 (&#39;complaints&#39;, 1655),
 (&#39;special&#39;, 1654),
 (&#39;provide&#39;, 1650),
 (&#39;deal&#39;, 1646),
 (&#39;control&#39;, 1645),
 (&#39;tube&#39;, 1642),
 (&#39;public&#39;, 1641),
 (&#39;possible&#39;, 1639),
 (&#39;complained&#39;, 1635),
 (&#39;seems&#39;, 1634),
 (&#39;upgraded&#39;, 1631),
 (&#39;reservation&#39;, 1627),
 (&#39;plug&#39;, 1623),
 (&#39;strange&#39;, 1622),
 (&#39;sit&#39;, 1616),
 (&#39;pictures&#39;, 1615),
 (&#39;tables&#39;, 1614),
 (&#39;leaving&#39;, 1612),
 (&#39;missing&#39;, 1611),
 (&#39;cheap&#39;, 1611),
 (&#39;must&#39;, 1602),
 (&#39;floors&#39;, 1596),
 (&#39;priced&#39;, 1595),
 (&#39;real&#39;, 1585),
 (&#39;his&#39;, 1583),
 (&#39;run&#39;, 1581),
 (&#39;empty&#39;, 1565),
 (&#39;concierge&#39;, 1564),
 (&#39;facility&#39;, 1558),
 (&#39;negative&#39;, 1553),
 (&#39;looks&#39;, 1553),
 (&#39;fire&#39;, 1539),
 (&#39;sleeping&#39;, 1538),
 (&#39;carpets&#39;, 1536),
 (&#39;horrible&#39;, 1535),
 (&#39;try&#39;, 1534),
 (&#39;across&#39;, 1532),
 (&#39;worked&#39;, 1529),
 (&#39;e&#39;, 1519),
 (&#39;paper&#39;, 1519),
 (&#39;house&#39;, 1517),
 (&#39;areas&#39;, 1515),
 (&#39;number&#39;, 1514),
 (&#39;music&#39;, 1513),
 (&#39;asking&#39;, 1510),
 (&#39;cleanliness&#39;, 1503),
 (&#39;wardrobe&#39;, 1499),
 (&#39;except&#39;, 1494),
 (&#39;till&#39;, 1491),
 (&#39;payment&#39;, 1487),
 (&#39;cool&#39;, 1486),
 (&#39;minibar&#39;, 1485),
 (&#39;dining&#39;, 1485),
 (&#39;stop&#39;, 1484),
 (&#39;stuff&#39;, 1483),
 (&#39;case&#39;, 1483),
 (&#39;works&#39;, 1482),
 (&#39;tram&#39;, 1481),
 (&#39;considering&#39;, 1480),
 (&#39;alarm&#39;, 1478),
 (&#39;bathrooms&#39;, 1476),
 (&#39;mentioned&#39;, 1475),
 (&#39;taking&#39;, 1471),
 (&#39;checkout&#39;, 1470),
 (&#39;club&#39;, 1467),
 (&#39;reason&#39;, 1465),
 (&#39;maintenance&#39;, 1463),
 (&#39;weekend&#39;, 1460),
 (&#39;impossible&#39;, 1460),
 (&#39;sign&#39;, 1459),
 (&#39;c&#39;, 1458),
 (&#39;children&#39;, 1456),
 (&#39;meal&#39;, 1456),
 (&#39;balcony&#39;, 1453),
 (&#39;return&#39;, 1452),
 (&#39;visit&#39;, 1451),
 (&#39;unable&#39;, 1450),
 (&#39;perhaps&#39;, 1449),
 (&#39;narrow&#39;, 1448),
 (&#39;apart&#39;, 1443),
 (&#39;9&#39;, 1442),
 (&#39;property&#39;, 1435),
 (&#39;received&#39;, 1432),
 (&#39;facing&#39;, 1431),
 (&#39;clear&#39;, 1430),
 (&#39;conditioner&#39;, 1429),
 (&#39;towel&#39;, 1428),
 (&#39;plus&#39;, 1419),
 (&#39;bus&#39;, 1416),
 (&#39;sheets&#39;, 1414),
 (&#39;advertised&#39;, 1413),
 (&#39;attitude&#39;, 1412),
 (&#39;shame&#39;, 1409),
 (&#39;yet&#39;, 1403),
 (&#39;sofa&#39;, 1403),
 (&#39;normal&#39;, 1403),
 (&#39;cheaper&#39;, 1401),
 (&#39;ended&#39;, 1400),
 (&#39;toiletries&#39;, 1393),
 (&#39;completely&#39;, 1390),
 (&#39;waited&#39;, 1389),
 (&#39;below&#39;, 1385),
 (&#39;pm&#39;, 1379),
 (&#39;fix&#39;, 1374),
 (&#39;chair&#39;, 1371),
 (&#39;clothes&#39;, 1369),
 (&#39;deluxe&#39;, 1368),
 (&#39;variety&#39;, 1368),
 (&#39;clearly&#39;, 1366),
 (&#39;cups&#39;, 1365),
 (&#39;those&#39;, 1364),
 (&#39;smoke&#39;, 1362),
 (&#39;25&#39;, 1361),
 (&#39;condition&#39;, 1355),
 (&#39;king&#39;, 1351),
 (&#39;year&#39;, 1347),
 (&#39;wet&#39;, 1346),
 (&#39;huge&#39;, 1345),
 (&#39;particularly&#39;, 1345),
 (&#39;itself&#39;, 1344),
 (&#39;aircon&#39;, 1344),
 (&#39;hilton&#39;, 1341),
 (&#39;heard&#39;, 1338),
 (&#39;design&#39;, 1337),
 (&#39;separate&#39;, 1336),
 (&#39;hand&#39;, 1336),
 (&#39;queue&#39;, 1336),
 (&#39;replaced&#39;, 1335),
 (&#39;finally&#39;, 1327),
 (&#39;amsterdam&#39;, 1321),
 (&#39;customers&#39;, 1316),
 (&#39;additional&#39;, 1316),
 (&#39;wish&#39;, 1312),
 (&#39;complaint&#39;, 1311),
 (&#39;seen&#39;, 1308),
 (&#39;care&#39;, 1307),
 (&#39;travel&#39;, 1300),
 (&#39;slippers&#39;, 1294),
 (&#39;previous&#39;, 1291),
 (&#39;years&#39;, 1291),
 (&#39;within&#39;, 1289),
 (&#39;ceiling&#39;, 1287),
 (&#39;services&#39;, 1284),
 (&#39;advance&#39;, 1283),
 (&#39;start&#39;, 1278),
 (&#39;kitchen&#39;, 1278),
 (&#39;min&#39;, 1276),
 (&#39;pressure&#39;, 1276),
 (&#39;sunday&#39;, 1273),
 (&#39;whilst&#39;, 1272),
 (&#39;larger&#39;, 1271),
 (&#39;unfriendly&#39;, 1270),
 (&#39;pillow&#39;, 1267),
 (&#39;compared&#39;, 1266),
 (&#39;privacy&#39;, 1264),
 (&#39;distance&#39;, 1263),
 (&#39;minute&#39;, 1259),
 (&#39;continental&#39;, 1252),
 (&#39;cleaner&#39;, 1251),
 (&#39;terrace&#39;, 1246),
 (&#39;tell&#39;, 1244),
 (&#39;unhelpful&#39;, 1241),
 (&#39;please&#39;, 1240),
 (&#39;week&#39;, 1240),
 (&#39;general&#39;, 1238),
 (&#39;bring&#39;, 1233),
 (&#39;woke&#39;, 1231),
 (&#39;wine&#39;, 1230),
 (&#39;tight&#39;, 1226),
 (&#39;wife&#39;, 1224),
 (&#39;weak&#39;, 1223),
 (&#39;management&#39;, 1222),
 (&#39;soap&#39;, 1220),
 (&#39;anyone&#39;, 1217),
 (&#39;running&#39;, 1216),
 (&#39;improved&#39;, 1209),
 (&#39;totally&#39;, 1208),
 (&#39;line&#39;, 1207),
 (&#39;bacon&#39;, 1202),
 (&#39;him&#39;, 1199),
 (&#39;aware&#39;, 1199),
 (&#39;proper&#39;, 1199),
 (&#39;11&#39;, 1196),
 (&#39;hardly&#39;, 1192),
 (&#39;attention&#39;, 1192),
 (&#39;sauna&#39;, 1182),
 (&#39;guess&#39;, 1176),
 (&#39;fully&#39;, 1175),
 (&#39;lower&#39;, 1175),
 (&#39;home&#39;, 1173),
 (&#39;pleasant&#39;, 1173),
 (&#39;cup&#39;, 1173),
 (&#39;behind&#39;, 1166),
 (&#39;24&#39;, 1163),
 (&#39;tub&#39;, 1158),
 (&#39;returned&#39;, 1157),
 (&#39;kids&#39;, 1156),
 (&#39;dislike&#39;, 1155),
 (&#39;type&#39;, 1153),
 (&#39;local&#39;, 1150),
 (&#39;underground&#39;, 1146),
 (&#39;quickly&#39;, 1141),
 (&#39;shabby&#39;, 1140),
 (&#39;man&#39;, 1137),
 (&#39;refund&#39;, 1136),
 (&#39;pushed&#39;, 1136),
 (&#39;show&#39;, 1135),
 (&#39;name&#39;, 1134),
 (&#39;modern&#39;, 1133),
 (&#39;others&#39;, 1132),
 (&#39;100&#39;, 1129),
 (&#39;bread&#39;, 1128),
 (&#39;partner&#39;, 1127),
 (&#39;corner&#39;, 1123),
 (&#39;loved&#39;, 1121),
 (&#39;fit&#39;, 1118),
 (&#39;higher&#39;, 1118),
 (&#39;wash&#39;, 1118),
 (&#39;major&#39;, 1116),
 (&#39;doing&#39;, 1116),
 (&#39;security&#39;, 1113),
 (&#39;heat&#39;, 1112),
 (&#39;curtain&#39;, 1111),
 (&#39;shampoo&#39;, 1109),
 (&#39;barely&#39;, 1108),
 (&#39;arrive&#39;, 1107),
 (&#39;happened&#39;, 1106),
 (&#39;refurbishment&#39;, 1104),
 (&#39;unless&#39;, 1104),
 (&#39;crowded&#39;, 1099),
 (&#39;outdated&#39;, 1099),
 (&#39;myself&#39;, 1098),
 (&#39;sort&#39;, 1090),
 (&#39;saturday&#39;, 1090),
 (&#39;elevators&#39;, 1088),
 (&#39;dust&#39;, 1088),
 (&#39;everywhere&#39;, 1087),
 (&#39;personal&#39;, 1087),
 (&#39;fruit&#39;, 1084),
 (&#39;mind&#39;, 1078),
 (&#39;onto&#39;, 1076),
 (&#39;super&#39;, 1075),
 (&#39;opening&#39;, 1074),
 (&#39;therefore&#39;, 1074),
 (&#39;woken&#39;, 1070),
 (&#39;bother&#39;, 1068),
 (&#39;email&#39;, 1068),
 (&#39;sent&#39;, 1060),
 (&#39;speak&#39;, 1059),
 (&#39;glasses&#39;, 1057),
 (&#39;brought&#39;, 1057),
 (&#39;signal&#39;, 1057),
 (&#39;downstairs&#39;, 1055),
 (&#39;photos&#39;, 1054),
 (&#39;charges&#39;, 1054),
 (&#39;talking&#39;, 1052),
 (&#39;pounds&#39;, 1051),
 (&#39;makes&#39;, 1050),
 (&#39;directly&#39;, 1049),
 (&#39;box&#39;, 1047),
 (&#39;party&#39;, 1045),
 (&#39;wasnt&#39;, 1044),
 (&#39;easily&#39;, 1040),
 (&#39;style&#39;, 1040),
 (&#39;40&#39;, 1035),
 (&#39;hadn&#39;, 1030),
 (&#39;started&#39;, 1026),
 (&#39;blocked&#39;, 1026),
 (&#39;dont&#39;, 1025),
 (&#39;friends&#39;, 1022),
 (&#39;shut&#39;, 1021),
 (&#39;welcome&#39;, 1021),
 (&#39;stains&#39;, 1016),
 (&#39;keeping&#39;, 1015),
 (&#39;hairdryer&#39;, 1014),
 (&#39;often&#39;, 1014),
 (&#39;guy&#39;, 1014),
 (&#39;refused&#39;, 1010),
 (&#39;spent&#39;, 1009),
 (&#39;welcoming&#39;, 1009),
 (&#39;believe&#39;, 1008),
 (&#39;saying&#39;, 1005),
 (&#39;young&#39;, 1000),
 (&#39;smelt&#39;, 999),
 (&#39;comfort&#39;, 997),
 (&#39;husband&#39;, 996),
 (&#39;mention&#39;, 994),
 (&#39;poorly&#39;, 994),
 (&#39;smelled&#39;, 994),
 (&#39;heater&#39;, 994),
 (&#39;ventilation&#39;, 991),
 (&#39;forgot&#39;, 990),
 (&#39;saw&#39;, 989),
 (&#39;account&#39;, 986),
 (&#39;weather&#39;, 983),
 (&#39;answer&#39;, 982),
 (&#39;u&#39;, 982),
 (&#39;town&#39;, 980),
 (&#39;stained&#39;, 976),
 (&#39;dry&#39;, 974),
 (&#39;heavy&#39;, 970),
 (&#39;obviously&#39;, 970),
 (&#39;throughout&#39;, 969),
 (&#39;walked&#39;, 967),
 (&#39;lost&#39;, 966),
 (&#39;amazing&#39;, 961),
 (&#39;ridiculous&#39;, 961),
 (&#39;amenities&#39;, 961),
 (&#39;third&#39;, 960),
 (&#39;afternoon&#39;, 960),
 (&#39;dusty&#39;, 959),
 (&#39;stuffy&#39;, 956),
 (&#39;duvet&#39;, 955),
 (&#39;drain&#39;, 954),
 (&#39;black&#39;, 954),
 (&#39;further&#39;, 950),
 (&#39;pre&#39;, 950),
 (&#39;badly&#39;, 947),
 (&#39;past&#39;, 947),
 (&#39;via&#39;, 945),
 (&#39;immediately&#39;, 943),
 (&#39;allowed&#39;, 943),
 (&#39;everyone&#39;, 940),
 (&#39;cash&#39;, 939),
 (&#39;details&#39;, 937),
 (&#39;daily&#39;, 934),
 (&#39;unpleasant&#39;, 931),
 (&#39;reach&#39;, 931),
 (&#39;midnight&#39;, 930),
 (&#39;travelling&#39;, 930),
 (&#39;power&#39;, 924),
 (&#39;anyway&#39;, 922),
 (&#39;switch&#39;, 922),
 (&#39;adequate&#39;, 921),
 (&#39;2nd&#39;, 919),
 (&#39;won&#39;, 918),
 (&#39;missed&#39;, 917),
 (&#39;simple&#39;, 913),
 (&#39;bag&#39;, 911),
 (&#39;required&#39;, 911),
 (&#39;ideal&#39;, 909),
 (&#39;flight&#39;, 909),
 (&#39;shuttle&#39;, 908),
 (&#39;takes&#39;, 907),
 (&#39;enjoy&#39;, 905),
 (&#39;bathtub&#39;, 903),
 (&#39;supposed&#39;, 903),
 (&#39;nor&#39;, 900),
 (&#39;comfy&#39;, 899),
 (&#39;choices&#39;, 899),
 (&#39;bottles&#39;, 898),
 (&#39;updating&#39;, 896),
 (&#39;fair&#39;, 896),
 (&#39;certainly&#39;, 896),
 (&#39;odd&#39;, 890),
 (&#39;acceptable&#39;, 888),
 (&#39;ones&#39;, 886),
 (&#39;cover&#39;, 884),
 (&#39;earlier&#39;, 884),
 (&#39;opposite&#39;, 883),
 (&#39;transport&#39;, 882),
 (&#39;entire&#39;, 881),
 (&#39;holiday&#39;, 877),
 (&#39;five&#39;, 876),
 (&#39;awkward&#39;, 875),
 (&#39;scrambled&#39;, 871),
 (&#39;added&#39;, 871),
 (&#39;disabled&#39;, 870),
 (&#39;generally&#39;, 867),
 (&#39;avoid&#39;, 865),
 (&#39;add&#39;, 865),
 (&#39;tap&#39;, 863),
 (&#39;buy&#39;, 862),
 (&#39;preferred&#39;, 862),
 ...]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">total_counts</span><span class="o">.</span><span class="n">most_common</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[13]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[(&#39;&#39;, 1358561),
 (&#39;the&#39;, 1045673),
 (&#39;and&#39;, 639524),
 (&#39;was&#39;, 473104),
 (&#39;to&#39;, 416438),
 (&#39;a&#39;, 394856),
 (&#39;room&#39;, 316449),
 (&#39;in&#39;, 281710),
 (&#39;very&#39;, 273046),
 (&#39;no&#39;, 242756),
 (&#39;staff&#39;, 233853),
 (&#39;of&#39;, 227201),
 (&#39;for&#39;, 208503),
 (&#39;location&#39;, 203640),
 (&#39;hotel&#39;, 199839),
 (&#39;is&#39;, 184424),
 (&#39;i&#39;, 183344),
 (&#39;we&#39;, 168052),
 (&#39;it&#39;, 164566),
 (&#39;were&#39;, 152430),
 (&#39;not&#39;, 148879),
 (&#39;breakfast&#39;, 142934),
 (&#39;good&#39;, 132989),
 (&#39;negative&#39;, 129548),
 (&#39;with&#39;, 117820),
 (&#39;great&#39;, 115496),
 (&#39;but&#39;, 107465),
 (&#39;on&#39;, 104209),
 (&#39;at&#39;, 98097),
 (&#39;friendly&#39;, 89904),
 (&#39;t&#39;, 89694),
 (&#39;had&#39;, 88122),
 (&#39;from&#39;, 83957),
 (&#39;helpful&#39;, 80480),
 (&#39;bed&#39;, 79692),
 (&#39;nice&#39;, 79256),
 (&#39;that&#39;, 79100),
 (&#39;clean&#39;, 75347),
 (&#39;rooms&#39;, 75093),
 (&#39;have&#39;, 74755),
 (&#39;you&#39;, 73027),
 (&#39;as&#39;, 71170),
 (&#39;there&#39;, 67319),
 (&#39;this&#39;, 67276),
 (&#39;so&#39;, 66914),
 (&#39;our&#39;, 65650),
 (&#39;comfortable&#39;, 65433),
 (&#39;excellent&#39;, 64586),
 (&#39;all&#39;, 63614),
 (&#39;my&#39;, 61898),
 (&#39;are&#39;, 61716),
 (&#39;small&#39;, 61479),
 (&#39;they&#39;, 61442),
 (&#39;be&#39;, 60113),
 (&#39;would&#39;, 50431),
 (&#39;stay&#39;, 49417),
 (&#39;nothing&#39;, 45374),
 (&#39;service&#39;, 45104),
 (&#39;really&#39;, 44737),
 (&#39;bathroom&#39;, 43973),
 (&#39;which&#39;, 43640),
 (&#39;out&#39;, 42103),
 (&#39;could&#39;, 41398),
 (&#39;when&#39;, 41241),
 (&#39;one&#39;, 39714),
 (&#39;too&#39;, 39620),
 (&#39;us&#39;, 38720),
 (&#39;bar&#39;, 38679),
 (&#39;only&#39;, 37926),
 (&#39;lovely&#39;, 37413),
 (&#39;an&#39;, 36773),
 (&#39;everything&#39;, 36747),
 (&#39;positive&#39;, 36680),
 (&#39;close&#39;, 36169),
 (&#39;s&#39;, 34991),
 (&#39;also&#39;, 34126),
 (&#39;shower&#39;, 34005),
 (&#39;like&#39;, 33819),
 (&#39;station&#39;, 33470),
 (&#39;night&#39;, 33168),
 (&#39;just&#39;, 32821),
 (&#39;reception&#39;, 32507),
 (&#39;if&#39;, 31943),
 (&#39;well&#39;, 31736),
 (&#39;bit&#39;, 31515),
 (&#39;didn&#39;, 31313),
 (&#39;or&#39;, 30169),
 (&#39;little&#39;, 29939),
 (&#39;get&#39;, 29222),
 (&#39;perfect&#39;, 29134),
 (&#39;more&#39;, 28607),
 (&#39;by&#39;, 28300),
 (&#39;food&#39;, 27790),
 (&#39;time&#39;, 27285),
 (&#39;view&#39;, 27200),
 (&#39;area&#39;, 26720),
 (&#39;me&#39;, 26425),
 (&#39;walk&#39;, 26404),
 (&#39;check&#39;, 26157),
 (&#39;up&#39;, 25536),
 (&#39;been&#39;, 25460),
 (&#39;did&#39;, 24676),
 (&#39;day&#39;, 24290),
 (&#39;quiet&#39;, 23990),
 (&#39;price&#39;, 23954),
 (&#39;restaurant&#39;, 23902),
 (&#39;facilities&#39;, 23866),
 (&#39;can&#39;, 23864),
 (&#39;free&#39;, 23487),
 (&#39;even&#39;, 23336),
 (&#39;amazing&#39;, 22598),
 (&#39;coffee&#39;, 22326),
 (&#39;london&#39;, 22279),
 (&#39;beds&#39;, 22244),
 (&#39;comfy&#39;, 22240),
 (&#39;some&#39;, 22062),
 (&#39;about&#39;, 22054),
 (&#39;again&#39;, 21903),
 (&#39;floor&#39;, 21325),
 (&#39;city&#39;, 21095),
 (&#39;2&#39;, 20920),
 (&#39;next&#39;, 19862),
 (&#39;wifi&#39;, 19847),
 (&#39;water&#39;, 19619),
 (&#39;after&#39;, 19564),
 (&#39;much&#39;, 19420),
 (&#39;quite&#39;, 19041),
 (&#39;expensive&#39;, 18836),
 (&#39;will&#39;, 18690),
 (&#39;metro&#39;, 18591),
 (&#39;back&#39;, 18454),
 (&#39;than&#39;, 18181),
 (&#39;modern&#39;, 18009),
 (&#39;other&#39;, 17932),
 (&#39;made&#39;, 17334),
 (&#39;size&#39;, 17142),
 (&#39;big&#39;, 17047),
 (&#39;poor&#39;, 16891),
 (&#39;air&#39;, 16663),
 (&#39;fantastic&#39;, 16641),
 (&#39;what&#39;, 16558),
 (&#39;place&#39;, 16545),
 (&#39;easy&#39;, 16499),
 (&#39;better&#39;, 16362),
 (&#39;around&#39;, 16312),
 (&#39;door&#39;, 16310),
 (&#39;near&#39;, 16212),
 (&#39;pool&#39;, 16153),
 (&#39;spacious&#39;, 16093),
 (&#39;money&#39;, 16047),
 (&#39;central&#39;, 15914),
 (&#39;extremely&#39;, 15880),
 (&#39;two&#39;, 15815),
 (&#39;wasn&#39;, 15763),
 (&#39;stayed&#39;, 15704),
 (&#39;hot&#39;, 15652),
 (&#39;got&#39;, 15606),
 (&#39;5&#39;, 15557),
 (&#39;do&#39;, 15474),
 (&#39;noisy&#39;, 15058),
 (&#39;work&#39;, 14940),
 (&#39;value&#39;, 14903),
 (&#39;beautiful&#39;, 14776),
 (&#39;tea&#39;, 14725),
 (&#39;restaurants&#39;, 14709),
 (&#39;old&#39;, 14640),
 (&#39;parking&#39;, 14623),
 (&#39;noise&#39;, 14489),
 (&#39;booking&#39;, 14384),
 (&#39;best&#39;, 14202),
 (&#39;first&#39;, 14191),
 (&#39;street&#39;, 14134),
 (&#39;minutes&#39;, 14086),
 (&#39;need&#39;, 14030),
 (&#39;your&#39;, 13893),
 (&#39;front&#39;, 13886),
 (&#39;loved&#39;, 13877),
 (&#39;people&#39;, 13835),
 (&#39;go&#39;, 13808),
 (&#39;over&#39;, 13756),
 (&#39;walking&#39;, 13739),
 (&#39;3&#39;, 13619),
 (&#39;enough&#39;, 13588),
 (&#39;4&#39;, 13541),
 (&#39;booked&#39;, 13515),
 (&#39;extra&#39;, 13227),
 (&#39;asked&#39;, 13216),
 (&#39;use&#39;, 13134),
 (&#39;tube&#39;, 13132),
 (&#39;away&#39;, 13018),
 (&#39;morning&#39;, 12962),
 (&#39;every&#39;, 12840),
 (&#39;any&#39;, 12774),
 (&#39;outside&#39;, 12600),
 (&#39;has&#39;, 12339),
 (&#39;being&#39;, 12298),
 (&#39;large&#39;, 12293),
 (&#39;definitely&#39;, 12288),
 (&#39;off&#39;, 12208),
 (&#39;right&#39;, 12198),
 (&#39;bad&#39;, 12000),
 (&#39;quality&#39;, 11989),
 (&#39;couldn&#39;, 11880),
 (&#39;far&#39;, 11874),
 (&#39;because&#39;, 11842),
 (&#39;desk&#39;, 11826),
 (&#39;should&#39;, 11817),
 (&#39;double&#39;, 11756),
 (&#39;window&#39;, 11659),
 (&#39;here&#39;, 11606),
 (&#39;10&#39;, 11513),
 (&#39;them&#39;, 11505),
 (&#39;cold&#39;, 11340),
 (&#39;way&#39;, 11309),
 (&#39;where&#39;, 11222),
 (&#39;told&#39;, 11055),
 (&#39;most&#39;, 11053),
 (&#39;down&#39;, 10937),
 (&#39;tv&#39;, 10927),
 (&#39;always&#39;, 10866),
 (&#39;centre&#39;, 10838),
 (&#39;their&#39;, 10788),
 (&#39;recommend&#39;, 10786),
 (&#39;bath&#39;, 10770),
 (&#39;train&#39;, 10722),
 (&#39;distance&#39;, 10640),
 (&#39;before&#39;, 10633),
 (&#39;open&#39;, 10552),
 (&#39;access&#39;, 10551),
 (&#39;many&#39;, 10515),
 (&#39;hotels&#39;, 10473),
 (&#39;who&#39;, 10398),
 (&#39;though&#39;, 10387),
 (&#39;super&#39;, 10374),
 (&#39;into&#39;, 10311),
 (&#39;available&#39;, 10308),
 (&#39;choice&#39;, 10278),
 (&#39;especially&#39;, 10274),
 (&#39;wonderful&#39;, 10246),
 (&#39;then&#39;, 10246),
 (&#39;convenient&#39;, 10173),
 (&#39;high&#39;, 10009),
 (&#39;park&#39;, 10003),
 (&#39;although&#39;, 9977),
 (&#39;liked&#39;, 9962),
 (&#39;make&#39;, 9734),
 (&#39;space&#39;, 9725),
 (&#39;sleep&#39;, 9719),
 (&#39;pay&#39;, 9670),
 (&#39;feel&#39;, 9644),
 (&#39;star&#39;, 9610),
 (&#39;find&#39;, 9599),
 (&#39;early&#39;, 9585),
 (&#39;located&#39;, 9584),
 (&#39;pleasant&#39;, 9560),
 (&#39;decor&#39;, 9460),
 (&#39;lot&#39;, 9435),
 (&#39;needed&#39;, 9388),
 (&#39;1&#39;, 9275),
 (&#39;few&#39;, 9250),
 (&#39;don&#39;, 9233),
 (&#39;building&#39;, 9167),
 (&#39;pillows&#39;, 9162),
 (&#39;still&#39;, 9127),
 (&#39;center&#39;, 9107),
 (&#39;went&#39;, 9086),
 (&#39;etc&#39;, 9080),
 (&#39;arrived&#39;, 9027),
 (&#39;working&#39;, 9027),
 (&#39;warm&#39;, 8983),
 (&#39;experience&#39;, 8941),
 (&#39;top&#39;, 8872),
 (&#39;paid&#39;, 8857),
 (&#39;long&#39;, 8826),
 (&#39;help&#39;, 8796),
 (&#39;new&#39;, 8784),
 (&#39;welcoming&#39;, 8673),
 (&#39;during&#39;, 8654),
 (&#39;arrival&#39;, 8623),
 (&#39;problem&#39;, 8611),
 (&#39;however&#39;, 8562),
 (&#39;given&#39;, 8551),
 (&#39;lobby&#39;, 8514),
 (&#39;overall&#39;, 8488),
 (&#39;its&#39;, 8478),
 (&#39;ok&#39;, 8466),
 (&#39;standard&#39;, 8418),
 (&#39;times&#39;, 8396),
 (&#39;bedroom&#39;, 8395),
 (&#39;thing&#39;, 8315),
 (&#39;polite&#39;, 8214),
 (&#39;left&#39;, 8186),
 (&#39;main&#39;, 8151),
 (&#39;felt&#39;, 8064),
 (&#39;having&#39;, 8043),
 (&#39;included&#39;, 7963),
 (&#39;never&#39;, 7954),
 (&#39;think&#39;, 7950),
 (&#39;buffet&#39;, 7942),
 (&#39;toilet&#39;, 7938),
 (&#39;hard&#39;, 7924),
 (&#39;without&#39;, 7924),
 (&#39;late&#39;, 7873),
 (&#39;needs&#39;, 7853),
 (&#39;took&#39;, 7808),
 (&#39;design&#39;, 7791),
 (&#39;same&#39;, 7708),
 (&#39;he&#39;, 7691),
 (&#39;take&#39;, 7690),
 (&#39;bus&#39;, 7645),
 (&#39;drinks&#39;, 7611),
 (&#39;guests&#39;, 7580),
 (&#39;kind&#39;, 7554),
 (&#39;see&#39;, 7546),
 (&#39;tiny&#39;, 7542),
 (&#39;spa&#39;, 7462),
 (&#39;paris&#39;, 7446),
 (&#39;lots&#39;, 7434),
 (&#39;windows&#39;, 7400),
 (&#39;days&#39;, 7386),
 (&#39;found&#39;, 7377),
 (&#39;said&#39;, 7369),
 (&#39;slow&#39;, 7305),
 (&#39;tram&#39;, 7300),
 (&#39;going&#39;, 7271),
 (&#39;another&#39;, 7243),
 (&#39;put&#39;, 7209),
 (&#39;suite&#39;, 7144),
 (&#39;nearby&#39;, 7096),
 (&#39;within&#39;, 7058),
 (&#39;conditioning&#39;, 7052),
 (&#39;car&#39;, 7050),
 (&#39;side&#39;, 6992),
 (&#39;underground&#39;, 6974),
 (&#39;come&#39;, 6970),
 (&#39;airport&#39;, 6960),
 (&#39;upgrade&#39;, 6941),
 (&#39;short&#39;, 6934),
 (&#39;evening&#39;, 6906),
 (&#39;want&#39;, 6887),
 (&#39;single&#39;, 6879),
 (&#39;fresh&#39;, 6845),
 (&#39;english&#39;, 6838),
 (&#39;how&#39;, 6835),
 (&#39;lift&#39;, 6807),
 (&#39;ask&#39;, 6767),
 (&#39;charge&#39;, 6764),
 (&#39;nights&#39;, 6732),
 (&#39;card&#39;, 6729),
 (&#39;ever&#39;, 6726),
 (&#39;cleanliness&#39;, 6723),
 (&#39;full&#39;, 6678),
 (&#39;anything&#39;, 6649),
 (&#39;upgraded&#39;, 6627),
 (&#39;towels&#39;, 6568),
 (&#39;staying&#39;, 6547),
 (&#39;lounge&#39;, 6526),
 (&#39;dirty&#39;, 6494),
 (&#39;minute&#39;, 6436),
 (&#39;shopping&#39;, 6429),
 (&#39;superb&#39;, 6418),
 (&#39;such&#39;, 6416),
 (&#39;welcome&#39;, 6398),
 (&#39;ve&#39;, 6369),
 (&#39;while&#39;, 6351),
 (&#39;road&#39;, 6336),
 (&#39;due&#39;, 6309),
 (&#39;gave&#39;, 6286),
 (&#39;15&#39;, 6273),
 (&#39;both&#39;, 6271),
 (&#39;light&#39;, 6268),
 (&#39;views&#39;, 6233),
 (&#39;visit&#39;, 6221),
 (&#39;rather&#39;, 6146),
 (&#39;she&#39;, 6116),
 (&#39;professional&#39;, 6112),
 (&#39;through&#39;, 6084),
 (&#39;expected&#39;, 6079),
 (&#39;came&#39;, 6017),
 (&#39;happy&#39;, 6015),
 (&#39;brilliant&#39;, 5988),
 (&#39;provided&#39;, 5988),
 (&#39;wanted&#39;, 5982),
 (&#39;wait&#39;, 5974),
 (&#39;special&#39;, 5900),
 (&#39;cost&#39;, 5897),
 (&#39;busy&#39;, 5874),
 (&#39;comfort&#39;, 5870),
 (&#39;selection&#39;, 5864),
 (&#39;am&#39;, 5864),
 (&#39;attentive&#39;, 5858),
 (&#39;public&#39;, 5834),
 (&#39;complimentary&#39;, 5828),
 (&#39;uncomfortable&#39;, 5822),
 (&#39;offered&#39;, 5807),
 (&#39;each&#39;, 5781),
 (&#39;30&#39;, 5765),
 (&#39;things&#39;, 5760),
 (&#39;worth&#39;, 5759),
 (&#39;until&#39;, 5749),
 (&#39;transport&#39;, 5738),
 (&#39;cleaning&#39;, 5704),
 (&#39;luggage&#39;, 5686),
 (&#39;hear&#39;, 5681),
 (&#39;second&#39;, 5681),
 (&#39;enjoyed&#39;, 5678),
 (&#39;internet&#39;, 5668),
 (&#39;used&#39;, 5663),
 (&#39;stop&#39;, 5661),
 (&#39;making&#39;, 5630),
 (&#39;atmosphere&#39;, 5620),
 (&#39;concierge&#39;, 5552),
 (&#39;able&#39;, 5538),
 (&#39;mini&#39;, 5537),
 (&#39;gym&#39;, 5537),
 (&#39;efficient&#39;, 5531),
 (&#39;looked&#39;, 5528),
 (&#39;min&#39;, 5528),
 (&#39;20&#39;, 5507),
 (&#39;amsterdam&#39;, 5483),
 (&#39;person&#39;, 5470),
 (&#39;absolutely&#39;, 5463),
 (&#39;places&#39;, 5457),
 (&#39;taxi&#39;, 5449),
 (&#39;know&#39;, 5444),
 (&#39;com&#39;, 5440),
 (&#39;per&#39;, 5427),
 (&#39;smell&#39;, 5424),
 (&#39;rude&#39;, 5410),
 (&#39;fine&#39;, 5389),
 (&#39;change&#39;, 5377),
 (&#39;machine&#39;, 5364),
 (&#39;say&#39;, 5335),
 (&#39;d&#39;, 5327),
 (&#39;birthday&#39;, 5323),
 (&#39;fridge&#39;, 5313),
 (&#39;shops&#39;, 5294),
 (&#39;tired&#39;, 5247),
 (&#39;checked&#39;, 5242),
 (&#39;eat&#39;, 5237),
 (&#39;receptionist&#39;, 5236),
 (&#39;family&#39;, 5204),
 (&#39;drink&#39;, 5193),
 (&#39;whole&#39;, 5182),
 (&#39;mins&#39;, 5151),
 (&#39;difficult&#39;, 5148),
 (&#39;hours&#39;, 5138),
 (&#39;plenty&#39;, 5134),
 (&#39;roof&#39;, 5120),
 (&#39;trip&#39;, 5117),
 (&#39;thought&#39;, 5091),
 (&#39;dinner&#39;, 5049),
 (&#39;ready&#39;, 5045),
 (&#39;huge&#39;, 5016),
 (&#39;look&#39;, 5012),
 (&#39;attractions&#39;, 5008),
 (&#39;sure&#39;, 4999),
 (&#39;different&#39;, 4912),
 (&#39;looking&#39;, 4911),
 (&#39;terrace&#39;, 4902),
 (&#39;fault&#39;, 4875),
 (&#39;pretty&#39;, 4860),
 (&#39;across&#39;, 4859),
 (&#39;business&#39;, 4840),
 (&#39;customer&#39;, 4837),
 (&#39;fabulous&#39;, 4820),
 (&#39;last&#39;, 4781),
 (&#39;end&#39;, 4778),
 (&#39;delicious&#39;, 4759),
 (&#39;charged&#39;, 4752),
 (&#39;limited&#39;, 4714),
 (&#39;getting&#39;, 4710),
 (&#39;manager&#39;, 4685),
 (&#39;kept&#39;, 4678),
 (&#39;dark&#39;, 4668),
 (&#39;safe&#39;, 4648),
 (&#39;love&#39;, 4642),
 (&#39;book&#39;, 4637),
 (&#39;m&#39;, 4630),
 (&#39;tower&#39;, 4623),
 (&#39;wall&#39;, 4610),
 (&#39;leave&#39;, 4607),
 (&#39;balcony&#39;, 4585),
 (&#39;hour&#39;, 4560),
 (&#39;issue&#39;, 4555),
 (&#39;cleaned&#39;, 4553),
 (&#39;table&#39;, 4526),
 (&#39;style&#39;, 4503),
 (&#39;return&#39;, 4490),
 (&#39;ideal&#39;, 4488),
 (&#39;stuff&#39;, 4487),
 (&#39;above&#39;, 4477),
 (&#39;re&#39;, 4474),
 (&#39;seemed&#39;, 4461),
 (&#39;areas&#39;, 4438),
 (&#39;order&#39;, 4415),
 (&#39;fact&#39;, 4413),
 (&#39;thank&#39;, 4398),
 (&#39;something&#39;, 4363),
 (&#39;broken&#39;, 4331),
 (&#39;phone&#39;, 4325),
 (&#39;menu&#39;, 4324),
 (&#39;couple&#39;, 4302),
 (&#39;highly&#39;, 4293),
 (&#39;barcelona&#39;, 4280),
 (&#39;closed&#39;, 4272),
 (&#39;furniture&#39;, 4247),
 (&#39;expect&#39;, 4229),
 (&#39;cool&#39;, 4179),
 (&#39;basic&#39;, 4174),
 (&#39;done&#39;, 4165),
 (&#39;con&#39;, 4150),
 (&#39;options&#39;, 4138),
 (&#39;offer&#39;, 4127),
 (&#39;touch&#39;, 4118),
 (&#39;variety&#39;, 4078),
 (&#39;soft&#39;, 4072),
 (&#39;properly&#39;, 4059),
 (&#39;inside&#39;, 4053),
 (&#39;heating&#39;, 4052),
 (&#39;almost&#39;, 4040),
 (&#39;her&#39;, 4028),
 (&#39;despite&#39;, 3978),
 (&#39;give&#39;, 3976),
 (&#39;swimming&#39;, 3975),
 (&#39;requested&#39;, 3973),
 (&#39;home&#39;, 3973),
 (&#39;elevator&#39;, 3961),
 (&#39;wi&#39;, 3939),
 (&#39;less&#39;, 3925),
 (&#39;bars&#39;, 3920),
 (&#39;bottle&#39;, 3914),
 (&#39;loud&#39;, 3910),
 (&#39;checking&#39;, 3900),
 (&#39;fi&#39;, 3890),
 (&#39;plus&#39;, 3875),
 (&#39;glass&#39;, 3829),
 (&#39;decorated&#39;, 3824),
 (&#39;walls&#39;, 3802),
 (&#39;eggs&#39;, 3785),
 (&#39;property&#39;, 3783),
 (&#39;executive&#39;, 3772),
 (&#39;call&#39;, 3766),
 (&#39;disappointed&#39;, 3761),
 (&#39;lack&#39;, 3735),
 (&#39;part&#39;, 3734),
 (&#39;position&#39;, 3732),
 (&#39;dated&#39;, 3731),
 (&#39;accommodating&#39;, 3709),
 (&#39;twin&#39;, 3699),
 (&#39;prices&#39;, 3688),
 (&#39;rooftop&#39;, 3678),
 (&#39;else&#39;, 3665),
 (&#39;amenities&#39;, 3664),
 (&#39;rate&#39;, 3659),
 (&#39;coming&#39;, 3649),
 (&#39;bigger&#39;, 3642),
 (&#39;terrible&#39;, 3638),
 (&#39;waiting&#39;, 3630),
 (&#39;between&#39;, 3628),
 (&#39;request&#39;, 3621),
 (&#39;under&#39;, 3609),
 (&#39;kettle&#39;, 3608),
 (&#39;system&#39;, 3600),
 (&#39;local&#39;, 3583),
 (&#39;maybe&#39;, 3582),
 (&#39;toiletries&#39;, 3568),
 (&#39;three&#39;, 3547),
 (&#39;entrance&#39;, 3541),
 (&#39;corner&#39;, 3537),
 (&#39;changed&#39;, 3506),
 (&#39;doors&#39;, 3496),
 (&#39;line&#39;, 3493),
 (&#39;disappointing&#39;, 3486),
 (&#39;once&#39;, 3485),
 (&#39;someone&#39;, 3479),
 (&#39;guest&#39;, 3473),
 (&#39;travel&#39;, 3464),
 (&#39;actually&#39;, 3461),
 (&#39;7&#39;, 3439),
 (&#39;lighting&#39;, 3436),
 (&#39;housekeeping&#39;, 3425),
 (&#39;served&#39;, 3411),
 (&#39;temperature&#39;, 3405),
 (&#39;sound&#39;, 3396),
 (&#39;let&#39;, 3389),
 (&#39;weekend&#39;, 3362),
 (&#39;euros&#39;, 3354),
 (&#39;wouldn&#39;, 3350),
 (&#39;decent&#39;, 3345),
 (&#39;carpet&#39;, 3342),
 (&#39;since&#39;, 3338),
 (&#39;slightly&#39;, 3336),
 (&#39;town&#39;, 3335),
 (&#39;stations&#39;, 3320),
 (&#39;several&#39;, 3317),
 (&#39;stairs&#39;, 3298),
 (&#39;mattress&#39;, 3289),
 (&#39;called&#39;, 3289),
 (&#39;instead&#39;, 3287),
 (&#39;move&#39;, 3272),
 (&#39;n&#39;, 3272),
 (&#39;why&#39;, 3260),
 (&#39;level&#39;, 3257),
 (&#39;tried&#39;, 3257),
 (&#39;6&#39;, 3254),
 (&#39;bags&#39;, 3233),
 (&#39;half&#39;, 3230),
 (&#39;milk&#39;, 3230),
 (&#39;itself&#39;, 3219),
 (&#39;vienna&#39;, 3219),
 (&#39;connection&#39;, 3209),
 (&#39;square&#39;, 3201),
 (&#39;lady&#39;, 3171),
 (&#39;real&#39;, 3165),
 (&#39;house&#39;, 3157),
 (&#39;worked&#39;, 3152),
 (&#39;interior&#39;, 3149),
 (&#39;member&#39;, 3148),
 (&#39;later&#39;, 3148),
 (&#39;twice&#39;, 3146),
 (&#39;cooked&#39;, 3136),
 (&#39;garden&#39;, 3132),
 (&#39;facility&#39;, 3130),
 (&#39;keep&#39;, 3117),
 (&#39;awesome&#39;, 3104),
 (&#39;middle&#39;, 3097),
 (&#39;either&#39;, 3078),
 (&#39;sink&#39;, 3077),
 (&#39;wine&#39;, 3076),
 (&#39;equipped&#39;, 3071),
 (&#39;50&#39;, 3063),
 (&#39;hair&#39;, 3051),
 (&#39;key&#39;, 3034),
 (&#39;euro&#39;, 3020),
 (&#39;none&#39;, 3018),
 (&#39;st&#39;, 3011),
 (&#39;cosy&#39;, 3001),
 (&#39;stars&#39;, 2999),
 (&#39;dining&#39;, 2993),
 (&#39;site&#39;, 2980),
 (&#39;attention&#39;, 2970),
 (&#39;own&#39;, 2969),
 (&#39;fast&#39;, 2969),
 (&#39;set&#39;, 2968),
 (&#39;00&#39;, 2961),
 (&#39;quick&#39;, 2949),
 (&#39;upon&#39;, 2948),
 (&#39;helped&#39;, 2948),
 (&#39;fruit&#39;, 2945),
 (&#39;bathrooms&#39;, 2942),
 (&#39;option&#39;, 2936),
 (&#39;yet&#39;, 2934),
 (&#39;moved&#39;, 2931),
 (&#39;stylish&#39;, 2926),
 (&#39;general&#39;, 2926),
 (&#39;everyone&#39;, 2925),
 (&#39;club&#39;, 2925),
 (&#39;does&#39;, 2904),
 (&#39;everywhere&#39;, 2896),
 (&#39;may&#39;, 2895),
 (&#39;tourist&#39;, 2892),
 (&#39;milan&#39;, 2888),
 (&#39;particularly&#39;, 2886),
 (&#39;services&#39;, 2885),
 (&#39;priced&#39;, 2882),
 (&#39;superior&#39;, 2869),
 (&#39;smaller&#39;, 2866),
 (&#39;including&#39;, 2864),
 (&#39;problems&#39;, 2856),
 (&#39;his&#39;, 2850),
 (&#39;lifts&#39;, 2842),
 (&#39;reasonable&#39;, 2830),
 (&#39;already&#39;, 2824),
 (&#39;12&#39;, 2810),
 (&#39;probably&#39;, 2807),
 (&#39;unfortunately&#39;, 2804),
 (&#39;point&#39;, 2800),
 (&#39;year&#39;, 2800),
 (&#39;hyde&#39;, 2792),
 (&#39;subway&#39;, 2786),
 (&#39;easily&#39;, 2775),
 (&#39;overpriced&#39;, 2765),
 (&#39;throughout&#39;, 2762),
 (&#39;weren&#39;, 2761),
 (&#39;courteous&#39;, 2757),
 (&#39;together&#39;, 2735),
 (&#39;continental&#39;, 2734),
 (&#39;ac&#39;, 2734),
 (&#39;lights&#39;, 2733),
 (&#39;didnt&#39;, 2732),
 (&#39;least&#39;, 2731),
 (&#39;information&#39;, 2730),
 (&#39;de&#39;, 2716),
 (&#39;pricey&#39;, 2705),
 (&#39;these&#39;, 2703),
 (&#39;cannot&#39;, 2695),
 (&#39;rest&#39;, 2691),
 (&#39;non&#39;, 2681),
 (&#39;major&#39;, 2668),
 (&#39;8&#39;, 2667),
 (&#39;iron&#39;, 2666),
 (&#39;using&#39;, 2662),
 (&#39;deal&#39;, 2656),
 (&#39;nicely&#39;, 2653),
 (&#39;personal&#39;, 2650),
 (&#39;doesn&#39;, 2643),
 (&#39;meal&#39;, 2640),
 (&#39;try&#39;, 2639),
 (&#39;low&#39;, 2633),
 (&#39;tidy&#39;, 2632),
 (&#39;ground&#39;, 2617),
 (&#39;king&#39;, 2596),
 (&#39;average&#39;, 2593),
 (&#39;cheap&#39;, 2592),
 (&#39;friends&#39;, 2577),
 (&#39;must&#39;, 2568),
 (&#39;hall&#39;, 2560),
 (&#39;breakfasts&#39;, 2538),
 (&#39;thanks&#39;, 2537),
 (&#39;issues&#39;, 2535),
 (&#39;trouble&#39;, 2530),
 (&#39;handy&#39;, 2529),
 (&#39;staffs&#39;, 2525),
 (&#39;start&#39;, 2521),
 (&#39;paying&#39;, 2516),
 (&#39;awful&#39;, 2515),
 (&#39;possible&#39;, 2513),
 (&#39;traffic&#39;, 2510),
 (&#39;four&#39;, 2508),
 (&#39;river&#39;, 2504),
 (&#39;relaxing&#39;, 2502),
 (&#39;proximity&#39;, 2501),
 (&#39;complain&#39;, 2492),
 (&#39;turn&#39;, 2487),
 (&#39;received&#39;, 2479),
 (&#39;now&#39;, 2479),
 (&#39;outstanding&#39;, 2476),
 (&#39;items&#39;, 2474),
 (&#39;wrong&#39;, 2474),
 (&#39;situated&#39;, 2460),
 (&#39;curtains&#39;, 2460),
 (&#39;head&#39;, 2449),
 (&#39;appointed&#39;, 2449),
 (&#39;except&#39;, 2448),
 (&#39;children&#39;, 2448),
 (&#39;credit&#39;, 2448),
 (&#39;recommended&#39;, 2443),
 (&#39;choices&#39;, 2442),
 (&#39;bonus&#39;, 2436),
 (&#39;paddington&#39;, 2435),
 (&#39;ordered&#39;, 2431),
 (&#39;channels&#39;, 2420),
 (&#39;run&#39;, 2416),
 (&#39;basement&#39;, 2416),
 (&#39;exceptional&#39;, 2415),
 (&#39;opened&#39;, 2411),
 (&#39;appreciated&#39;, 2410),
 (&#39;looks&#39;, 2398),
 (&#39;sized&#39;, 2394),
 (&#39;fan&#39;, 2393),
 (&#39;24&#39;, 2388),
 (&#39;provide&#39;, 2388),
 (&#39;longer&#39;, 2388),
 (&#39;anyone&#39;, 2387),
 (&#39;meant&#39;, 2384),
 (&#39;enjoy&#39;, 2382),
 (&#39;thin&#39;, 2374),
 (&#39;round&#39;, 2373),
 (&#39;construction&#39;, 2358),
 (&#39;eiffel&#39;, 2358),
 (&#39;kitchen&#39;, 2351),
 (&#39;cramped&#39;, 2351),
 (&#39;care&#39;, 2350),
 (&#39;stops&#39;, 2348),
 (&#39;number&#39;, 2328),
 (&#39;minibar&#39;, 2324),
 (&#39;designed&#39;, 2319),
 (&#39;kids&#39;, 2314),
 (&#39;luxury&#39;, 2312),
 (&#39;reach&#39;, 2310),
 (&#39;helpfull&#39;, 2306),
 (&#39;slept&#39;, 2303),
 (&#39;checkout&#39;, 2302),
 (&#39;e&#39;, 2297),
 (&#39;sauna&#39;, 2293),
 (&#39;otherwise&#39;, 2286),
 (&#39;years&#39;, 2286),
 (&#39;considering&#39;, 2285),
 (&#39;opposite&#39;, 2280),
 (&#39;incredibly&#39;, 2280),
 (&#39;might&#39;, 2276),
 (&#39;sit&#39;, 2274),
 (&#39;boutique&#39;, 2271),
 (&#39;afternoon&#39;, 2268),
 (&#39;surprise&#39;, 2266),
 (&#39;music&#39;, 2263),
 (&#39;young&#39;, 2262),
 (&#39;those&#39;, 2244),
 (&#39;museums&#39;, 2233),
 (&#39;amount&#39;, 2232),
 (&#39;control&#39;, 2232),
 (&#39;wife&#39;, 2225),
 (&#39;decoration&#39;, 2224),
 (&#39;leaving&#39;, 2224),
 (&#39;fab&#39;, 2221),
 (&#39;tasty&#39;, 2218),
 (&#39;beach&#39;, 2210),
 (&#39;works&#39;, 2208),
 (&#39;smoking&#39;, 2201),
 (&#39;cafes&#39;, 2200),
 (&#39;makes&#39;, 2199),
 (&#39;class&#39;, 2197),
 (&#39;worst&#39;, 2184),
 (&#39;floors&#39;, 2179),
 (&#39;turned&#39;, 2176),
 (&#39;fixed&#39;, 2174),
 (&#39;la&#39;, 2167),
 (&#39;wish&#39;, 2166),
 (&#39;taken&#39;, 2164),
 (&#39;seem&#39;, 2152),
 (&#39;complaints&#39;, 2151),
 (&#39;cozy&#39;, 2150),
 (&#39;understand&#39;, 2150),
 (&#39;minor&#39;, 2146),
 (&#39;separate&#39;, 2146),
 (&#39;corridor&#39;, 2142),
 (&#39;informed&#39;, 2141),
 (&#39;facing&#39;, 2130),
 (&#39;attitude&#39;, 2126),
 (&#39;shuttle&#39;, 2120),
 (&#39;mirror&#39;, 2114),
 (&#39;trying&#39;, 2098),
 (&#39;travelling&#39;, 2087),
 (&#39;choose&#39;, 2086),
 (&#39;deluxe&#39;, 2086),
 (&#39;heart&#39;, 2084),
 (&#39;pictures&#39;, 2076),
 (&#39;taking&#39;, 2073),
 (&#39;sheets&#39;, 2067),
 (&#39;name&#39;, 2067),
 (&#39;till&#39;, 2065),
 (&#39;slippers&#39;, 2048),
 (&#39;quickly&#39;, 2041),
 (&#39;friendliness&#39;, 2030),
 (&#39;100&#39;, 2021),
 (&#39;website&#39;, 2021),
 (&#39;renovation&#39;, 2018),
 (&#39;neighborhood&#39;, 2018),
 (&#39;seems&#39;, 2014),
 (&#39;walked&#39;, 2012),
 (&#39;apart&#39;, 2012),
 (&#39;directly&#39;, 2011),
 (&#39;perfectly&#39;, 2010),
 (&#39;seen&#39;, 2009),
 (&#39;museum&#39;, 2008),
 (&#39;luxurious&#39;, 2008),
 (&#39;downstairs&#39;, 2001),
 (&#39;u&#39;, 2000),
 (&#39;reservation&#39;, 2000),
 (&#39;certainly&#39;, 1992),
 (&#39;sleeping&#39;, 1991),
 (&#39;sometimes&#39;, 1988),
 (&#39;spotless&#39;, 1986),
 (&#39;reason&#39;, 1985),
 (&#39;9&#39;, 1975),
 (&#39;sofa&#39;, 1973),
 (&#39;compared&#39;, 1970),
 (&#39;isn&#39;, 1964),
 (&#39;snacks&#39;, 1964),
 (&#39;corridors&#39;, 1959),
 (&#39;daily&#39;, 1956),
 (&#39;beautifully&#39;, 1955),
 (&#39;visiting&#39;, 1954),
 (&#39;transportation&#39;, 1951),
 (&#39;via&#39;, 1948),
 (&#39;deposit&#39;, 1942),
 (&#39;adequate&#39;, 1942),
 (&#39;hand&#39;, 1939),
 (&#39;whilst&#39;, 1937),
 (&#39;case&#39;, 1934),
 (&#39;hilton&#39;, 1932),
 (&#39;annoying&#39;, 1930),
 (&#39;smile&#39;, 1929),
 (&#39;larger&#39;, 1928),
 (&#39;condition&#39;, 1924),
 (&#39;asking&#39;, 1924),
 (&#39;others&#39;, 1921),
 (&#39;man&#39;, 1918),
 (&#39;anywhere&#39;, 1915),
 (&#39;duomo&#39;, 1915),
 (&#39;oxford&#39;, 1912),
 (&#39;c&#39;, 1912),
 (&#39;25&#39;, 1907),
 (&#39;personnel&#39;, 1905),
 (&#39;bill&#39;, 1905),
 (&#39;takes&#39;, 1894),
 (&#39;cafe&#39;, 1880),
 (&#39;pillow&#39;, 1879),
 (&#39;allowed&#39;, 1875),
 (&#39;gorgeous&#39;, 1874),
 (&#39;renovated&#39;, 1870),
 (&#39;simple&#39;, 1866),
 (&#39;week&#39;, 1865),
 (&#39;husband&#39;, 1864),
 (&#39;normal&#39;, 1861),
 (&#39;v&#39;, 1857),
 (&#39;behind&#39;, 1856),
 (&#39;soon&#39;, 1856),
 (&#39;totally&#39;, 1852),
 (&#39;plug&#39;, 1852),
 (&#39;tables&#39;, 1848),
 (&#39;detail&#39;, 1844),
 (&#39;world&#39;, 1841),
 (&#39;steps&#39;, 1835),
 (&#39;generally&#39;, 1833),
 (&#39;added&#39;, 1830),
 (&#39;complained&#39;, 1830),
 (&#39;sky&#39;, 1830),
 (&#39;team&#39;, 1827),
 (&#39;o2&#39;, 1827),
 (&#39;pressure&#39;, 1816),
 (&#39;accommodation&#39;, 1813),
 (&#39;tub&#39;, 1804),
 (&#39;missing&#39;, 1798),
 (&#39;cheaper&#39;, 1797),
 (&#39;partner&#39;, 1794),
 (&#39;cake&#39;, 1792),
 (&#39;completely&#39;, 1791),
 (&#39;mentioned&#39;, 1789),
 (&#39;flight&#39;, 1788),
 (&#39;wardrobe&#39;, 1786),
 (&#39;management&#39;, 1786),
 (&#39;standards&#39;, 1785),
 (&#39;fire&#39;, 1785),
 (&#39;show&#39;, 1785),
 (&#39;sights&#39;, 1781),
 (&#39;ll&#39;, 1767),
 (&#39;worn&#39;, 1764),
 (&#39;additional&#39;, 1752),
 (&#39;five&#39;, 1746),
 (&#39;ride&#39;, 1745),
 (&#39;clear&#39;, 1741),
 (&#39;sunday&#39;, 1740),
 (&#39;stunning&#39;, 1735),
 (&#39;strange&#39;, 1735),
 (&#39;fully&#39;, 1732),
 (&#39;please&#39;, 1732),
 (&#39;immediately&#39;, 1725),
 (&#39;details&#39;, 1724),
 (&#39;overlooking&#39;, 1723),
 (&#39;below&#39;, 1721),
 (&#39;brought&#39;, 1718),
 (&#39;daughter&#39;, 1717),
 (&#39;him&#39;, 1716),
 (&#39;kensington&#39;, 1715),
 (&#39;empty&#39;, 1706),
 (&#39;aircon&#39;, 1705),
 (&#39;towel&#39;, 1695),
 (&#39;spot&#39;, 1680),
 (&#39;horrible&#39;, 1674),
 (&#39;conditioner&#39;, 1673),
 (&#39;carpets&#39;, 1670),
 (&#39;pm&#39;, 1666),
 (&#39;11&#39;, 1662),
 (&#39;paper&#39;, 1661),
 (&#39;shame&#39;, 1661),
 (&#39;private&#39;, 1659),
 (&#39;proper&#39;, 1656),
 (&#39;bread&#39;, 1648),
 (&#39;perhaps&#39;, 1648),
 (&#39;anniversary&#39;, 1647),
 (&#39;maintenance&#39;, 1646),
 (&#39;canal&#39;, 1638),
 (&#39;spent&#39;, 1635),
 (&#39;heard&#39;, 1629),
 (&#39;sightseeing&#39;, 1629),
 (&#39;literally&#39;, 1625),
 (&#39;ended&#39;, 1625),
 (&#39;apartment&#39;, 1624),
 (&#39;customers&#39;, 1624),
 (&#39;security&#39;, 1619),
 (&#39;bedrooms&#39;, 1615),
 (&#39;type&#39;, 1614),
 (&#39;idea&#39;, 1608),
 (&#39;ceiling&#39;, 1607),
 (&#39;payment&#39;, 1606),
 (&#39;feeling&#39;, 1606),
 (&#39;accessible&#39;, 1606),
 (&#39;charming&#39;, 1604),
 (&#39;champagne&#39;, 1603),
 (&#39;bacon&#39;, 1600),
 (&#39;previous&#39;, 1600),
 (&#39;guy&#39;, 1598),
 (&#39;sign&#39;, 1598),
 (&#39;enjoyable&#39;, 1596),
 (&#39;fairly&#39;, 1594),
 (&#39;alarm&#39;, 1594),
 (&#39;clearly&#39;, 1593),
 (&#39;fair&#39;, 1591),
 ...]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Words that you would expect to see more often in positive reviews  like "amazing"  have a ratio greater than 1. The more skewed a word is toward postive, the farther from 1 its positive-to-negative ratio will be.
Words that you would expect to see more often in negative reviews  like "terrible"  have positive values that are less than 1. The more skewed a word is toward negative, the closer to zero its positive-to-negative ratio will be.
Neutral words, which don't really convey any sentiment because you would expect to see them in all sorts of reviews  like "the"  have values very close to 1. A perfectly neutral word  one that was used in exactly the same number of positive reviews as negative reviews  would be almost exactly 1. The +1 we suggested you add to the denominator slightly biases words toward negative, but it won't matter because it will be a tiny bias and later we'll be ignoring words that are too close to neutral anyway.
Ok, the ratios tell us which words are used more often in postive or negative reviews, but the specific values we've calculated are a bit difficult to work with. A very positive word like "amazing" has a value above 4, whereas a very negative word like "terrible" has a value around 0.18. Those values aren't easy to compare for a couple of reasons:</p>
<p>Right now, 1 is considered neutral, but the absolute value of the postive-to-negative rations of very postive words is larger than the absolute value of the ratios for the very negative words. So there is no way to directly compare two numbers and see if one word conveys the same magnitude of positive sentiment as another word conveys negative sentiment. So we should center all the values around netural so the absolute value from neutral of the postive-to-negative ratio for a word would indicate how much sentiment (positive or negative) that word conveys.
When comparing absolute values it's easier to do that around zero than one.
To fix these issues, we'll convert all of our ratios to new values using logarithms.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pos_neg_ratios</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>

<span class="c1"># Calculate the ratios of positive and negative uses of the most common words</span>
<span class="c1"># Consider words to be &quot;common&quot; if they&#39;ve been used at least 100 times</span>
<span class="k">for</span> <span class="n">term</span><span class="p">,</span><span class="n">cnt</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">total_counts</span><span class="o">.</span><span class="n">most_common</span><span class="p">()):</span>
    <span class="k">if</span><span class="p">(</span><span class="n">cnt</span> <span class="o">&gt;</span> <span class="mi">100</span><span class="p">):</span>
        <span class="n">pos_neg_ratio</span> <span class="o">=</span> <span class="n">positive_counts</span><span class="p">[</span><span class="n">term</span><span class="p">]</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">negative_counts</span><span class="p">[</span><span class="n">term</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">pos_neg_ratios</span><span class="p">[</span><span class="n">term</span><span class="p">]</span> <span class="o">=</span> <span class="n">pos_neg_ratio</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pos-to-neg ratio for &#39;the&#39; = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pos_neg_ratios</span><span class="p">[</span><span class="s2">&quot;the&quot;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pos-to-neg ratio for &#39;amazing&#39; = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pos_neg_ratios</span><span class="p">[</span><span class="s2">&quot;amazing&quot;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pos-to-neg ratio for &#39;terrible&#39; = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pos_neg_ratios</span><span class="p">[</span><span class="s2">&quot;terrible&quot;</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Pos-to-neg ratio for &#39;the&#39; = 0.9707387862796834
Pos-to-neg ratio for &#39;amazing&#39; = 22.491683991683992
Pos-to-neg ratio for &#39;terrible&#39; = 0.07790284360189574
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">word</span><span class="p">,</span><span class="n">ratio</span> <span class="ow">in</span> <span class="n">pos_neg_ratios</span><span class="o">.</span><span class="n">most_common</span><span class="p">():</span>
    <span class="n">pos_neg_ratios</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">ratio</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\vaibh\Anaconda3x\lib\site-packages\ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log
  
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pos-to-neg ratio for &#39;the&#39; = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pos_neg_ratios</span><span class="p">[</span><span class="s2">&quot;the&quot;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pos-to-neg ratio for &#39;amazing&#39; = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pos_neg_ratios</span><span class="p">[</span><span class="s2">&quot;amazing&quot;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pos-to-neg ratio for &#39;terrible&#39; = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pos_neg_ratios</span><span class="p">[</span><span class="s2">&quot;terrible&quot;</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Pos-to-neg ratio for &#39;the&#39; = -0.02969786204183641
Pos-to-neg ratio for &#39;amazing&#39; = 3.113145640521723
Pos-to-neg ratio for &#39;terrible&#39; = -2.552292823538083
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If everything worked, now you should see neutral words with values close to zero. In this case, "the" is near zero but slightly positive, so it was probably used in more positive reviews than negative reviews. But look at "amazing"'s ratio - it's above 1, showing it is clearly a word with positive sentiment. And "terrible" has a similar score, but in the opposite direction, so it's below -1. It's now clear that both of these words are associated with specific, opposing sentiments.</p>
<p>Now run the following cells to see more ratios.</p>
<p>The first cell displays all the words, ordered by how associated they are with postive reviews. (Your notebook will most likely truncate the output so you won't actually see all the words in the list.)</p>
<p>The second cell displays the 30 words most associated with negative reviews by reversing the order of the first list and then looking at the first 30 words. (If you want the second cell to display all the words, ordered by how associated they are with negative reviews, you could just write reversed(pos_neg_ratios.most_common()).)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pos_neg_ratios</span><span class="o">.</span><span class="n">most_common</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[18]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[(&#39;aerobus&#39;, 4.548599834499697),
 (&#39;negative&#39;, 4.411158948711202),
 (&#39;theatres&#39;, 4.076232812279055),
 (&#39;dame&#39;, 4.02733385193914),
 (&#39;wonderfully&#39;, 4.023117052933733),
 (&#39;notre&#39;, 4.017383521085972),
 (&#39;breathtaking&#39;, 3.9765615265657175),
 (&#39;divine&#39;, 3.7612001156935624),
 (&#39;oasis&#39;, 3.703768066607687),
 (&#39;immaculately&#39;, 3.6375861597263857),
 (&#39;hofburg&#39;, 3.6109179126442243),
 (&#39;spotlessly&#39;, 3.570988654030486),
 (&#39;sse&#39;, 3.5648268054439574),
 (&#39;museums&#39;, 3.491905620533111),
 (&#39;seine&#39;, 3.449987545831587),
 (&#39;buckingham&#39;, 3.448001447859958),
 (&#39;excelent&#39;, 3.4400173735117376),
 (&#39;galleries&#39;, 3.439349147626532),
 (&#39;orsay&#39;, 3.4094961844768505),
 (&#39;lush&#39;, 3.4011973816621555),
 (&#39;theaters&#39;, 3.4011973816621555),
 (&#39;impeccably&#39;, 3.3843902633457743),
 (&#39;harrods&#39;, 3.380994674344636),
 (&#39;lication&#39;, 3.3758795736778655),
 (&#39;albert&#39;, 3.3706543553936084),
 (&#39;tate&#39;, 3.3623575483458916),
 (&#39;wonderfull&#39;, 3.361532125269724),
 (&#39;yummy&#39;, 3.3512527051458987),
 (&#39;phenomenal&#39;, 3.3440389678222067),
 (&#39;helpfulness&#39;, 3.3349479961209547),
 (&#39;superb&#39;, 3.292449492816166),
 (&#39;gorgeous&#39;, 3.2799155854161217),
 (&#39;exquisite&#39;, 3.2724165917962305),
 (&#39;excellent&#39;, 3.26993061301413),
 (&#39;espanya&#39;, 3.265759410767051),
 (&#39;hyde&#39;, 3.262567484366249),
 (&#39;gaudi&#39;, 3.2516656476911914),
 (&#39;2min&#39;, 3.248434627109745),
 (&#39;musee&#39;, 3.2088254890146994),
 (&#39;awesome&#39;, 3.2052294157269103),
 (&#39;immaculate&#39;, 3.1918471524802814),
 (&#39;spacious&#39;, 3.189047598580155),
 (&#39;fantastic&#39;, 3.1838276633832576),
 (&#39;covent&#39;, 3.1828870925359647),
 (&#39;unbeatable&#39;, 3.1780538303479458),
 (&#39;comfy&#39;, 3.16599062078966),
 (&#39;louvre&#39;, 3.1653471790788306),
 (&#39;fantastically&#39;, 3.1612467120315646),
 (&#39;lafayette&#39;, 3.1135153092103742),
 (&#39;amazing&#39;, 3.113145640521723),
 (&#39;abbey&#39;, 3.106080330722856),
 (&#39;spacy&#39;, 3.0985896589936988),
 (&#39;stylish&#39;, 3.093187609704704),
 (&#39;beautifully&#39;, 3.091577069783773),
 (&#39;superbly&#39;, 3.077970371790963),
 (&#39;tastefully&#39;, 3.0741542353297944),
 (&#39;excellant&#39;, 3.0706335817271087),
 (&#39;amazingly&#39;, 3.069344090897237),
 (&#39;brera&#39;, 3.054001181677967),
 (&#39;delicious&#39;, 3.0462845527168225),
 (&#39;thoughtful&#39;, 3.0423555896383325),
 (&#39;rathaus&#39;, 3.0204248861443626),
 (&#39;beautiful&#39;, 3.0163160676690017),
 (&#39;parliament&#39;, 3.0122615755052013),
 (&#39;triomphe&#39;, 3.008977500304012),
 (&#39;obliging&#39;, 3.006782109740576),
 (&#39;royalty&#39;, 2.995732273553991),
 (&#39;trafalgar&#39;, 2.9894626605403958),
 (&#39;airy&#39;, 2.9869985935852363),
 (&#39;unforgettable&#39;, 2.9789251552376097),
 (&#39;fabulous&#39;, 2.966713579664955),
 (&#39;placa&#39;, 2.9628444067091557),
 (&#39;tasteful&#39;, 2.955458374416051),
 (&#39;courteous&#39;, 2.9513302774952814),
 (&#39;lys&#39;, 2.9444389791664403),
 (&#39;terrific&#39;, 2.928226391188618),
 (&#39;catalunya&#39;, 2.920769235080536),
 (&#39;exellent&#39;, 2.920224721045846),
 (&#39;outstanding&#39;, 2.917983520679613),
 (&#39;localization&#39;, 2.917770732084279),
 (&#39;friendly&#39;, 2.9121864937361397),
 (&#39;friendliness&#39;, 2.909240242200547),
 (&#39;stunning&#39;, 2.894636156682622),
 (&#39;arc&#39;, 2.8943321591122615),
 (&#39;strategic&#39;, 2.882403588246988),
 (&#39;elemis&#39;, 2.8693183486983322),
 (&#39;oxford&#39;, 2.8663531360302357),
 (&#39;sants&#39;, 2.863703510814003),
 (&#39;location&#39;, 2.8626448171189858),
 (&#39;impeccable&#39;, 2.860157979299668),
 (&#39;elegant&#39;, 2.8574276021768106),
 (&#39;helpful&#39;, 2.8547712560358787),
 (&#39;piccadilly&#39;, 2.851861903134289),
 (&#39;earls&#39;, 2.847812143477369),
 (&#39;closeness&#39;, 2.8455211917308127),
 (&#39;southbank&#39;, 2.833213344056216),
 (&#39;cute&#39;, 2.8315312578732312),
 (&#39;queensway&#39;, 2.829940018711247),
 (&#39;latin&#39;, 2.8273136219290276),
 (&#39;aldgate&#39;, 2.8247744754103516),
 (&#39;spotless&#39;, 2.8178650671094165),
 (&#39;pancras&#39;, 2.815988037774337),
 (&#39;wonderful&#39;, 2.811619095553118),
 (&#39;exceptional&#39;, 2.8115111034175593),
 (&#39;fab&#39;, 2.811504138489455),
 (&#39;heavenly&#39;, 2.803360380906535),
 (&#39;spacey&#39;, 2.803360380906535),
 (&#39;stephen&#39;, 2.803360380906535),
 (&#39;balloons&#39;, 2.7999876964278956),
 (&#39;rer&#39;, 2.7999876964278956),
 (&#39;regents&#39;, 2.7990219793079367),
 (&#39;delightful&#39;, 2.797281334830153),
 (&#39;westbahnhof&#39;, 2.793208009442517),
 (&#39;excellently&#39;, 2.785011242238338),
 (&#39;passeig&#39;, 2.779509165084355),
 (&#39;quietness&#39;, 2.7788192719904172),
 (&#39;centrale&#39;, 2.7771514677981997),
 (&#39;champs&#39;, 2.772588722239781),
 (&#39;splendid&#39;, 2.772588722239781),
 (&#39;macaroons&#39;, 2.772588722239781),
 (&#39;warmly&#39;, 2.765620052923688),
 (&#39;marylebone&#39;, 2.7580606216768717),
 (&#39;picadilly&#39;, 2.7568403652716422),
 (&#39;museum&#39;, 2.7563111247194634),
 (&#39;helpfull&#39;, 2.7470864294288453),
 (&#39;magical&#39;, 2.7454377331738304),
 (&#39;gem&#39;, 2.740840023925201),
 (&#39;freindly&#39;, 2.732003442124703),
 (&#39;belvedere&#39;, 2.731580698512404),
 (&#39;conveniently&#39;, 2.730397499794207),
 (&#39;sloterdijk&#39;, 2.7300291078209855),
 (&#39;village&#39;, 2.70805020110221),
 (&#39;lovely&#39;, 2.7054871924373205),
 (&#39;modern&#39;, 2.700141288956532),
 (&#39;germain&#39;, 2.6820747146989494),
 (&#39;elysees&#39;, 2.681021528714291),
 (&#39;peaceful&#39;, 2.6750556789671713),
 (&#39;vibrant&#39;, 2.672332118500131),
 (&#39;sacre&#39;, 2.670309873119363),
 (&#39;pleasantly&#39;, 2.6678593205189647),
 (&#39;opera&#39;, 2.6595825655599894),
 (&#39;bonus&#39;, 2.655440250829913),
 (&#39;brilliant&#39;, 2.6344152930702833),
 (&#39;shopping&#39;, 2.633239977549345),
 (&#39;vondelpark&#39;, 2.631888840136646),
 (&#39;cookie&#39;, 2.6280074934286737),
 (&#39;borough&#39;, 2.6210388241125804),
 (&#39;hop&#39;, 2.6135240276100937),
 (&#39;quirky&#39;, 2.6110181095508658),
 (&#39;scala&#39;, 2.606796467397037),
 (&#39;cheerful&#39;, 2.6060510331470885),
 (&#39;delight&#39;, 2.6026896854443837),
 (&#39;charming&#39;, 2.5900439262440957),
 (&#39;luxembourg&#39;, 2.5877640352277083),
 (&#39;montmartre&#39;, 2.586689344097943),
 (&#39;magnificent&#39;, 2.578124778620101),
 (&#39;heartbeat&#39;, 2.5745188084776873),
 (&#39;accommodating&#39;, 2.5690203139415586),
 (&#39;sights&#39;, 2.567369201352572),
 (&#39;eurostar&#39;, 2.567209245428974),
 (&#39;sagrada&#39;, 2.5666960827964784),
 (&#39;classy&#39;, 2.563409711275944),
 (&#39;history&#39;, 2.561499095269384),
 (&#39;neat&#39;, 2.5563656137701454),
 (&#39;schonbrunn&#39;, 2.5508646175797978),
 (&#39;casa&#39;, 2.550421256898627),
 (&#39;gothic&#39;, 2.545075171254453),
 (&#39;elegance&#39;, 2.5437471498109336),
 (&#39;gloucester&#39;, 2.5382217085557217),
 (&#39;bustle&#39;, 2.5347203555002196),
 (&#39;euston&#39;, 2.5319067038351837),
 (&#39;elysee&#39;, 2.531426665422893),
 (&#39;calm&#39;, 2.527417358472589),
 (&#39;thankyou&#39;, 2.5226469777708473),
 (&#39;landmarks&#39;, 2.51939282585917),
 (&#39;michel&#39;, 2.515678308454754),
 (&#39;attentive&#39;, 2.5133516813585204),
 (&#39;familia&#39;, 2.511076367521385),
 (&#39;nord&#39;, 2.508812170641555),
 (&#39;specious&#39;, 2.501435951739211),
 (&#39;cozy&#39;, 2.501134186409757),
 (&#39;mod&#39;, 2.499944527152541),
 (&#39;links&#39;, 2.4932054526026954),
 (&#39;unique&#39;, 2.4908413853078146),
 (&#39;accomodating&#39;, 2.477937980471907),
 (&#39;relaxed&#39;, 2.477013948989091),
 (&#39;appointed&#39;, 2.4760960201058455),
 (&#39;thumbs&#39;, 2.474435349920705),
 (&#39;gare&#39;, 2.4712078054298385),
 (&#39;hammersmith&#39;, 2.466214516775848),
 (&#39;sumptuous&#39;, 2.465488563930899),
 (&#39;westfield&#39;, 2.463853240590168),
 (&#39;regent&#39;, 2.4619171315633017),
 (&#39;proximity&#39;, 2.45963222669276),
 (&#39;vibe&#39;, 2.4411712562801924),
 (&#39;holborn&#39;, 2.439444275711243),
 (&#39;memorable&#39;, 2.4389969484839225),
 (&#39;ziggo&#39;, 2.4383866341531073),
 (&#39;loved&#39;, 2.4308889420473068),
 (&#39;bubbly&#39;, 2.4294768448486694),
 (&#39;olympic&#39;, 2.4292177439274116),
 (&#39;handy&#39;, 2.423168949182221),
 (&#39;stroll&#39;, 2.4203681286504293),
 (&#39;brilliantly&#39;, 2.414289082574047),
 (&#39;praise&#39;, 2.414289082574047),
 (&#39;danube&#39;, 2.412933150162911),
 (&#39;incredible&#39;, 2.4093731606430575),
 (&#39;palace&#39;, 2.4065160158422776),
 (&#39;decorated&#39;, 2.4004648673600015),
 (&#39;doorstep&#39;, 2.3999592570192223),
 (&#39;royal&#39;, 2.398832041016757),
 (&#39;alex&#39;, 2.3978952727983707),
 (&#39;cathedral&#39;, 2.3968497943968177),
 (&#39;gracia&#39;, 2.393754480132339),
 (&#39;gardens&#39;, 2.3916491563014177),
 (&#39;convenient&#39;, 2.3887091368488953),
 (&#39;comfortable&#39;, 2.3831481868782385),
 (&#39;marvellous&#39;, 2.379546134130174),
 (&#39;barbican&#39;, 2.379546134130174),
 (&#39;kensington&#39;, 2.3752242766340173),
 (&#39;roomy&#39;, 2.37242866636131),
 (&#39;paddington&#39;, 2.3713215213458567),
 (&#39;leicester&#39;, 2.3642786619993856),
 (&#39;great&#39;, 2.3600451028141833),
 (&#39;contemporary&#39;, 2.358376452622461),
 (&#39;saint&#39;, 2.3581549441488563),
 (&#39;bayswater&#39;, 2.3562892719659065),
 (&#39;nicely&#39;, 2.35509503826601),
 (&#39;homely&#39;, 2.3513752571634776),
 (&#39;petals&#39;, 2.3513752571634776),
 (&#39;quiet&#39;, 2.342573644719577),
 (&#39;hermes&#39;, 2.341805806147327),
 (&#39;hustle&#39;, 2.3363824725773363),
 (&#39;exemplary&#39;, 2.32949254591397),
 (&#39;duomo&#39;, 2.3292842993492857),
 (&#39;apollo&#39;, 2.32163328796474),
 (&#39;exploring&#39;, 2.319721375237033),
 (&#39;tidy&#39;, 2.3181414294087745),
 (&#39;cookies&#39;, 2.3171572998531365),
 (&#39;baker&#39;, 2.3116349285139637),
 (&#39;westminster&#39;, 2.311500456651998),
 (&#39;delighted&#39;, 2.306577114263583),
 (&#39;ambience&#39;, 2.2982901687111648),
 (&#39;montparnasse&#39;, 2.2975725511705014),
 (&#39;chocolates&#39;, 2.296887071879408),
 (&#39;shepherds&#39;, 2.295416603515433),
 (&#39;leidseplein&#39;, 2.2925347571405443),
 (&#39;strawberries&#39;, 2.2914117923959205),
 (&#39;architecture&#39;, 2.281531683796213),
 (&#39;marvelous&#39;, 2.2809235962128662),
 (&#39;moulin&#39;, 2.2809235962128662),
 (&#39;professional&#39;, 2.2804729224479714),
 (&#39;nou&#39;, 2.278774444300327),
 (&#39;knowledgable&#39;, 2.272984623217755),
 (&#39;liverpool&#39;, 2.272507637756768),
 (&#39;wonderland&#39;, 2.272125885509337),
 (&#39;heart&#39;, 2.2713325494899412),
 (&#39;plentiful&#39;, 2.264363880173848),
 (&#39;touches&#39;, 2.2629198366016143),
 (&#39;frendly&#39;, 2.2553322081435003),
 (&#39;daniel&#39;, 2.2512917986064953),
 (&#39;highly&#39;, 2.251163106758946),
 (&#39;canals&#39;, 2.2464956263430023),
 (&#39;efficient&#39;, 2.240549702074593),
 (&#39;circus&#39;, 2.240064736012712),
 (&#39;greenwich&#39;, 2.2398749646865896),
 (&#39;olympia&#39;, 2.2380465718564744),
 (&#39;heaven&#39;, 2.2380465718564744),
 (&#39;convinient&#39;, 2.2373445711256448),
 (&#39;iconic&#39;, 2.236833715431265),
 (&#39;polite&#39;, 2.236380619985695),
 (&#39;ideally&#39;, 2.2363785147557773),
 (&#39;artistic&#39;, 2.2300144001592104),
 (&#39;du&#39;, 2.2293816889707507),
 (&#39;piazza&#39;, 2.222542385320509),
 (&#39;arena&#39;, 2.2158669281454992),
 (&#39;quaint&#39;, 2.212538812309262),
 (&#39;kindness&#39;, 2.207274913189721),
 (&#39;soho&#39;, 2.207052666272482),
 (&#39;victoria&#39;, 2.205855466535495),
 (&#39;tranquil&#39;, 2.1972245773362196),
 (&#39;embankment&#39;, 2.1972245773362196),
 (&#39;favourite&#39;, 2.1952023319554517),
 (&#39;walkable&#39;, 2.192161275379673),
 (&#39;defo&#39;, 2.1897895988487015),
 (&#39;mall&#39;, 2.1838505178109626),
 (&#39;informative&#39;, 2.1771233980151323),
 (&#39;cake&#39;, 2.1745033051370877),
 (&#39;bahn&#39;, 2.172476407647025),
 (&#39;russell&#39;, 2.170413319885563),
 (&#39;knowledgeable&#39;, 2.168418578087138),
 (&#39;es&#39;, 2.1675488091901025),
 (&#39;comfiest&#39;, 2.164963715117998),
 (&#39;attractions&#39;, 2.1641691435885972),
 (&#39;marina&#39;, 2.1629746542931407),
 (&#39;array&#39;, 2.159484249353372),
 (&#39;camden&#39;, 2.158003864182938),
 (&#39;gogh&#39;, 2.1567332159814825),
 (&#39;super&#39;, 2.1566564057564674),
 (&#39;rambla&#39;, 2.1566462178518875),
 (&#39;pla&#39;, 2.1559816188021705),
 (&#39;thames&#39;, 2.1558832371797783),
 (&#39;doormen&#39;, 2.1552015875613715),
 (&#39;recommendations&#39;, 2.155153363415532),
 (&#39;dome&#39;, 2.1546649629174235),
 (&#39;personalised&#39;, 2.1498223384416355),
 (&#39;supermarkets&#39;, 2.146830563584813),
 (&#39;bush&#39;, 2.145742621501076),
 (&#39;easy&#39;, 2.143185867620253),
 (&#39;spectacular&#39;, 2.133686556532232),
 (&#39;excel&#39;, 2.132816002271211),
 (&#39;caring&#39;, 2.125961557314729),
 (&#39;stations&#39;, 2.1228517332224617),
 (&#39;extraordinary&#39;, 2.1216418961702126),
 (&#39;pristine&#39;, 2.120263536200091),
 (&#39;reasonably&#39;, 2.1159991374136333),
 (&#39;explore&#39;, 2.1117424864681573),
 (&#39;sleek&#39;, 2.1102132003465894),
 (&#39;ease&#39;, 2.109061789741548),
 (&#39;funky&#39;, 2.108769156774356),
 (&#39;james&#39;, 2.106252799130493),
 (&#39;perfect&#39;, 2.106207604454418),
 (&#39;ben&#39;, 2.1048512572052043),
 (&#39;pleasure&#39;, 2.101629456655198),
 (&#39;shepherd&#39;, 2.097141118779237),
 (&#39;locality&#39;, 2.0918640616783932),
 (&#39;ambiance&#39;, 2.0902007608315754),
 (&#39;100m&#39;, 2.0856720914304723),
 (&#39;marais&#39;, 2.0856720914304723),
 (&#39;love&#39;, 2.0791992642710193),
 (&#39;cava&#39;, 2.0703090581165635),
 (&#39;lyon&#39;, 2.069779630768099),
 (&#39;stadium&#39;, 2.0650528042277365),
 (&#39;prompt&#39;, 2.0642403803477856),
 (&#39;clean&#39;, 2.0639474796802704),
 (&#39;convenience&#39;, 2.0635681925235456),
 (&#39;ample&#39;, 2.0583881324820035),
 (&#39;hesitate&#39;, 2.057323736426217),
 (&#39;david&#39;, 2.05572501506252),
 (&#39;grocery&#39;, 2.0541237336955462),
 (&#39;stones&#39;, 2.0492277630833393),
 (&#39;competent&#39;, 2.044755983691946),
 (&#39;5min&#39;, 2.0436524338282505),
 (&#39;gracious&#39;, 2.03688192726104),
 (&#39;pharmacy&#39;, 2.03688192726104),
 (&#39;thank&#39;, 2.0359400254060716),
 (&#39;st&#39;, 2.0353815518858056),
 (&#39;las&#39;, 2.0319005969108357),
 (&#39;galleria&#39;, 2.030170492673053),
 (&#39;shops&#39;, 2.0275927273326966),
 (&#39;welcoming&#39;, 2.0265837098153914),
 (&#39;theatre&#39;, 2.026202575796198),
 (&#39;historic&#39;, 2.0248985603739436),
 (&#39;chic&#39;, 2.0227155602790585),
 (&#39;authentic&#39;, 2.0149030205422647),
 (&#39;triumph&#39;, 2.0149030205422647),
 (&#39;favorite&#39;, 2.0133514298508457),
 (&#39;enjoyed&#39;, 2.0066471423469916),
 (&#39;confortable&#39;, 2.0056006278799514),
 (&#39;distance&#39;, 2.0039785867128224),
 (&#39;ramblas&#39;, 2.0002599919254127),
 (&#39;goodies&#39;, 1.992430164690206),
 (&#39;heathrow&#39;, 1.9828805799738585),
 (&#39;born&#39;, 1.9810014688665833),
 (&#39;equipped&#39;, 1.979058193374189),
 (&#39;exceptionally&#39;, 1.9742242001936336),
 (&#39;views&#39;, 1.9729488332822323),
 (&#39;wembley&#39;, 1.9669635582531455),
 (&#39;pleasant&#39;, 1.9662661665963699),
 (&#39;notch&#39;, 1.9661128563728327),
 (&#39;stratford&#39;, 1.9636097261547143),
 (&#39;maria&#39;, 1.9629077254238845),
 (&#39;tasty&#39;, 1.9557318873538132),
 (&#39;chilled&#39;, 1.9528546214081244),
 (&#39;eiffel&#39;, 1.9493057380564516),
 (&#39;nice&#39;, 1.9488116516430403),
 (&#39;gifts&#39;, 1.9459101490553132),
 (&#39;imperial&#39;, 1.9459101490553132),
 (&#39;tube&#39;, 1.9449532528055333),
 (&#39;station&#39;, 1.9412405085165496),
 (&#39;knightsbridge&#39;, 1.9399399820688095),
 (&#39;die&#39;, 1.9383629434199305),
 (&#39;silent&#39;, 1.9373447861963902),
 (&#39;shard&#39;, 1.9361221426891504),
 (&#39;highlights&#39;, 1.9348603128687283),
 (&#39;quarter&#39;, 1.93334892318234),
 (&#39;parks&#39;, 1.9315214116032138),
 (&#39;art&#39;, 1.9280325779479073),
 (&#39;panoramic&#39;, 1.927891643552635),
 (&#39;concerts&#39;, 1.9266787871274256),
 (&#39;schiphol&#39;, 1.9252908618525775),
 (&#39;exceeded&#39;, 1.9207515894191585),
 (&#39;treats&#39;, 1.911489925168834),
 (&#39;paul&#39;, 1.9102410728485784),
 (&#39;stores&#39;, 1.9057037285772729),
 (&#39;tower&#39;, 1.9050185917372144),
 (&#39;restaurants&#39;, 1.9047508168756062),
 (&#39;rouge&#39;, 1.9042374526547452),
 (&#39;castle&#39;, 1.9029851043382795),
 (&#39;swift&#39;, 1.9002401122221249),
 (&#39;approachable&#39;, 1.8960555888300947),
 (&#39;sophisticated&#39;, 1.8918429277850375),
 (&#39;bridge&#39;, 1.888318478417287),
 (&#39;luxurious&#39;, 1.8842067784827028),
 (&#39;position&#39;, 1.882819434743685),
 (&#39;historical&#39;, 1.8808872491240625),
 (&#39;des&#39;, 1.8754584881047018),
 (&#39;national&#39;, 1.8744511850731684),
 (&#39;dream&#39;, 1.8718021769015913),
 (&#39;boutique&#39;, 1.8715482731297564),
 (&#39;cloud&#39;, 1.8687205103641833),
 (&#39;fluffy&#39;, 1.8613008870809282),
 (&#39;defiantly&#39;, 1.8601966307812834),
 (&#39;wien&#39;, 1.8597641983421125),
 (&#39;navigli&#39;, 1.8581345381729277),
 (&#39;generous&#39;, 1.855734768723027),
 (&#39;asset&#39;, 1.8551812956655511),
 (&#39;pubs&#39;, 1.8525516654060048),
 (&#39;cosy&#39;, 1.8496891904722275),
 (&#39;routes&#39;, 1.8482716794913974),
 (&#39;earl&#39;, 1.8466003849276411),
 (&#39;fireplace&#39;, 1.8458266904983307),
 (&#39;university&#39;, 1.8439452223986252),
 (&#39;resturants&#39;, 1.8399615710459327),
 (&#39;ealing&#39;, 1.83961549040569),
 (&#39;metro&#39;, 1.8359391368360687),
 (&#39;sites&#39;, 1.834886497423527),
 (&#39;court&#39;, 1.8340618489187444),
 (&#39;rich&#39;, 1.8329697378747178),
 (&#39;markets&#39;, 1.830840819270526),
 (&#39;lively&#39;, 1.829499797210902),
 (&#39;frank&#39;, 1.824549292051046),
 (&#39;enjoyable&#39;, 1.8235316282283922),
 (&#39;thanks&#39;, 1.8229030505963937),
 (&#39;prime&#39;, 1.818606719264243),
 (&#39;west&#39;, 1.8159737273486496),
 (&#39;equiped&#39;, 1.8144877203056111),
 (&#39;sightseeing&#39;, 1.8112195427827673),
 (&#39;furnished&#39;, 1.8108076641987494),
 (&#39;cdg&#39;, 1.8055527913603908),
 (&#39;brill&#39;, 1.80280930541464),
 (&#39;kings&#39;, 1.802341578558592),
 (&#39;newly&#39;, 1.7982487846678048),
 (&#39;stops&#39;, 1.7937475414534412),
 (&#39;supportive&#39;, 1.791759469228055),
 (&#39;destinations&#39;, 1.791759469228055),
 (&#39;boats&#39;, 1.791759469228055),
 (&#39;centrally&#39;, 1.7881297011774764),
 (&#39;arch&#39;, 1.7863686205931786),
 (&#39;canary&#39;, 1.7845392212545679),
 (&#39;efficiency&#39;, 1.784324490740537),
 (&#39;cordial&#39;, 1.7829488395459),
 (&#39;highlight&#39;, 1.7788560643921472),
 (&#39;trendy&#39;, 1.7785142424780345),
 (&#39;close&#39;, 1.7780856885349015),
 (&#39;science&#39;, 1.7730673362159026),
 (&#39;south&#39;, 1.7705272491222808),
 (&#39;o2&#39;, 1.7702260216179322),
 (&#39;market&#39;, 1.7699931927461003),
 (&#39;smart&#39;, 1.7672037799706113),
 (&#39;subway&#39;, 1.7660425812229255),
 (&#39;sweets&#39;, 1.765557096834031),
 (&#39;central&#39;, 1.7651105878418878),
 (&#39;wharf&#39;, 1.7649669522314801),
 (&#39;pantry&#39;, 1.7643604950399405),
 (&#39;50m&#39;, 1.7600107709134747),
 (&#39;fountain&#39;, 1.7594986070098335),
 (&#39;smiling&#39;, 1.758753172759885),
 (&#39;languages&#39;, 1.7578579175523736),
 (&#39;est&#39;, 1.75539182505718),
 (&#39;beach&#39;, 1.7547857185154034),
 (&#39;buses&#39;, 1.7537443782265814),
 (&#39;celebrate&#39;, 1.7537320736388158),
 (&#39;helpfully&#39;, 1.7443572303334711),
 (&#39;library&#39;, 1.7346010553881064),
 (&#39;atmosphere&#39;, 1.7264615969064594),
 (&#39;personable&#39;, 1.7206635475443246),
 (&#39;de&#39;, 1.716101925995371),
 (&#39;pauls&#39;, 1.7125100975739145),
 (&#39;theater&#39;, 1.7122952978738082),
 (&#39;gallery&#39;, 1.7104138297741025),
 (&#39;gatwick&#39;, 1.7086928705294415),
 (&#39;centraal&#39;, 1.7076763520175138),
 (&#39;transport&#39;, 1.7046451321353742),
 (&#39;supermarket&#39;, 1.7034037048524318),
 (&#39;diagonal&#39;, 1.7018112325651154),
 (&#39;5mins&#39;, 1.7016083722337574),
 (&#39;beat&#39;, 1.6966943574313285),
 (&#39;boyfriends&#39;, 1.6952992030404928),
 (&#39;200m&#39;, 1.6945957207744073),
 (&#39;jubilee&#39;, 1.6933193964148026),
 (&#39;eager&#39;, 1.6916760106710724),
 (&#39;rembrandt&#39;, 1.6916760106710724),
 (&#39;remarkable&#39;, 1.6885752329928243),
 (&#39;sunset&#39;, 1.6885752329928243),
 (&#39;good&#39;, 1.6860959826709392),
 (&#39;visiting&#39;, 1.6843392206072183),
 (&#39;willingness&#39;, 1.6843392206072183),
 (&#39;ace&#39;, 1.6817585740137264),
 (&#39;unlimited&#39;, 1.6724127115954888),
 (&#39;george&#39;, 1.6711314814394402),
 (&#39;birthday&#39;, 1.6692258308130736),
 (&#39;plenty&#39;, 1.6663648179965942),
 (&#39;welcome&#39;, 1.6603691060460284),
 (&#39;styled&#39;, 1.6554230256759237),
 (&#39;speedy&#39;, 1.6514021115331325),
 (&#39;remembered&#39;, 1.6506808709681495),
 (&#39;cinema&#39;, 1.6471782404169475),
 (&#39;le&#39;, 1.64696035175719),
 (&#39;jazz&#39;, 1.6458055566049752),
 (&#39;magic&#39;, 1.6451559950361796),
 (&#39;tesco&#39;, 1.6382860667717587),
 (&#39;flower&#39;, 1.6324274306587991),
 (&#39;milano&#39;, 1.6311778990705061),
 (&#39;genuinely&#39;, 1.6304281883259362),
 (&#39;arranging&#39;, 1.6299164437776412),
 (&#39;chelsea&#39;, 1.6288559982912019),
 (&#39;garden&#39;, 1.6283245790525467),
 (&#39;underground&#39;, 1.6255240501857247),
 (&#39;crisp&#39;, 1.6251040291784997),
 (&#39;tapas&#39;, 1.622860932766241),
 (&#39;interesting&#39;, 1.6224300707277532),
 (&#39;touch&#39;, 1.620843212262114),
 (&#39;celebrating&#39;, 1.6204877486206852),
 (&#39;harbour&#39;, 1.6201907042103623),
 (&#39;del&#39;, 1.6199092123013956),
 (&#39;famous&#39;, 1.6177367152487956),
 (&#39;venues&#39;, 1.616818019731723),
 (&#39;definately&#39;, 1.6166408247281583),
 (&#39;walking&#39;, 1.61626567005127),
 (&#39;lancaster&#39;, 1.6160824551527688),
 (&#39;situated&#39;, 1.6157902426147719),
 (&#39;hill&#39;, 1.6143041020852733),
 (&#39;interiors&#39;, 1.612101029853584),
 (&#39;bond&#39;, 1.6094379124341003),
 (&#39;joy&#39;, 1.6094379124341003),
 (&#39;airports&#39;, 1.6094379124341003),
 (&#39;professionalism&#39;, 1.6059836775660128),
 (&#39;presented&#39;, 1.6043831417724763),
 (&#39;reasonable&#39;, 1.601405740736836),
 (&#39;district&#39;, 1.5959013267165671),
 (&#39;sized&#39;, 1.5949774261030463),
 (&#39;staff&#39;, 1.5938070907212465),
 (&#39;rose&#39;, 1.5920461697222312),
 (&#39;hospitable&#39;, 1.590019826576999),
 (&#39;waterloo&#39;, 1.5885312276147867),
 (&#39;comfort&#39;, 1.5857117665320422),
 (&#39;transports&#39;, 1.575536360758419),
 (&#39;canal&#39;, 1.5754136387848958),
 (&#39;design&#39;, 1.5735241319237332),
 (&#39;skyline&#39;, 1.573505903208037),
 (&#39;eateries&#39;, 1.5718999931150353),
 (&#39;smartphone&#39;, 1.5712166996139025),
 (&#39;zuid&#39;, 1.5664205273504097),
 (&#39;transportation&#39;, 1.5562853054563666),
 (&#39;staf&#39;, 1.5553706911638245),
 (&#39;smiley&#39;, 1.5494948764670669),
 (&#39;wimbledon&#39;, 1.5493339883643948),
 (&#39;rai&#39;, 1.547562508716013),
 (&#39;recommended&#39;, 1.5440928645908993),
 (&#39;plush&#39;, 1.5425436776040702),
 (&#39;cheery&#39;, 1.540445040947149),
 (&#39;deco&#39;, 1.539516966634595),
 (&#39;notting&#39;, 1.5353299402803786),
 (&#39;mile&#39;, 1.5351220184582344),
 (&#39;citizenm&#39;, 1.534714366238164),
 (&#39;comprehensive&#39;, 1.5301885407799598),
 (&#39;touring&#39;, 1.5298852807321466),
 (&#39;shoreditch&#39;, 1.5227695297884265),
 (&#39;connections&#39;, 1.5216989981260935),
 (&#39;located&#39;, 1.5200982456848795),
 (&#39;patient&#39;, 1.519825753744413),
 (&#39;discreet&#39;, 1.5173226235262947),
 (&#39;styling&#39;, 1.5079014932146777),
 (&#39;relaxing&#39;, 1.5070099501975518),
 (&#39;hesitation&#39;, 1.5064386729619539),
 (&#39;el&#39;, 1.4987723445465808),
 (&#39;within&#39;, 1.4978565369011716),
 (&#39;zoo&#39;, 1.4947750041139605),
 (&#39;touristic&#39;, 1.4932664806720584),
 (&#39;confort&#39;, 1.4894785973551214),
 (&#39;tours&#39;, 1.4855925821021712),
 (&#39;affordable&#39;, 1.4837927256047683),
 (&#39;anniversary&#39;, 1.482349419915826),
 (&#39;circle&#39;, 1.4816045409242156),
 (&#39;staffs&#39;, 1.4810216204763482),
 (&#39;bus&#39;, 1.4806738455634652),
 (&#39;hip&#39;, 1.4759065198095778),
 (&#39;vienna&#39;, 1.4739999415389962),
 (&#39;locations&#39;, 1.4699085011610242),
 (&#39;pleasing&#39;, 1.4685324593568627),
 (&#39;la&#39;, 1.4678516468943923),
 (&#39;fun&#39;, 1.466337068793427),
 (&#39;concierges&#39;, 1.4619317753255106),
 (&#39;lake&#39;, 1.4610179073158271),
 (&#39;xx&#39;, 1.4604023332736125),
 (&#39;touristy&#39;, 1.4593194961347804),
 (&#39;rue&#39;, 1.4586150226995167),
 (&#39;definitely&#39;, 1.4579130923623482),
 (&#39;prosecco&#39;, 1.455287232606842),
 (&#39;faulted&#39;, 1.455287232606842),
 (&#39;attentiveness&#39;, 1.4539530095937054),
 (&#39;welcomed&#39;, 1.453258148380061),
 (&#39;train&#39;, 1.4508405565895073),
 (&#39;near&#39;, 1.4501985496175398),
 (&#39;ensured&#39;, 1.4469189829363254),
 (&#39;ms&#39;, 1.4469189829363254),
 (&#39;victorian&#39;, 1.4403615823901663),
 (&#39;barcelona&#39;, 1.436994413880989),
 (&#39;marco&#39;, 1.4350845252893227),
 (&#39;perfectly&#39;, 1.4342228276918414),
 (&#39;catalonia&#39;, 1.4335472459704361),
 (&#39;rainfall&#39;, 1.4271163556401458),
 (&#39;printing&#39;, 1.42529651892316),
 (&#39;catered&#39;, 1.420943496533065),
 (&#39;nicest&#39;, 1.4204273674893493),
 (&#39;lives&#39;, 1.4198170531585343),
 (&#39;cafes&#39;, 1.4184072122370093),
 (&#39;minute&#39;, 1.4131140169563776),
 (&#39;books&#39;, 1.4131056185705473),
 (&#39;exhibition&#39;, 1.4092838793445894),
 (&#39;les&#39;, 1.4081134085145304),
 (&#39;kitchenette&#39;, 1.405342556090585),
 (&#39;creative&#39;, 1.405342556090585),
 (&#39;environment&#39;, 1.400346114575541),
 (&#39;bustling&#39;, 1.3971052772241064),
 (&#39;malpensa&#39;, 1.3962446919730587),
 (&#39;church&#39;, 1.3951833085371366),
 (&#39;impressive&#39;, 1.3935495320010627),
 (&#39;queries&#39;, 1.3915994133495837),
 (&#39;quick&#39;, 1.3905370488586806),
 (&#39;upscale&#39;, 1.3862943611198906),
 (&#39;boulevard&#39;, 1.3862943611198906),
 (&#39;waterfall&#39;, 1.3862943611198906),
 (&#39;linate&#39;, 1.3862943611198906),
 (&#39;river&#39;, 1.3813117897754268),
 (&#39;fast&#39;, 1.3799931430431616),
 (&#39;champagne&#39;, 1.3738718411213333),
 (&#39;ideal&#39;, 1.36939411125513),
 (&#39;mr&#39;, 1.3682758556172123),
 (&#39;tram&#39;, 1.3677358988006378),
 (&#39;ultra&#39;, 1.3672461661491961),
 (&#39;gentle&#39;, 1.3639886036055924),
 (&#39;vast&#39;, 1.3609765531356006),
 (&#39;cooperative&#39;, 1.3581234841531944),
 (&#39;responsive&#39;, 1.3548310916641055),
 (&#39;class&#39;, 1.3514005565673164),
 (&#39;suggestions&#39;, 1.3512030413086205),
 (&#39;pleasent&#39;, 1.3507876726629808),
 (&#39;beyond&#39;, 1.3491033327938105),
 (&#39;genuine&#39;, 1.3444472511843901),
 (&#39;greeted&#39;, 1.343514020511036),
 (&#39;cakes&#39;, 1.341936508489493),
 (&#39;dam&#39;, 1.3397743454849977),
 (&#39;willing&#39;, 1.3392489974298367),
 (&#39;rd&#39;, 1.3339263756025748),
 (&#39;avenue&#39;, 1.3322271398496148),
 (&#39;enormous&#39;, 1.3315438463484823),
 (&#39;lines&#39;, 1.3298802718397993),
 (&#39;organic&#39;, 1.32818673031261),
 (&#39;land&#39;, 1.3277981544382822),
 (&#39;bars&#39;, 1.3270943627315683),
 (&#39;accommodations&#39;, 1.3236587901284056),
 (&#39;assisted&#39;, 1.3217558399823195),
 (&#39;recommend&#39;, 1.3206113225355545),
 (&#39;respectful&#39;, 1.3173014896329391),
 (&#39;magazines&#39;, 1.3156767939059373),
 (&#39;large&#39;, 1.314045701556352),
 (&#39;getaway&#39;, 1.3105825393841943),
 (&#39;tour&#39;, 1.3077040865266691),
 (&#39;best&#39;, 1.3057768049244303),
 (&#39;nespresso&#39;, 1.3017592544835241),
 (&#39;considerate&#39;, 1.3011365527795837),
 (&#39;cruise&#39;, 1.2992829841302609),
 (&#39;disappoint&#39;, 1.2992829841302609),
 (&#39;atmospheric&#39;, 1.2992829841302609),
 (&#39;attraction&#39;, 1.2981459743431858),
 (&#39;smooth&#39;, 1.2980537276755313),
 (&#39;traditional&#39;, 1.2964904662585874),
 (&#39;parisian&#39;, 1.2950456896547455),
 (&#39;politeness&#39;, 1.294356865794205),
 (&#39;wishing&#39;, 1.2934006142271943),
 (&#39;milan&#39;, 1.2932725577683495),
 (&#39;busses&#39;, 1.2878542883066382),
 (&#39;honeymoon&#39;, 1.2863090909865718),
 (&#39;express&#39;, 1.284976588479023),
 (&#39;recently&#39;, 1.279913957561319),
 (&#39;40th&#39;, 1.278080776479658),
 (&#39;artwork&#39;, 1.2770950691548986),
 (&#39;decent&#39;, 1.2763571784346526),
 (&#39;vintage&#39;, 1.2755429968271879),
 (&#39;port&#39;, 1.2722757827189497),
 (&#39;enthusiastic&#39;, 1.2718840099421465),
 (&#39;trouble&#39;, 1.2698617645613786),
 (&#39;10min&#39;, 1.267953133989343),
 (&#39;definetly&#39;, 1.264933504115623),
 (&#39;surprises&#39;, 1.2636920390275583),
 (&#39;square&#39;, 1.262829491996076),
 (&#39;perfection&#39;, 1.252762968495368),
 (&#39;golden&#39;, 1.252762968495368),
 (&#39;designer&#39;, 1.2484245668967697),
 (&#39;cleanness&#39;, 1.2469388402093793),
 (&#39;cleanliness&#39;, 1.2443691763668994),
 (&#39;thoroughly&#39;, 1.2431935174792172),
 (&#39;truly&#39;, 1.2390953297667042),
 (&#39;railway&#39;, 1.238427708408986),
 (&#39;faultless&#39;, 1.2359244041325383),
 (&#39;walk&#39;, 1.233534866715915),
 (&#39;surprisingly&#39;, 1.2312104101096337),
 (&#39;team&#39;, 1.2283118726312037),
 (&#39;plaza&#39;, 1.2237754316221157),
 (&#39;venue&#39;, 1.2237754316221157),
 (&#39;tips&#39;, 1.2237754316221157),
 (&#39;concept&#39;, 1.2230209992966306),
 (&#39;boat&#39;, 1.2222913848496206),
 (&#39;tickets&#39;, 1.2178975437944293),
 (&#39;rooftop&#39;, 1.217805264635612),
 (&#39;gift&#39;, 1.21700230461627),
 (&#39;cocktails&#39;, 1.2127255954355307),
 (&#39;decorations&#39;, 1.2100151187818986),
 (&#39;walks&#39;, 1.2091541630679337),
 (&#39;min&#39;, 1.2028758834292992),
 (&#39;freshly&#39;, 1.2026020021921573),
 (&#39;apples&#39;, 1.202332114868476),
 (&#39;style&#39;, 1.201953475787453),
 (&#39;wishes&#39;, 1.199964782928397),
 (&#39;blocks&#39;, 1.1979105096503901),
 (&#39;tourist&#39;, 1.1973938332278935),
 (&#39;comforts&#39;, 1.1968043148473233),
 (&#39;varied&#39;, 1.1936100172903894),
 (&#39;visit&#39;, 1.1894043884976455),
 (&#39;dlr&#39;, 1.1887633856624071),
 (&#39;posh&#39;, 1.1851527449991661),
 (&#39;docklands&#39;, 1.1837700970084166),
 (&#39;tennis&#39;, 1.1786549963416462),
 (&#39;happily&#39;, 1.1761158498229698),
 (&#39;cleaness&#39;, 1.1749852674526837),
 (&#39;features&#39;, 1.1727202608218317),
 (&#39;hospitality&#39;, 1.1707341628502022),
 (&#39;transit&#39;, 1.170585788293199),
 (&#39;interior&#39;, 1.1666540246654518),
 (&#39;terminal&#39;, 1.1655065234981399),
 (&#39;personnel&#39;, 1.1654935380872489),
 (&#39;buzz&#39;, 1.1645702564599072),
 (&#39;surroundings&#39;, 1.1645310722746391),
 (&#39;riverside&#39;, 1.1611326456494435),
 (&#39;def&#39;, 1.1592369104845446),
 (&#39;ferry&#39;, 1.1576208417962197),
 (&#39;pleased&#39;, 1.1561167831483008),
 (&#39;attractive&#39;, 1.1515346901224521),
 (&#39;recommending&#39;, 1.149503895964499),
 (&#39;intimate&#39;, 1.149384614041533),
 (&#39;houses&#39;, 1.148622709242771),
 (&#39;amsterdam&#39;, 1.1468499865419481),
 (&#39;newspapers&#39;, 1.1451323043030026),
 (&#39;gadgets&#39;, 1.1430640512389434),
 (&#39;guided&#39;, 1.1378330018213911),
 (&#39;hub&#39;, 1.1349799328389845),
 (&#39;marble&#39;, 1.1340696005048392),
 (&#39;wide&#39;, 1.1337344236959361),
 (&#39;commute&#39;, 1.133098464739279),
 (&#39;flawless&#39;, 1.132513840343791),
 (&#39;reachable&#39;, 1.1322288994670946),
 (&#39;recomend&#39;, 1.1322288994670946),
 (&#39;appreciated&#39;, 1.1315118267800361),
 (&#39;kind&#39;, 1.1268733003863205),
 (&#39;john&#39;, 1.1249295969854831),
 (&#39;assortment&#39;, 1.122142786078304),
 (&#39;character&#39;, 1.1211484536905227),
 (&#39;excellence&#39;, 1.1198896871153945),
 (&#39;tech&#39;, 1.1192315758708453),
 (&#39;upgraded&#39;, 1.118831335721416),
 (&#39;underfloor&#39;, 1.1180303745252111),
 (&#39;cuisine&#39;, 1.1169614273363062),
 (&#39;breads&#39;, 1.1162338900179292),
 (&#39;30th&#39;, 1.1148728095398899),
 (&#39;overground&#39;, 1.1130010261202095),
 (&#39;17th&#39;, 1.1118575154181303),
 (&#39;metros&#39;, 1.1113513144455394),
 (&#39;assisting&#39;, 1.110882381259924),
 (&#39;designed&#39;, 1.110139793839177),
 (&#39;gig&#39;, 1.1073459686368643),
 (&#39;sweet&#39;, 1.1065646168586047),
 (&#39;silence&#39;, 1.1059923959657323),
 (&#39;metres&#39;, 1.1059115911497213),
 (&#39;value&#39;, 1.1054229611094646),
 (&#39;lots&#39;, 1.1048987934309307),
 (&#39;flowers&#39;, 1.0986122886681098),
 (&#39;everthing&#39;, 1.0986122886681098),
 (&#39;piano&#39;, 1.0986122886681098),
 (&#39;reccomend&#39;, 1.0986122886681098),
 (&#39;games&#39;, 1.0986122886681098),
 (&#39;paris&#39;, 1.0912849392907822),
 (&#39;charm&#39;, 1.0900285449767182),
 (&#39;well&#39;, 1.089934626216377),
 (&#39;london&#39;, 1.0876310372351607),
 (&#39;definite&#39;, 1.0870514662670339),
 (&#39;accessibility&#39;, 1.0868474470885232),
 (&#39;greeting&#39;, 1.0858325620217109),
 (&#39;bargain&#39;, 1.0826119473216687),
 (&#39;celebration&#39;, 1.0818051703517284),
 (&#39;san&#39;, 1.0813704822336037),
 (&#39;penny&#39;, 1.0785111093470223),
 (&#39;decor&#39;, 1.076886015345732),
 (&#39;terrace&#39;, 1.075628986894004),
 (&#39;theme&#39;, 1.07238127651924),
 (&#39;friendliest&#39;, 1.0704414117014134),
 (&#39;provides&#39;, 1.0647107369924282),
 (&#39;seeing&#39;, 1.0608719606852626),
 (&#39;linens&#39;, 1.0605124424358392),
 (&#39;accommodated&#39;, 1.0547604061392601),
 (&#39;crowds&#39;, 1.051544777810124),
 (&#39;neighborhood&#39;, 1.0509686944694996),
 (&#39;engaging&#39;, 1.0414538748281612),
 (&#39;chocolate&#39;, 1.039613947906154),
 (&#39;attending&#39;, 1.0392256389865981),
 (&#39;cons&#39;, 1.039188868197309),
 (&#39;everything&#39;, 1.0384125696290407),
 (&#39;honesty&#39;, 1.0376515888784226),
 (&#39;15th&#39;, 1.0352426747355203),
 (&#39;stop&#39;, 1.0341785132603754),
 (&#39;amenities&#39;, 1.0331030956107412),
 (&#39;bikes&#39;, 1.0278432177799024),
 (&#39;bakery&#39;, 1.0277862360994972),
 (&#39;spec&#39;, 1.0271533246859648),
 (&#39;15min&#39;, 1.0261572094526874),
 (&#39;classical&#39;, 1.0258529343856813),
 (&#39;michelin&#39;, 1.0252810155825602),
 (&#39;wow&#39;, 1.0228184492985761),
 (&#39;surprise&#39;, 1.0195858881915805),
 (&#39;justice&#39;, 1.0147308046874077),
 (&#39;loads&#39;, 1.0146123142553714),
 (&#39;cross&#39;, 1.0124888797699767),
 (&#39;boarding&#39;, 1.0116009116784799),
 (&#39;viennese&#39;, 1.0116009116784799),
 (&#39;airport&#39;, 1.0095939109803127),
 (&#39;spot&#39;, 1.009371256351211),
 (&#39;concert&#39;, 1.008966635312445),
 (&#39;british&#39;, 1.0062808069154452),
 (&#39;bloomsbury&#39;, 1.0055218656020977),
 (&#39;deck&#39;, 1.0045833390198333),
 (&#39;sparkling&#39;, 1.0044250736084086),
 (&#39;huge&#39;, 1.0033268732921612),
 (&#39;nibbles&#39;, 1.0033021088637848),
 (&#39;mood&#39;, 1.002845383576101),
 (&#39;doorman&#39;, 1.001985452979038),
 (&#39;wherever&#39;, 1.001448540214462),
 (&#39;nightlife&#39;, 1.0011139241832319),
 (&#39;grateful&#39;, 1.0003738490846965),
 (&#39;02&#39;, 1.0002672051686308),
 (&#39;50th&#39;, 0.9985288301111273),
 (&#39;beauty&#39;, 0.9963334395476915),
 (&#39;brand&#39;, 0.9960194185057014),
 (&#39;porters&#39;, 0.9926637106587292),
 (&#39;neighbourhood&#39;, 0.9919062893506337),
 (&#39;inexpensive&#39;, 0.990398704027877),
 (&#39;tastes&#39;, 0.9899784476653143),
 (&#39;rare&#39;, 0.987599759578937),
 (&#39;gate&#39;, 0.9808292530117262),
 (&#39;bicycles&#39;, 0.9808292530117262),
 (&#39;maintained&#39;, 0.9801364923328255),
 (&#39;starbucks&#39;, 0.9780782196398363),
 (&#39;cheeses&#39;, 0.9772514316638422),
 (&#39;360&#39;, 0.9772514316638422),
 (&#39;courtesy&#39;, 0.974998332700933),
 (&#39;grand&#39;, 0.9744862212542925),
 (&#39;helped&#39;, 0.9744662300685875),
 (&#39;sea&#39;, 0.9723185633438176),
 (&#39;muffins&#39;, 0.9718605830289658),
 (&#39;hoxton&#39;, 0.9694005571881035),
 (&#39;city&#39;, 0.9664068630886908),
 (&#39;centre&#39;, 0.9651127477420816),
 (&#39;east&#39;, 0.9633156705190179),
 (&#39;professionally&#39;, 0.958523495497428),
 (&#39;engaged&#39;, 0.9578397347870274),
 (&#39;right&#39;, 0.9573963741058568),
 (&#39;catching&#39;, 0.9555114450274363),
 (&#39;supper&#39;, 0.9555114450274363),
 (&#39;secure&#39;, 0.9547181090080405),
 (&#39;treat&#39;, 0.9505239035163974),
 (&#39;tubes&#39;, 0.9478850972923722),
 (&#39;helping&#39;, 0.9466618297504538),
 (&#39;decoration&#39;, 0.9444616088408515),
 (&#39;spread&#39;, 0.9435746908226235),
 (&#39;ports&#39;, 0.9426080401915286),
 (&#39;snacks&#39;, 0.9424430373036036),
 (&#39;special&#39;, 0.9421763544520381),
 (&#39;sight&#39;, 0.9394440368488719),
 (&#39;short&#39;, 0.9378907198441778),
 (&#39;public&#39;, 0.9375014571583892),
 (&#39;concierge&#39;, 0.9354040281074755),
 (&#39;detail&#39;, 0.9326626947435865),
 (&#39;camp&#39;, 0.931994123802605),
 (&#39;link&#39;, 0.9306794693262548),
 (&#39;college&#39;, 0.9295359586241757),
 (&#39;cleaniness&#39;, 0.9287132518727123),
 (&#39;y&#39;, 0.9284612674944103),
 (&#39;partners&#39;, 0.9270849770050356),
 (&#39;wines&#39;, 0.9111493323737364),
 (&#39;personel&#39;, 0.9106674743197929),
 (&#39;tons&#39;, 0.9075570519054004),
 (&#39;mayfair&#39;, 0.9071582483108824),
 (&#39;convention&#39;, 0.9071582483108824),
 (&#39;umbrella&#39;, 0.9044562742271522),
 (&#39;amazed&#39;, 0.903711949667295),
 (&#39;including&#39;, 0.9036199970534771),
 (&#39;exceedingly&#39;, 0.9028677115420144),
 (&#39;18th&#39;, 0.9019019944220555),
 (&#39;eye&#39;, 0.900693535060487),
 (&#39;range&#39;, 0.8992448646011665),
 (&#39;importantly&#39;, 0.8991962985148549),
 (&#39;rental&#39;, 0.8991229282517897),
 (&#39;extremely&#39;, 0.8973696467599976),
 (&#39;useful&#39;, 0.8963338758178616),
 (&#39;fruits&#39;, 0.8915981192837835),
 (&#39;et&#39;, 0.8873031950009027),
 (&#39;big&#39;, 0.8856948311640399),
 (&#39;downtown&#39;, 0.88560899722167),
 (&#39;minded&#39;, 0.8838873078194958),
 (&#39;kindly&#39;, 0.8838052767296668),
 (&#39;14th&#39;, 0.8835009090511642),
 (&#39;assist&#39;, 0.8825437994488784),
 (&#39;romantic&#39;, 0.8822027695352441),
 (&#39;various&#39;, 0.8804633963279904),
 (&#39;12th&#39;, 0.8799230877032802),
 (&#39;gladly&#39;, 0.8797331361403574),
 (&#39;diverse&#39;, 0.8770700187208738),
 (&#39;town&#39;, 0.875723546885155),
 (&#39;breakfasts&#39;, 0.8750224084020585),
 (&#39;accessible&#39;, 0.8744110957957645),
 (&#39;access&#39;, 0.8734289062746033),
 (&#39;kinds&#39;, 0.8727327575350252),
 (&#39;very&#39;, 0.8720478638061469),
 (&#39;home&#39;, 0.8692026957752536),
 (&#39;austrian&#39;, 0.868351269585036),
 (&#39;maps&#39;, 0.8675005677047231),
 (&#39;yards&#39;, 0.8649974374866045),
 (&#39;smoothly&#39;, 0.8649974374866045),
 (&#39;meters&#39;, 0.8639314529490354),
 (&#39;nearby&#39;, 0.8628458767756885),
 (&#39;interest&#39;, 0.8627499649461252),
 (&#39;sushi&#39;, 0.8602012652231116),
 (&#39;skylounge&#39;, 0.8602012652231116),
 (&#39;bike&#39;, 0.8574502318512216),
 (&#39;ritz&#39;, 0.8574502318512216),
 (&#39;culture&#39;, 0.8574502318512216),
 (&#39;ratio&#39;, 0.857035035665062),
 (&#39;sooo&#39;, 0.8567766043417474),
 (&#39;luxury&#39;, 0.8553399699232861),
 (&#39;chill&#39;, 0.8430873278508602),
 (&#39;surrounded&#39;, 0.8429921486759917),
 (&#39;urban&#39;, 0.8404718953168039),
 (&#39;restored&#39;, 0.8383291904044432),
 (&#39;residential&#39;, 0.8375098540210407),
 (&#39;strand&#39;, 0.837396789404492),
 (&#39;destination&#39;, 0.8367381001722013),
 (&#39;omelettes&#39;, 0.8362480242006185),
 (&#39;ride&#39;, 0.8358691645635807),
 (&#39;hammam&#39;, 0.8342257788198509),
 (&#39;japanese&#39;, 0.8340526336371831),
 (&#39;turkish&#39;, 0.8329091229351039),
 (&#39;blackout&#39;, 0.8324607929567358),
 (&#39;extensive&#39;, 0.8322599830226631),
 (&#39;meats&#39;, 0.8306769791511632),
 (&#39;laid&#39;, 0.826395727757607),
 (&#39;places&#39;, 0.8250612106368027),
 (&#39;highway&#39;, 0.8244831826210323),
 (&#39;foods&#39;, 0.822935162313152),
 (&#39;pure&#39;, 0.8215283472081522),
 (&#39;juices&#39;, 0.8191879014553103),
 (&#39;helps&#39;, 0.8183103235139513),
 (&#39;cocktail&#39;, 0.8140997909776078),
 (&#39;husbands&#39;, 0.8140997909776078),
 (&#39;moment&#39;, 0.8138046073876719),
 (&#39;centrum&#39;, 0.8135108628098204),
 (&#39;marathon&#39;, 0.8128116843160345),
 (&#39;10mins&#39;, 0.8109302162163288),
 (&#39;festival&#39;, 0.8109302162163288),
 (&#39;clever&#39;, 0.8109302162163288),
 (&#39;linen&#39;, 0.8016055183067048),
 (&#39;holland&#39;, 0.7972874398125424),
 (&#39;25th&#39;, 0.7969439742415889),
 (&#39;60th&#39;, 0.7969439742415889),
 (&#39;christmas&#39;, 0.7964062530908144),
 (&#39;liked&#39;, 0.7956792972252575),
 (&#39;purposes&#39;, 0.7939518796819108),
 (&#39;overlooking&#39;, 0.7931863001008034),
 (&#39;here&#39;, 0.7917426709719635),
 (&#39;microwave&#39;, 0.790349508516308),
 (&#39;bright&#39;, 0.7875099420082302),
 (&#39;trams&#39;, 0.7829324844323003),
 (&#39;refreshing&#39;, 0.7806064858885313),
 (&#39;doctor&#39;, 0.7777045685880083),
 (&#39;park&#39;, 0.7760402464578382),
 (&#39;north&#39;, 0.7757087812529657),
 (&#39;across&#39;, 0.7748443971466626),
 (&#39;easter&#39;, 0.7748252115742124),
 (&#39;center&#39;, 0.7743133936883122),
 (&#39;films&#39;, 0.7731898882334817),
 (&#39;selection&#39;, 0.7716951196442524),
 ...]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># words most frequently seen in a review with a &quot;NEGATIVE&quot; label</span>
<span class="nb">list</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">pos_neg_ratios</span><span class="o">.</span><span class="n">most_common</span><span class="p">()))[</span><span class="mi">0</span><span class="p">:</span><span class="mi">30</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[19]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[(&#39;mouldy&#39;, -inf),
 (&#39;unusable&#39;, -5.19295685089021),
 (&#39;unstable&#39;, -4.757891273005756),
 (&#39;powdered&#39;, -4.68213122712422),
 (&#39;inappropriate&#39;, -4.663439094112067),
 (&#39;scratched&#39;, -4.269697449699962),
 (&#39;positive&#39;, -4.2036140943766425),
 (&#39;intermittent&#39;, -4.132496328186477),
 (&#39;sewer&#39;, -4.102643365036796),
 (&#39;flushed&#39;, -4.102643365036796),
 (&#39;repairs&#39;, -4.088773517172645),
 (&#39;vent&#39;, -4.038655656361512),
 (&#39;hopeless&#39;, -4.02535169073515),
 (&#39;skirting&#39;, -4.007333185232471),
 (&#39;damaged&#39;, -3.970291913552122),
 (&#39;loudly&#39;, -3.967592856582957),
 (&#39;untidy&#39;, -3.9415818076696905),
 (&#39;disorganised&#39;, -3.927896354584436),
 (&#39;leaked&#39;, -3.867722746531566),
 (&#39;unreliable&#39;, -3.801091444720864),
 (&#39;flushing&#39;, -3.801091444720864),
 (&#39;bins&#39;, -3.7992275112828016),
 (&#39;rudely&#39;, -3.784189633918261),
 (&#39;chipped&#39;, -3.7545334243353734),
 (&#39;unacceptable&#39;, -3.726401893437026),
 (&#39;torn&#39;, -3.7184382563554808),
 (&#39;patchy&#39;, -3.672072335797555),
 (&#39;mold&#39;, -3.66612246699132),
 (&#39;sewage&#39;, -3.6450768314555435),
 (&#39;erratic&#39;, -3.6375861597263857)]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vocab</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">total_counts</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>81295
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">layer_0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">vocab_size</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[38]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">layer_0</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[38]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(1, 81295)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Create a dictionary of words in the vocabulary mapped to index positions </span>
<span class="c1"># (to be used in layer_0)</span>
<span class="n">word2index</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">):</span>
    <span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
    
<span class="c1"># display the map of words to indices</span>
<span class="n">word2index</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[23]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>{&#39;&#39;: 0,
 &#39;helpfuld&#39;: 1,
 &#39;flexibililty&#39;: 2,
 &#39;damaging&#39;: 3,
 &#39;beutefull&#39;: 4,
 &#39;unfamiliar&#39;: 5,
 &#39;comissions&#39;: 6,
 &#39;delishious&#39;: 7,
 &#39;hs&#39;: 8,
 &#39;lazaro&#39;: 9,
 &#39;matrasse&#39;: 10,
 &#39;chloroform&#39;: 11,
 &#39;ands&#39;: 12,
 &#39;reppublic&#39;: 13,
 &#39;for5&#39;: 14,
 &#39;entends&#39;: 15,
 &#39;daniele&#39;: 16,
 &#39;hiwever&#39;: 17,
 &#39;suitabje&#39;: 18,
 &#39;yataklar&#39;: 19,
 &#39;orders&#39;: 20,
 &#39;amabile&#39;: 21,
 &#39;vetter&#39;: 22,
 &#39;pastried&#39;: 23,
 &#39;apprehensive&#39;: 24,
 &#39;protecting&#39;: 25,
 &#39;attracts&#39;: 26,
 &#39;execially&#39;: 27,
 &#39;spitalfield&#39;: 28,
 &#39;schould&#39;: 29,
 &#39;blood&#39;: 30,
 &#39;3081032&#39;: 31,
 &#39;sumptuos&#39;: 32,
 &#39;hurted&#39;: 33,
 &#39;restorated&#39;: 34,
 &#39;elivater&#39;: 35,
 &#39;juste&#39;: 36,
 &#39;dockland&#39;: 37,
 &#39;poorer&#39;: 38,
 &#39;daim&#39;: 39,
 &#39;billboard&#39;: 40,
 &#39;cubical&#39;: 41,
 &#39;cusp&#39;: 42,
 &#39;stygian&#39;: 43,
 &#39;faq&#39;: 44,
 &#39;glores&#39;: 45,
 &#39;glazier&#39;: 46,
 &#39;failry&#39;: 47,
 &#39;juli&#39;: 48,
 &#39;showercwater&#39;: 49,
 &#39;althoughe&#39;: 50,
 &#39;wormy&#39;: 51,
 &#39;store&#39;: 52,
 &#39;oreinted&#39;: 53,
 &#39;begger&#39;: 54,
 &#39;depandance&#39;: 55,
 &#39;reverts&#39;: 56,
 &#39;valyr&#39;: 57,
 &#39;trem&#39;: 58,
 &#39;bub&#39;: 59,
 &#39;hone&#39;: 60,
 &#39;doorways&#39;: 61,
 &#39;annexes&#39;: 62,
 &#39;streetside&#39;: 63,
 &#39;ironic&#39;: 64,
 &#39;ynder&#39;: 65,
 &#39;sunshine&#39;: 66,
 &#39;simpatico&#39;: 67,
 &#39;negressco&#39;: 68,
 &#39;tealess&#39;: 69,
 &#39;pacing&#39;: 70,
 &#39;feadback&#39;: 71,
 &#39;scottish&#39;: 72,
 &#39;wanderful&#39;: 73,
 &#39;336&#39;: 74,
 &#39;eals&#39;: 75,
 &#39;localised&#39;: 76,
 &#39;alternatives&#39;: 77,
 &#39;karlzplatz&#39;: 78,
 &#39;sherly&#39;: 79,
 &#39;pampering&#39;: 80,
 &#39;oay&#39;: 81,
 &#39;krays&#39;: 82,
 &#39;gettinf&#39;: 83,
 &#39;litre&#39;: 84,
 &#39;20mins&#39;: 85,
 &#39;juliet&#39;: 86,
 &#39;taho&#39;: 87,
 &#39;kathereen&#39;: 88,
 &#39;media&#39;: 89,
 &#39;struglled&#39;: 90,
 &#39;liuigi&#39;: 91,
 &#39;x6&#39;: 92,
 &#39;dian&#39;: 93,
 &#39;painfully&#39;: 94,
 &#39;excerise&#39;: 95,
 &#39;paited&#39;: 96,
 &#39;wentilation&#39;: 97,
 &#39;operative&#39;: 98,
 &#39;dissatisfying&#39;: 99,
 &#39;spilling&#39;: 100,
 &#39;whart&#39;: 101,
 &#39;cataluyna&#39;: 102,
 &#39;bool&#39;: 103,
 &#39;mcdonnalds&#39;: 104,
 &#39;verve&#39;: 105,
 &#39;elevaion&#39;: 106,
 &#39;wounded&#39;: 107,
 &#39;neigberhood&#39;: 108,
 &#39;photocopies&#39;: 109,
 &#39;10mbps&#39;: 110,
 &#39;dealer&#39;: 111,
 &#39;delux&#39;: 112,
 &#39;buddhist&#39;: 113,
 &#39;chateaus&#39;: 114,
 &#39;britania&#39;: 115,
 &#39;exposing&#39;: 116,
 &#39;contactbooking&#39;: 117,
 &#39;73yr&#39;: 118,
 &#39;thepicture&#39;: 119,
 &#39;clearlly&#39;: 120,
 &#39;seemt&#39;: 121,
 &#39;retained&#39;: 122,
 &#39;belled&#39;: 123,
 &#39;separators&#39;: 124,
 &#39;onif&#39;: 125,
 &#39;leidisplain&#39;: 126,
 &#39;contaminates&#39;: 127,
 &#39;quit&#39;: 128,
 &#39;tiresome&#39;: 129,
 &#39;thouroghly&#39;: 130,
 &#39;panettone&#39;: 131,
 &#39;blowdrier&#39;: 132,
 &#39;propriety&#39;: 133,
 &#39;occupents&#39;: 134,
 &#39;keft&#39;: 135,
 &#39;8009&#39;: 136,
 &#39;wilkinson&#39;: 137,
 &#39;reloje&#39;: 138,
 &#39;textiles&#39;: 139,
 &#39;appenrently&#39;: 140,
 &#39;mentioned&#39;: 141,
 &#39;cheaply&#39;: 142,
 &#39;konumu&#39;: 143,
 &#39;metrou&#39;: 144,
 &#39;castille&#39;: 145,
 &#39;overhaul&#39;: 146,
 &#39;aprat&#39;: 147,
 &#39;borederline&#39;: 148,
 &#39;noide&#39;: 149,
 &#39;hallam&#39;: 150,
 &#39;disclaimers&#39;: 151,
 &#39;waitor&#39;: 152,
 &#39;peacefully&#39;: 153,
 &#39;caved&#39;: 154,
 &#39;ammaaaaaazing&#39;: 155,
 &#39;1029&#39;: 156,
 &#39;hued&#39;: 157,
 &#39;unneeded&#39;: 158,
 &#39;elies&#39;: 159,
 &#39;rivals&#39;: 160,
 &#39;reakfest&#39;: 161,
 &#39;transformer&#39;: 162,
 &#39;panther&#39;: 163,
 &#39;departude&#39;: 164,
 &#39;adrees&#39;: 165,
 &#39;rv1&#39;: 166,
 &#39;gowned&#39;: 167,
 &#39;pruce&#39;: 168,
 &#39;fore&#39;: 169,
 &#39;grandparents&#39;: 170,
 &#39;hited&#39;: 171,
 &#39;souffle&#39;: 172,
 &#39;gratitute&#39;: 173,
 &#39;amorous&#39;: 174,
 &#39;statements&#39;: 175,
 &#39;optimize&#39;: 176,
 &#39;akin&#39;: 177,
 &#39;professiona&#39;: 178,
 &#39;chillers&#39;: 179,
 &#39;yoaan&#39;: 180,
 &#39;bycicles&#39;: 181,
 &#39;breezier&#39;: 182,
 &#39;englander&#39;: 183,
 &#39;plantroom&#39;: 184,
 &#39;vera&#39;: 185,
 &#39;delious&#39;: 186,
 &#39;soaf&#39;: 187,
 &#39;signals&#39;: 188,
 &#39;discarded&#39;: 189,
 &#39;obligations&#39;: 190,
 &#39;cutterry&#39;: 191,
 &#39;roomhad&#39;: 192,
 &#39;4adults&#39;: 193,
 &#39;cau&#39;: 194,
 &#39;halyard&#39;: 195,
 &#39;compimentary&#39;: 196,
 &#39;sowelcoming&#39;: 197,
 &#39;wet&#39;: 198,
 &#39;torwards&#39;: 199,
 &#39;e17&#39;: 200,
 &#39;peinado&#39;: 201,
 &#39;gardini&#39;: 202,
 &#39;lemony&#39;: 203,
 &#39;thme&#39;: 204,
 &#39;lactofree&#39;: 205,
 &#39;intrigue&#39;: 206,
 &#39;churchs&#39;: 207,
 &#39;locatine&#39;: 208,
 &#39;petites&#39;: 209,
 &#39;sto&#39;: 210,
 &#39;frederique&#39;: 211,
 &#39;pplentiful&#39;: 212,
 &#39;showerthough&#39;: 213,
 &#39;sweaties&#39;: 214,
 &#39;spritz&#39;: 215,
 &#39;trans&#39;: 216,
 &#39;tapa&#39;: 217,
 &#39;llke&#39;: 218,
 &#39;n00&#39;: 219,
 &#39;fiorina&#39;: 220,
 &#39;cengiz&#39;: 221,
 &#39;mastic&#39;: 222,
 &#39;gavin&#39;: 223,
 &#39;whooptie&#39;: 224,
 &#39;korner&#39;: 225,
 &#39;estacio&#39;: 226,
 &#39;bowie&#39;: 227,
 &#39;complacency&#39;: 228,
 &#39;radioed&#39;: 229,
 &#39;jaro&#39;: 230,
 &#39;battled&#39;: 231,
 &#39;mantainance&#39;: 232,
 &#39;vrv&#39;: 233,
 &#39;avoide&#39;: 234,
 &#39;buidings&#39;: 235,
 &#39;storrs&#39;: 236,
 &#39;jacuzzi&#39;: 237,
 &#39;incredibley&#39;: 238,
 &#39;brainer&#39;: 239,
 &#39;ll&#39;: 240,
 &#39;unuseful&#39;: 241,
 &#39;stroop&#39;: 242,
 &#39;bemoaned&#39;: 243,
 &#39;frederic&#39;: 244,
 &#39;springs&#39;: 245,
 &#39;backings&#39;: 246,
 &#39;fromageries&#39;: 247,
 &#39;e4&#39;: 248,
 &#39;1050pm&#39;: 249,
 &#39;californian&#39;: 250,
 &#39;malfunctioning&#39;: 251,
 &#39;jumper&#39;: 252,
 &#39;loccitane&#39;: 253,
 &#39;mateesss&#39;: 254,
 &#39;continentals&#39;: 255,
 &#39;creecky&#39;: 256,
 &#39;poooor&#39;: 257,
 &#39;camer&#39;: 258,
 &#39;costcutting&#39;: 259,
 &#39;7sqm&#39;: 260,
 &#39;spnent&#39;: 261,
 &#39;enviornement&#39;: 262,
 &#39;yannick&#39;: 263,
 &#39;attentive&#39;: 264,
 &#39;helplessly&#39;: 265,
 &#39;catastrofic&#39;: 266,
 &#39;corporates&#39;: 267,
 &#39;catania&#39;: 268,
 &#39;dislake&#39;: 269,
 &#39;blindes&#39;: 270,
 &#39;heizung&#39;: 271,
 &#39;aroun&#39;: 272,
 &#39;supreme&#39;: 273,
 &#39;mny&#39;: 274,
 &#39;costa&#39;: 275,
 &#39;replaces&#39;: 276,
 &#39;taximeters&#39;: 277,
 &#39;twinroom&#39;: 278,
 &#39;seagulls&#39;: 279,
 &#39;camile&#39;: 280,
 &#39;revealed&#39;: 281,
 &#39;victorica&#39;: 282,
 &#39;glaciere&#39;: 283,
 &#39;pedal&#39;: 284,
 &#39;daytime&#39;: 285,
 &#39;inidividuals&#39;: 286,
 &#39;jacuuzzi&#39;: 287,
 &#39;dividers&#39;: 288,
 &#39;shover&#39;: 289,
 &#39;wrist&#39;: 290,
 &#39;exent&#39;: 291,
 &#39;handeling&#39;: 292,
 &#39;unpgrade&#39;: 293,
 &#39;jellies&#39;: 294,
 &#39;quieter&#39;: 295,
 &#39;foulded&#39;: 296,
 &#39;croiassante&#39;: 297,
 &#39;badell&#39;: 298,
 &#39;lioking&#39;: 299,
 &#39;icecold&#39;: 300,
 &#39;relise&#39;: 301,
 &#39;respsionist&#39;: 302,
 &#39;thebpurpose&#39;: 303,
 &#39;fly&#39;: 304,
 &#39;doorperson&#39;: 305,
 &#39;townhouse&#39;: 306,
 &#39;woke&#39;: 307,
 &#39;fatima&#39;: 308,
 &#39;brakefeast&#39;: 309,
 &#39;tres&#39;: 310,
 &#39;sheshen&#39;: 311,
 &#39;beneden&#39;: 312,
 &#39;sneezed&#39;: 313,
 &#39;rattley&#39;: 314,
 &#39;toucan&#39;: 315,
 &#39;custumers&#39;: 316,
 &#39;cadeques&#39;: 317,
 &#39;saladas&#39;: 318,
 &#39;edu&#39;: 319,
 &#39;icc&#39;: 320,
 &#39;vegetarion&#39;: 321,
 &#39;boooking&#39;: 322,
 &#39;nagive&#39;: 323,
 &#39;hoetel&#39;: 324,
 &#39;meal&#39;: 325,
 &#39;babaye&#39;: 326,
 &#39;easily&#39;: 327,
 &#39;bleh&#39;: 328,
 &#39;tousist&#39;: 329,
 &#39;reaaaaly&#39;: 330,
 &#39;configuraitons&#39;: 331,
 &#39;alernate&#39;: 332,
 &#39;smaal&#39;: 333,
 &#39;hitzing&#39;: 334,
 &#39;sponges&#39;: 335,
 &#39;interrupted&#39;: 336,
 &#39;c4&#39;: 337,
 &#39;clash&#39;: 338,
 &#39;twentieth&#39;: 339,
 &#39;wreaked&#39;: 340,
 &#39;parlemant&#39;: 341,
 &#39;twater&#39;: 342,
 &#39;brakefest&#39;: 343,
 &#39;tramps&#39;: 344,
 &#39;heter&#39;: 345,
 &#39;helmet&#39;: 346,
 &#39;spikes&#39;: 347,
 &#39;fantatic&#39;: 348,
 &#39;competitions&#39;: 349,
 &#39;toy&#39;: 350,
 &#39;boycott&#39;: 351,
 &#39;sputtered&#39;: 352,
 &#39;barri&#39;: 353,
 &#39;excpensive&#39;: 354,
 &#39;interlinking&#39;: 355,
 &#39;confortabil&#39;: 356,
 &#39;trey&#39;: 357,
 &#39;2007&#39;: 358,
 &#39;dolmans&#39;: 359,
 &#39;inexperience&#39;: 360,
 &#39;credit&#39;: 361,
 &#39;mailliot&#39;: 362,
 &#39;anger&#39;: 363,
 &#39;fibres&#39;: 364,
 &#39;heavenly&#39;: 365,
 &#39;hasson&#39;: 366,
 &#39;room105&#39;: 367,
 &#39;furnited&#39;: 368,
 &#39;printme&#39;: 369,
 &#39;aslong&#39;: 370,
 &#39;cornetto&#39;: 371,
 &#39;shunned&#39;: 372,
 &#39;vermeer&#39;: 373,
 &#39;intuitive&#39;: 374,
 &#39;cavour&#39;: 375,
 &#39;centralstation&#39;: 376,
 &#39;israeli&#39;: 377,
 &#39;facitlities&#39;: 378,
 &#39;gnat&#39;: 379,
 &#39;downtairs&#39;: 380,
 &#39;cheffs&#39;: 381,
 &#39;unventilated&#39;: 382,
 &#39;mellan&#39;: 383,
 &#39;transaction&#39;: 384,
 &#39;park&#39;: 385,
 &#39;shrugged&#39;: 386,
 &#39;reward&#39;: 387,
 &#39;draing&#39;: 388,
 &#39;humility&#39;: 389,
 &#39;supliments&#39;: 390,
 &#39;indented&#39;: 391,
 &#39;row&#39;: 392,
 &#39;ballcony&#39;: 393,
 &#39;liddle&#39;: 394,
 &#39;steeped&#39;: 395,
 &#39;clerks&#39;: 396,
 &#39;frother&#39;: 397,
 &#39;nuts&#39;: 398,
 &#39;t1&#39;: 399,
 &#39;gethsemane&#39;: 400,
 &#39;whereby&#39;: 401,
 &#39;jakob&#39;: 402,
 &#39;upgradadtion&#39;: 403,
 &#39;teeny&#39;: 404,
 &#39;quiries&#39;: 405,
 &#39;pestered&#39;: 406,
 &#39;crime&#39;: 407,
 &#39;stevan&#39;: 408,
 &#39;imformation&#39;: 409,
 &#39;banister&#39;: 410,
 &#39;consumate&#39;: 411,
 &#39;ausencia&#39;: 412,
 &#39;chanos&#39;: 413,
 &#39;altirnative&#39;: 414,
 &#39;3xx&#39;: 415,
 &#39;stra&#39;: 416,
 &#39;castletroy&#39;: 417,
 &#39;quilt&#39;: 418,
 &#39;1400hours&#39;: 419,
 &#39;religous&#39;: 420,
 &#39;radiators&#39;: 421,
 &#39;gulps&#39;: 422,
 &#39;centricity&#39;: 423,
 &#39;extra15&#39;: 424,
 &#39;documented&#39;: 425,
 &#39;generla&#39;: 426,
 &#39;irritation&#39;: 427,
 &#39;checked&#39;: 428,
 &#39;walkabout&#39;: 429,
 &#39;caliu&#39;: 430,
 &#39;faktura&#39;: 431,
 &#39;gaved&#39;: 432,
 &#39;shaker&#39;: 433,
 &#39;facs&#39;: 434,
 &#39;montse&#39;: 435,
 &#39;teaste&#39;: 436,
 &#39;serait&#39;: 437,
 &#39;mariahilferkirche&#39;: 438,
 &#39;utensill&#39;: 439,
 &#39;mohamed&#39;: 440,
 &#39;storlek&#39;: 441,
 &#39;yourselves&#39;: 442,
 &#39;tampax&#39;: 443,
 &#39;wather&#39;: 444,
 &#39;boufett&#39;: 445,
 &#39;modrenisation&#39;: 446,
 &#39;dinkng&#39;: 447,
 &#39;crossroads&#39;: 448,
 &#39;tunnel&#39;: 449,
 &#39;tasety&#39;: 450,
 &#39;quicken&#39;: 451,
 &#39;brigit&#39;: 452,
 &#39;notably&#39;: 453,
 &#39;directionally&#39;: 454,
 &#39;inconvienient&#39;: 455,
 &#39;sparklingly&#39;: 456,
 &#39;rectangular&#39;: 457,
 &#39;bullring&#39;: 458,
 &#39;vacationer&#39;: 459,
 &#39;gorky&#39;: 460,
 &#39;scrbed&#39;: 461,
 &#39;mariah&#39;: 462,
 &#39;devuce&#39;: 463,
 &#39;cmfortable&#39;: 464,
 &#39;adorator&#39;: 465,
 &#39;rnigt&#39;: 466,
 &#39;battle&#39;: 467,
 &#39;89eur&#39;: 468,
 &#39;maximus&#39;: 469,
 &#39;handbasin&#39;: 470,
 &#39;appeares&#39;: 471,
 &#39;laramda&#39;: 472,
 &#39;threads&#39;: 473,
 &#39;exhibtion&#39;: 474,
 &#39;breakfa&#39;: 475,
 &#39;macdonald&#39;: 476,
 &#39;gripes&#39;: 477,
 &#39;batches&#39;: 478,
 &#39;holdings&#39;: 479,
 &#39;configurations&#39;: 480,
 &#39;tasco&#39;: 481,
 &#39;decolorated&#39;: 482,
 &#39;picking&#39;: 483,
 &#39;tonis&#39;: 484,
 &#39;impersonality&#39;: 485,
 &#39;makingkit&#39;: 486,
 &#39;personnally&#39;: 487,
 &#39;clatter&#39;: 488,
 &#39;wirkung&#39;: 489,
 &#39;widisha&#39;: 490,
 &#39;sade&#39;: 491,
 &#39;probleme&#39;: 492,
 &#39;extreeemmmly&#39;: 493,
 &#39;itemisation&#39;: 494,
 &#39;prau&#39;: 495,
 &#39;603&#39;: 496,
 &#39;samsonite&#39;: 497,
 &#39;nazmul&#39;: 498,
 &#39;mentally&#39;: 499,
 &#39;6m&#39;: 500,
 &#39;viewing&#39;: 501,
 &#39;renevations&#39;: 502,
 &#39;locati&#39;: 503,
 &#39;gruop&#39;: 504,
 &#39;thanked&#39;: 505,
 &#39;accidentals&#39;: 506,
 &#39;vegiterians&#39;: 507,
 &#39;lal&#39;: 508,
 &#39;savino&#39;: 509,
 &#39;considerar&#39;: 510,
 &#39;marvellously&#39;: 511,
 &#39;efficacit&#39;: 512,
 &#39;yuou&#39;: 513,
 &#39;ncie&#39;: 514,
 &#39;flexabikity&#39;: 515,
 &#39;prompt&#39;: 516,
 &#39;londoneye&#39;: 517,
 &#39;atraccions&#39;: 518,
 &#39;apere&#39;: 519,
 &#39;caramelise&#39;: 520,
 &#39;ntia&#39;: 521,
 &#39;maneuvering&#39;: 522,
 &#39;fray&#39;: 523,
 &#39;stas&#39;: 524,
 &#39;tim&#39;: 525,
 &#39;2000s&#39;: 526,
 &#39;wewe&#39;: 527,
 &#39;persinal&#39;: 528,
 &#39;palca&#39;: 529,
 &#39;genre&#39;: 530,
 &#39;circunstances&#39;: 531,
 &#39;crticism&#39;: 532,
 &#39;prevenant&#39;: 533,
 &#39;repitative&#39;: 534,
 &#39;executice&#39;: 535,
 &#39;proverbial&#39;: 536,
 &#39;sewagey&#39;: 537,
 &#39;morethan&#39;: 538,
 &#39;taxo&#39;: 539,
 &#39;lader&#39;: 540,
 &#39;claustophobic&#39;: 541,
 &#39;straighteners&#39;: 542,
 &#39;curie&#39;: 543,
 &#39;seconn&#39;: 544,
 &#39;oficer&#39;: 545,
 &#39;swamped&#39;: 546,
 &#39;petting&#39;: 547,
 &#39;exspensieve&#39;: 548,
 &#39;mornings&#39;: 549,
 &#39;nocontrol&#39;: 550,
 &#39;wallow&#39;: 551,
 &#39;bb1&#39;: 552,
 &#39;rabbah&#39;: 553,
 &#39;41euro&#39;: 554,
 &#39;uberx&#39;: 555,
 &#39;extral&#39;: 556,
 &#39;colorfull&#39;: 557,
 &#39;serevice&#39;: 558,
 &#39;refereshments&#39;: 559,
 &#39;reviewsabout&#39;: 560,
 &#39;nn&#39;: 561,
 &#39;hell&#39;: 562,
 &#39;perturbated&#39;: 563,
 &#39;refrezer&#39;: 564,
 &#39;eyc&#39;: 565,
 &#39;napler&#39;: 566,
 &#39;colon&#39;: 567,
 &#39;stroked&#39;: 568,
 &#39;roport&#39;: 569,
 &#39;curr&#39;: 570,
 &#39;syphon&#39;: 571,
 &#39;deft&#39;: 572,
 &#39;funebre&#39;: 573,
 &#39;importlantly&#39;: 574,
 &#39;stephendom&#39;: 575,
 &#39;erasable&#39;: 576,
 &#39;238&#39;: 577,
 &#39;starry&#39;: 578,
 &#39;rumanian&#39;: 579,
 &#39;smeg&#39;: 580,
 &#39;davin&#39;: 581,
 &#39;elevates&#39;: 582,
 &#39;crabtree&#39;: 583,
 &#39;monastery&#39;: 584,
 &#39;bowed&#39;: 585,
 &#39;stead&#39;: 586,
 &#39;bath&#39;: 587,
 &#39;investigator&#39;: 588,
 &#39;fastfood&#39;: 589,
 &#39;tempertute&#39;: 590,
 &#39;exempted&#39;: 591,
 &#39;empathy&#39;: 592,
 &#39;wyfi&#39;: 593,
 &#39;problenou&#39;: 594,
 &#39;amddv&#39;: 595,
 &#39;desapointed&#39;: 596,
 &#39;llaguna&#39;: 597,
 &#39;everynight&#39;: 598,
 &#39;singe&#39;: 599,
 &#39;girlies&#39;: 600,
 &#39;showed&#39;: 601,
 &#39;existence&#39;: 602,
 &#39;colonial&#39;: 603,
 &#39;emphasis&#39;: 604,
 &#39;cecciones&#39;: 605,
 &#39;carachter&#39;: 606,
 &#39;turks&#39;: 607,
 &#39;fabia&#39;: 608,
 &#39;unadjustable&#39;: 609,
 &#39;copenhagen&#39;: 610,
 &#39;snacked&#39;: 611,
 &#39;piso&#39;: 612,
 &#39;offfered&#39;: 613,
 &#39;deepness&#39;: 614,
 &#39;greatlocation&#39;: 615,
 &#39;itcwascredilved&#39;: 616,
 &#39;goodas&#39;: 617,
 &#39;beeg&#39;: 618,
 &#39;abbesses&#39;: 619,
 &#39;coredor&#39;: 620,
 &#39;nife&#39;: 621,
 &#39;accounting&#39;: 622,
 &#39;pointed&#39;: 623,
 &#39;regrettable&#39;: 624,
 &#39;rtnerstrasse&#39;: 625,
 &#39;unsympathetically&#39;: 626,
 &#39;evailable&#39;: 627,
 &#39;reform&#39;: 628,
 &#39;interspersed&#39;: 629,
 &#39;iznad&#39;: 630,
 &#39;effecte&#39;: 631,
 &#39;battop&#39;: 632,
 &#39;rw&#39;: 633,
 &#39;album&#39;: 634,
 &#39;mbit&#39;: 635,
 &#39;resurants&#39;: 636,
 &#39;showecaps&#39;: 637,
 &#39;crissiants&#39;: 638,
 &#39;liile&#39;: 639,
 &#39;abdalla&#39;: 640,
 &#39;theatres&#39;: 641,
 &#39;strolled&#39;: 642,
 &#39;hanger&#39;: 643,
 &#39;6001&#39;: 644,
 &#39;foosball&#39;: 645,
 &#39;allowance&#39;: 646,
 &#39;barcelonia&#39;: 647,
 &#39;budapest&#39;: 648,
 &#39;suitabe&#39;: 649,
 &#39;husbond&#39;: 650,
 &#39;50e&#39;: 651,
 &#39;actives&#39;: 652,
 &#39;genus&#39;: 653,
 &#39;criminally&#39;: 654,
 &#39;daiana&#39;: 655,
 &#39;crude&#39;: 656,
 &#39;schaeferer&#39;: 657,
 &#39;handbasins&#39;: 658,
 &#39;countyard&#39;: 659,
 &#39;worded&#39;: 660,
 &#39;hernandez&#39;: 661,
 &#39;entrepreneurial&#39;: 662,
 &#39;obvioubsly&#39;: 663,
 &#39;francis&#39;: 664,
 &#39;znr&#39;: 665,
 &#39;reviving&#39;: 666,
 &#39;kisstory&#39;: 667,
 &#39;elyssees&#39;: 668,
 &#39;marcella&#39;: 669,
 &#39;25&#39;: 670,
 &#39;alrady&#39;: 671,
 &#39;withou&#39;: 672,
 &#39;writes&#39;: 673,
 &#39;treatments&#39;: 674,
 &#39;arival&#39;: 675,
 &#39;neighboorhing&#39;: 676,
 &#39;venura&#39;: 677,
 &#39;substations&#39;: 678,
 &#39;repellent&#39;: 679,
 &#39;shoppe&#39;: 680,
 &#39;25degrees&#39;: 681,
 &#39;4times&#39;: 682,
 &#39;transpot&#39;: 683,
 &#39;emitting&#39;: 684,
 &#39;reservations&#39;: 685,
 &#39;couch&#39;: 686,
 &#39;brief&#39;: 687,
 &#39;communted&#39;: 688,
 &#39;adhd&#39;: 689,
 &#39;6minutes&#39;: 690,
 &#39;languagues&#39;: 691,
 &#39;unformality&#39;: 692,
 &#39;trustable&#39;: 693,
 &#39;assisstance&#39;: 694,
 &#39;dripoing&#39;: 695,
 &#39;recipation&#39;: 696,
 &#39;trajan&#39;: 697,
 &#39;loacated&#39;: 698,
 &#39;amina&#39;: 699,
 &#39;estation&#39;: 700,
 &#39;aproach&#39;: 701,
 &#39;resive&#39;: 702,
 &#39;overprice&#39;: 703,
 &#39;whacked&#39;: 704,
 &#39;dobbeltsengen&#39;: 705,
 &#39;chandon&#39;: 706,
 &#39;100times&#39;: 707,
 &#39;diagsnol&#39;: 708,
 &#39;alternativt&#39;: 709,
 &#39;knowledgeful&#39;: 710,
 &#39;likening&#39;: 711,
 &#39;heartbreaking&#39;: 712,
 &#39;wxyz&#39;: 713,
 &#39;comparisom&#39;: 714,
 &#39;barth&#39;: 715,
 &#39;dyr&#39;: 716,
 &#39;mchines&#39;: 717,
 &#39;aimlessly&#39;: 718,
 &#39;wait&#39;: 719,
 &#39;guise&#39;: 720,
 &#39;brooer&#39;: 721,
 &#39;brekefast&#39;: 722,
 &#39;encrypted&#39;: 723,
 &#39;begining&#39;: 724,
 &#39;worldy&#39;: 725,
 &#39;sulky&#39;: 726,
 &#39;practicate&#39;: 727,
 &#39;burthday&#39;: 728,
 &#39;materessess&#39;: 729,
 &#39;chambermaid&#39;: 730,
 &#39;relax&#39;: 731,
 &#39;possibility&#39;: 732,
 &#39;flue&#39;: 733,
 &#39;rumoroso&#39;: 734,
 &#39;tanjia&#39;: 735,
 &#39;tomorow&#39;: 736,
 &#39;defenatelly&#39;: 737,
 &#39;reburbed&#39;: 738,
 &#39;sp34&#39;: 739,
 &#39;acumindation&#39;: 740,
 &#39;yohhurts&#39;: 741,
 &#39;altstad&#39;: 742,
 &#39;hated&#39;: 743,
 &#39;nery&#39;: 744,
 &#39;stiftskeller&#39;: 745,
 &#39;spicily&#39;: 746,
 &#39;scrunchies&#39;: 747,
 &#39;animes&#39;: 748,
 &#39;studenthe&#39;: 749,
 &#39;floorspace&#39;: 750,
 &#39;infinite&#39;: 751,
 &#39;malmaison&#39;: 752,
 &#39;evryone&#39;: 753,
 &#39;col&#39;: 754,
 &#39;buckingham&#39;: 755,
 &#39;comport&#39;: 756,
 &#39;numberings&#39;: 757,
 &#39;invoces&#39;: 758,
 &#39;rsin&#39;: 759,
 &#39;frau&#39;: 760,
 &#39;incl&#39;: 761,
 &#39;fercility&#39;: 762,
 &#39;michelangelo&#39;: 763,
 &#39;1200gbp&#39;: 764,
 &#39;andeibd&#39;: 765,
 &#39;vingerary&#39;: 766,
 &#39;simulatneously&#39;: 767,
 &#39;regulatable&#39;: 768,
 &#39;coutry&#39;: 769,
 &#39;disatance&#39;: 770,
 &#39;challenge&#39;: 771,
 &#39;michelle&#39;: 772,
 &#39;kildare&#39;: 773,
 &#39;knife&#39;: 774,
 &#39;rogers&#39;: 775,
 &#39;satisfactory&#39;: 776,
 &#39;offhanded&#39;: 777,
 &#39;nightrest&#39;: 778,
 &#39;9x12&#39;: 779,
 &#39;thu&#39;: 780,
 &#39;atmoshere&#39;: 781,
 &#39;habitaciones&#39;: 782,
 &#39;stasoper&#39;: 783,
 &#39;whirring&#39;: 784,
 &#39;spelling&#39;: 785,
 &#39;afrosted&#39;: 786,
 &#39;erycomforts&#39;: 787,
 &#39;chidren&#39;: 788,
 &#39;okei&#39;: 789,
 &#39;seimpelin&#39;: 790,
 &#39;coying&#39;: 791,
 &#39;recommence&#39;: 792,
 &#39;rodes&#39;: 793,
 &#39;starck&#39;: 794,
 &#39;restorants&#39;: 795,
 &#39;romanticise&#39;: 796,
 &#39;hailu&#39;: 797,
 &#39;rosensteingasse&#39;: 798,
 &#39;allergy&#39;: 799,
 &#39;cosiderate&#39;: 800,
 &#39;limoncello&#39;: 801,
 &#39;socializing&#39;: 802,
 &#39;lekbed&#39;: 803,
 &#39;verrrry&#39;: 804,
 &#39;manifold&#39;: 805,
 &#39;empleeys&#39;: 806,
 &#39;carmen&#39;: 807,
 &#39;friendlt&#39;: 808,
 &#39;beauchamps&#39;: 809,
 &#39;nafthalin&#39;: 810,
 &#39;20m&#39;: 811,
 &#39;christendom&#39;: 812,
 &#39;merchandise&#39;: 813,
 &#39;hubs&#39;: 814,
 &#39;avearge&#39;: 815,
 &#39;rainhead&#39;: 816,
 &#39;verbal&#39;: 817,
 &#39;bocket&#39;: 818,
 &#39;torte&#39;: 819,
 &#39;handside&#39;: 820,
 &#39;approximated&#39;: 821,
 &#39;hu&#39;: 822,
 &#39;netbook&#39;: 823,
 &#39;annabell&#39;: 824,
 &#39;promse&#39;: 825,
 &#39;pensioners&#39;: 826,
 &#39;lagter&#39;: 827,
 &#39;redeaming&#39;: 828,
 &#39;practicle&#39;: 829,
 &#39;disaponting&#39;: 830,
 &#39;coulp&#39;: 831,
 &#39;nos&#39;: 832,
 &#39;theft&#39;: 833,
 &#39;lagguge&#39;: 834,
 &#39;mucshrooms&#39;: 835,
 &#39;mojo&#39;: 836,
 &#39;575&#39;: 837,
 &#39;scouts&#39;: 838,
 &#39;joah&#39;: 839,
 &#39;poofier&#39;: 840,
 &#39;gaven&#39;: 841,
 &#39;foned&#39;: 842,
 &#39;viennoserie&#39;: 843,
 &#39;beauti&#39;: 844,
 &#39;gogw&#39;: 845,
 &#39;macarons&#39;: 846,
 &#39;whatsover&#39;: 847,
 &#39;unbeliavebly&#39;: 848,
 &#39;rawlinson&#39;: 849,
 &#39;coonvenient&#39;: 850,
 &#39;enquiries&#39;: 851,
 &#39;parkings&#39;: 852,
 &#39;roomss&#39;: 853,
 &#39;2sq&#39;: 854,
 &#39;attendee&#39;: 855,
 &#39;gallagher&#39;: 856,
 &#39;taylor&#39;: 857,
 &#39;soecial&#39;: 858,
 &#39;merciiiiii&#39;: 859,
 &#39;parador&#39;: 860,
 &#39;hotellet&#39;: 861,
 &#39;rhs&#39;: 862,
 &#39;kompenserade&#39;: 863,
 &#39;waredrobe&#39;: 864,
 &#39;grovesenor&#39;: 865,
 &#39;transponder&#39;: 866,
 &#39;stefania&#39;: 867,
 &#39;abdulwahed&#39;: 868,
 &#39;towembley&#39;: 869,
 &#39;wintry&#39;: 870,
 &#39;houses&#39;: 871,
 &#39;bursting&#39;: 872,
 &#39;diogonal&#39;: 873,
 &#39;utilised&#39;: 874,
 &#39;impresion&#39;: 875,
 &#39;reggeli&#39;: 876,
 &#39;massiimo&#39;: 877,
 &#39;surly&#39;: 878,
 &#39;validity&#39;: 879,
 &#39;replenishments&#39;: 880,
 &#39;movments&#39;: 881,
 &#39;claimimg&#39;: 882,
 &#39;492&#39;: 883,
 &#39;tapped&#39;: 884,
 &#39;difficulty&#39;: 885,
 &#39;ouselves&#39;: 886,
 &#39;aereas&#39;: 887,
 &#39;jaunty&#39;: 888,
 &#39;inflict&#39;: 889,
 &#39;sobrassada&#39;: 890,
 &#39;abetter&#39;: 891,
 &#39;vit&#39;: 892,
 &#39;sanatory&#39;: 893,
 &#39;zcreen&#39;: 894,
 &#39;room121&#39;: 895,
 &#39;chillies&#39;: 896,
 &#39;moyennement&#39;: 897,
 &#39;fran&#39;: 898,
 &#39;closet&#39;: 899,
 &#39;mariahiflerstr&#39;: 900,
 &#39;ferried&#39;: 901,
 &#39;viw&#39;: 902,
 &#39;fossit&#39;: 903,
 &#39;joinery&#39;: 904,
 &#39;accesibke&#39;: 905,
 &#39;wew&#39;: 906,
 &#39;monocle&#39;: 907,
 &#39;necking&#39;: 908,
 &#39;luxary&#39;: 909,
 &#39;eifeltwor&#39;: 910,
 &#39;shold&#39;: 911,
 &#39;dormatory&#39;: 912,
 &#39;constantlyhaving&#39;: 913,
 &#39;facebook&#39;: 914,
 &#39;communicates&#39;: 915,
 &#39;enebriated&#39;: 916,
 &#39;appropiated&#39;: 917,
 &#39;adder&#39;: 918,
 &#39;fugue&#39;: 919,
 &#39;luuuuved&#39;: 920,
 &#39;eiffeil&#39;: 921,
 &#39;masahiro&#39;: 922,
 &#39;mousse&#39;: 923,
 &#39;montreal&#39;: 924,
 &#39;everyghing&#39;: 925,
 &#39;cereales&#39;: 926,
 &#39;cedarwood&#39;: 927,
 &#39;covent&#39;: 928,
 &#39;contemplated&#39;: 929,
 &#39;forewarn&#39;: 930,
 &#39;posizione&#39;: 931,
 &#39;prided&#39;: 932,
 &#39;choosy&#39;: 933,
 &#39;cortonoist&#39;: 934,
 &#39;immcaculate&#39;: 935,
 &#39;reburbishment&#39;: 936,
 &#39;1310&#39;: 937,
 &#39;e50&#39;: 938,
 &#39;seperatevfloor&#39;: 939,
 &#39;nightsbridgs&#39;: 940,
 &#39;gernez&#39;: 941,
 &#39;stages&#39;: 942,
 &#39;garedu&#39;: 943,
 &#39;bouillon&#39;: 944,
 &#39;luxurius&#39;: 945,
 &#39;pooooooor&#39;: 946,
 &#39;sigificance&#39;: 947,
 &#39;baf&#39;: 948,
 &#39;vity&#39;: 949,
 &#39;husain&#39;: 950,
 &#39;mant&#39;: 951,
 &#39;deutchmeister&#39;: 952,
 &#39;centenove&#39;: 953,
 &#39;difficulties&#39;: 954,
 &#39;agressive&#39;: 955,
 &#39;mangagement&#39;: 956,
 &#39;ashe&#39;: 957,
 &#39;congregation&#39;: 958,
 &#39;vino&#39;: 959,
 &#39;reinvents&#39;: 960,
 &#39;criticizing&#39;: 961,
 &#39;jeeves&#39;: 962,
 &#39;tpa&#39;: 963,
 &#39;cantonese&#39;: 964,
 &#39;perished&#39;: 965,
 &#39;privat&#39;: 966,
 &#39;humanism&#39;: 967,
 &#39;characteristic&#39;: 968,
 &#39;nikkei&#39;: 969,
 &#39;justifies&#39;: 970,
 &#39;wuirkiness&#39;: 971,
 &#39;freshly&#39;: 972,
 &#39;unencessary&#39;: 973,
 &#39;loafing&#39;: 974,
 &#39;nespreddo&#39;: 975,
 &#39;regulations&#39;: 976,
 &#39;harrington&#39;: 977,
 &#39;xoxo&#39;: 978,
 &#39;stafg&#39;: 979,
 &#39;ima&#39;: 980,
 &#39;powdered&#39;: 981,
 &#39;semi&#39;: 982,
 &#39;saone&#39;: 983,
 &#39;demonstated&#39;: 984,
 &#39;oleksandr&#39;: 985,
 &#39;foxnity&#39;: 986,
 &#39;guitarist&#39;: 987,
 &#39;precarious&#39;: 988,
 &#39;stagf&#39;: 989,
 &#39;200yard&#39;: 990,
 &#39;garish&#39;: 991,
 &#39;vuiton&#39;: 992,
 &#39;caroline&#39;: 993,
 &#39;celsius&#39;: 994,
 &#39;sacks&#39;: 995,
 &#39;lyet&#39;: 996,
 &#39;eu8&#39;: 997,
 &#39;mean&#39;: 998,
 &#39;maris&#39;: 999,
 ...}</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Creating-a-neural-network">Creating a neural network<a class="anchor-link" href="#Creating-a-neural-network">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[68]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Encapsulate our neural network in a class</span>
<span class="k">class</span> <span class="nc">SentimentNetwork</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reviews</span><span class="p">,</span><span class="n">labels</span><span class="p">,</span><span class="n">hidden_nodes</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create a SentimenNetwork with the given settings</span>
<span class="sd">        Args:</span>
<span class="sd">            reviews(list) - List of reviews used for training</span>
<span class="sd">            labels(list) - List of POSITIVE/NEGATIVE labels associated with the given reviews</span>
<span class="sd">            hidden_nodes(int) - Number of nodes to create in the hidden layer</span>
<span class="sd">            learning_rate(float) - Learning rate to use while training</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Assign a seed to our random number generator to ensure we get</span>
        <span class="c1"># reproducable results during development </span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># process the reviews and their associated labels so that everything</span>
        <span class="c1"># is ready for training</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_process_data</span><span class="p">(</span><span class="n">reviews</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        
        <span class="c1"># Build the network to have the number of hidden nodes and the learning rate that</span>
        <span class="c1"># were passed into this initializer. Make the same number of input nodes as</span>
        <span class="c1"># there are vocabulary words and create a single output node.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_network</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">review_vocab</span><span class="p">),</span><span class="n">hidden_nodes</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">pre_process_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reviews</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        
        <span class="c1"># populate review_vocab with all of the words in the given reviews</span>
        <span class="n">review_vocab</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">review</span> <span class="ow">in</span> <span class="n">reviews</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">review</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
                <span class="n">review_vocab</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

        <span class="c1"># Convert the vocabulary set to a list so we can access words via indices</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">review_vocab</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">review_vocab</span><span class="p">)</span>
        
        <span class="c1"># populate label_vocab with all of the words in the given labels.</span>
        <span class="n">label_vocab</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">:</span>
            <span class="n">label_vocab</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
        
        <span class="c1"># Convert the label vocabulary set to a list so we can access labels via indices</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_vocab</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">label_vocab</span><span class="p">)</span>
        
        <span class="c1"># Store the sizes of the review and label vocabularies.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">review_vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">review_vocab</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_vocab</span><span class="p">)</span>
        
        <span class="c1"># Create a dictionary of words in the vocabulary mapped to index positions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">review_vocab</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
        
        <span class="c1"># Create a dictionary of labels mapped to index positions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label2index</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_vocab</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">label2index</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
        
    <span class="k">def</span> <span class="nf">init_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_nodes</span><span class="p">,</span> <span class="n">hidden_nodes</span><span class="p">,</span> <span class="n">output_nodes</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
        <span class="c1"># Set number of nodes in input, hidden and output layers.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_nodes</span> <span class="o">=</span> <span class="n">input_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_nodes</span> <span class="o">=</span> <span class="n">hidden_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_nodes</span> <span class="o">=</span> <span class="n">output_nodes</span>

        <span class="c1"># Store the learning rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>

        <span class="c1"># Initialize weights</span>

        <span class="c1"># These are the weights between the input layer and the hidden layer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_0_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">input_nodes</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_nodes</span><span class="p">))</span>
    
        <span class="c1"># These are the weights between the hidden layer and the output layer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_1_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_nodes</span><span class="o">**-</span><span class="mf">0.5</span><span class="p">,</span> 
                                                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_nodes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_nodes</span><span class="p">))</span>
        
        <span class="c1"># The input layer, a two-dimensional matrix with shape 1 x input_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">input_nodes</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">update_input_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">review</span><span class="p">):</span>

        <span class="c1"># clear out previous state, reset the layer to be all 0s</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_0</span> <span class="o">*=</span> <span class="mi">0</span>
        
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">review</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
            
            <span class="k">if</span><span class="p">(</span><span class="n">word</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">layer_0</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]]</span> <span class="o">+=</span> <span class="mi">1</span>
                
    <span class="k">def</span> <span class="nf">get_target_for_label</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">label</span><span class="p">):</span>
        <span class="k">if</span><span class="p">(</span><span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">return</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
        
    <span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">sigmoid_output_2_derivative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">output</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">output</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">output</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_reviews</span><span class="p">,</span> <span class="n">training_labels</span><span class="p">):</span>
        
        <span class="c1"># make sure out we have a matching number of reviews and labels</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">training_reviews</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">training_labels</span><span class="p">))</span>
        
        <span class="c1"># Keep track of correct predictions to display accuracy during training </span>
        <span class="n">correct_so_far</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Remember when we started for printing time statistics</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        
        <span class="c1"># loop through all the given reviews and run a forward and backward pass,</span>
        <span class="c1"># updating weights for every item</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">training_reviews</span><span class="p">)):</span>
            
            <span class="c1"># Get the next review and its correct label</span>
            <span class="n">review</span> <span class="o">=</span> <span class="n">training_reviews</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">label</span> <span class="o">=</span> <span class="n">training_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            
            <span class="c1">#### Implement the forward pass here ####</span>
            <span class="c1">### Forward pass ###</span>

            <span class="c1"># Input Layer</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update_input_layer</span><span class="p">(</span><span class="n">review</span><span class="p">)</span>

            <span class="c1"># Hidden layer</span>
            <span class="n">layer_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_0</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_0_1</span><span class="p">)</span>

            <span class="c1"># Output layer</span>
            <span class="n">layer_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">layer_1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_1_2</span><span class="p">))</span>
            
            <span class="c1">#### Implement the backward pass here ####</span>
            <span class="c1">### Backward pass ###</span>

            <span class="c1"># Output error</span>
            <span class="n">layer_2_error</span> <span class="o">=</span> <span class="n">layer_2</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_target_for_label</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="c1"># Output layer error is the difference between desired target and actual output.</span>
            <span class="n">layer_2_delta</span> <span class="o">=</span> <span class="n">layer_2_error</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid_output_2_derivative</span><span class="p">(</span><span class="n">layer_2</span><span class="p">)</span>

            <span class="c1"># Backpropagated error</span>
            <span class="n">layer_1_error</span> <span class="o">=</span> <span class="n">layer_2_delta</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_1_2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="c1"># errors propagated to the hidden layer</span>
            <span class="n">layer_1_delta</span> <span class="o">=</span> <span class="n">layer_1_error</span> <span class="c1"># hidden layer gradients - no nonlinearity so it&#39;s the same as the error</span>

            <span class="c1"># Update the weights</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights_1_2</span> <span class="o">-=</span> <span class="n">layer_1</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">layer_2_delta</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="c1"># update hidden-to-output weights with gradient descent step</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights_0_1</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_0</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">layer_1_delta</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="c1"># update input-to-hidden weights with gradient descent step</span>

            <span class="c1"># Keep track of correct predictions.</span>
            <span class="k">if</span><span class="p">(</span><span class="n">layer_2</span> <span class="o">&gt;=</span> <span class="mf">0.5</span> <span class="ow">and</span> <span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
                <span class="n">correct_so_far</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">elif</span><span class="p">(</span><span class="n">layer_2</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">and</span> <span class="n">label</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                <span class="n">correct_so_far</span> <span class="o">+=</span> <span class="mi">1</span>
            
            <span class="c1"># For debug purposes, print out our prediction accuracy and speed </span>
            <span class="c1"># throughout the training process. </span>
            <span class="n">elapsed_time</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>
            <span class="n">reviews_per_second</span> <span class="o">=</span> <span class="n">i</span> <span class="o">/</span> <span class="n">elapsed_time</span> <span class="k">if</span> <span class="n">elapsed_time</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
            
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">Progress:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">i</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">training_reviews</span><span class="p">)))[:</span><span class="mi">4</span><span class="p">]</span> \
                             <span class="o">+</span> <span class="s2">&quot;% Speed(reviews/sec):&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">reviews_per_second</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span> \
                             <span class="o">+</span> <span class="s2">&quot; #Correct:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">correct_so_far</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; #Trained:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> \
                             <span class="o">+</span> <span class="s2">&quot; Training Accuracy:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">correct_so_far</span> <span class="o">*</span> <span class="mi">100</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))[:</span><span class="mi">4</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;%&quot;</span><span class="p">)</span>
            <span class="k">if</span><span class="p">(</span><span class="n">i</span> <span class="o">%</span> <span class="mi">2500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">testing_reviews</span><span class="p">,</span> <span class="n">testing_labels</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Attempts to predict the labels for the given testing_reviews,</span>
<span class="sd">        and uses the test_labels to calculate the accuracy of those predictions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="c1"># keep track of how many correct predictions we make</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># we&#39;ll time how many predictions per second we make</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="c1"># Loop through each of the given reviews and call run to predict</span>
        <span class="c1"># its label. </span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">testing_reviews</span><span class="p">)):</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">testing_reviews</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="k">if</span><span class="p">(</span><span class="n">pred</span> <span class="o">==</span> <span class="n">testing_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span>
                <span class="n">correct</span> <span class="o">+=</span> <span class="mi">1</span>
            
            <span class="c1"># For debug purposes, print out our prediction accuracy and speed </span>
            <span class="c1"># throughout the prediction process. </span>

            <span class="n">elapsed_time</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>
            <span class="n">reviews_per_second</span> <span class="o">=</span> <span class="n">i</span> <span class="o">/</span> <span class="n">elapsed_time</span> <span class="k">if</span> <span class="n">elapsed_time</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
            
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">Progress:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">i</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">testing_reviews</span><span class="p">)))[:</span><span class="mi">4</span><span class="p">]</span> \
                             <span class="o">+</span> <span class="s2">&quot;% Speed(reviews/sec):&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">reviews_per_second</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span> \
                             <span class="o">+</span> <span class="s2">&quot; #Correct:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">correct</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; #Tested:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> \
                             <span class="o">+</span> <span class="s2">&quot; Testing Accuracy:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">correct</span> <span class="o">*</span> <span class="mi">100</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))[:</span><span class="mi">4</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;%&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">review</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a POSITIVE or NEGATIVE prediction for the given review.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Run a forward pass through the network, like in the &quot;train&quot; function.</span>
        
        <span class="c1"># Input Layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_input_layer</span><span class="p">(</span><span class="n">review</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>

        <span class="c1"># Hidden layer</span>
        <span class="n">layer_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_0</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_0_1</span><span class="p">)</span>

        <span class="c1"># Output layer</span>
        <span class="n">layer_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">layer_1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_1_2</span><span class="p">))</span>
        
        <span class="c1"># Return POSITIVE for values above greater-than-or-equal-to 0.5 in the output layer;</span>
        <span class="c1"># return NEGATIVE for other values</span>
        <span class="k">if</span><span class="p">(</span><span class="n">layer_2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">):</span>
            <span class="k">return</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[69]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mlp</span> <span class="o">=</span> <span class="n">SentimentNetwork</span><span class="p">(</span><span class="n">reviews</span><span class="p">[:</span><span class="o">-</span><span class="mi">41000</span><span class="p">],</span><span class="n">labels</span><span class="p">[:</span><span class="o">-</span><span class="mi">41000</span><span class="p">],</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[70]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mlp</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">reviews</span><span class="p">[</span><span class="o">-</span><span class="mi">41000</span><span class="p">:],</span><span class="n">labels</span><span class="p">[</span><span class="o">-</span><span class="mi">41000</span><span class="p">:])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Progress:99.9% Speed(reviews/sec):1332. #Correct:10995 #Tested:41000 Testing Accuracy:26.8%</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Training-neural-network-model">Training neural network model<a class="anchor-link" href="#Training-neural-network-model">&#182;</a></h4><p>90-10 split</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[73]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mlp</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">reviews</span><span class="p">[:</span><span class="o">-</span><span class="mi">103000</span><span class="p">],</span><span class="n">labels</span><span class="p">[:</span><span class="o">-</span><span class="mi">103000</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%
Progress:0.26% Speed(reviews/sec):105.1 #Correct:132 #Trained:2501 Training Accuracy:5.27%
Progress:0.53% Speed(reviews/sec):98.01 #Correct:800 #Trained:5001 Training Accuracy:15.9%
Progress:0.80% Speed(reviews/sec):96.14 #Correct:3298 #Trained:7501 Training Accuracy:43.9%
Progress:1.07% Speed(reviews/sec):97.27 #Correct:5794 #Trained:10001 Training Accuracy:57.9%
Progress:1.34% Speed(reviews/sec):98.63 #Correct:8290 #Trained:12501 Training Accuracy:66.3%
Progress:1.61% Speed(reviews/sec):99.42 #Correct:10788 #Trained:15001 Training Accuracy:71.9%
Progress:1.88% Speed(reviews/sec):99.93 #Correct:13286 #Trained:17501 Training Accuracy:75.9%
Progress:2.15% Speed(reviews/sec):100.0 #Correct:15784 #Trained:20001 Training Accuracy:78.9%
Progress:2.42% Speed(reviews/sec):100.3 #Correct:18283 #Trained:22501 Training Accuracy:81.2%
Progress:2.69% Speed(reviews/sec):100.2 #Correct:20782 #Trained:25001 Training Accuracy:83.1%
Progress:2.96% Speed(reviews/sec):100.0 #Correct:23279 #Trained:27501 Training Accuracy:84.6%
Progress:3.23% Speed(reviews/sec):99.74 #Correct:25778 #Trained:30001 Training Accuracy:85.9%
Progress:3.50% Speed(reviews/sec):100.1 #Correct:28278 #Trained:32501 Training Accuracy:87.0%
Progress:3.77% Speed(reviews/sec):100.4 #Correct:30778 #Trained:35001 Training Accuracy:87.9%
Progress:4.04% Speed(reviews/sec):99.66 #Correct:33276 #Trained:37501 Training Accuracy:88.7%
Progress:4.31% Speed(reviews/sec):99.22 #Correct:35775 #Trained:40001 Training Accuracy:89.4%
Progress:4.58% Speed(reviews/sec):99.28 #Correct:38274 #Trained:42501 Training Accuracy:90.0%
Progress:4.85% Speed(reviews/sec):99.13 #Correct:40771 #Trained:45001 Training Accuracy:90.6%
Progress:5.12% Speed(reviews/sec):98.09 #Correct:43270 #Trained:47501 Training Accuracy:91.0%
Progress:5.39% Speed(reviews/sec):97.33 #Correct:45769 #Trained:50001 Training Accuracy:91.5%
Progress:5.66% Speed(reviews/sec):97.49 #Correct:48269 #Trained:52501 Training Accuracy:91.9%
Progress:5.93% Speed(reviews/sec):97.85 #Correct:50766 #Trained:55001 Training Accuracy:92.3%
Progress:6.19% Speed(reviews/sec):98.00 #Correct:53265 #Trained:57501 Training Accuracy:92.6%
Progress:6.46% Speed(reviews/sec):98.38 #Correct:55762 #Trained:60001 Training Accuracy:92.9%
Progress:6.73% Speed(reviews/sec):98.11 #Correct:58260 #Trained:62501 Training Accuracy:93.2%
Progress:7.00% Speed(reviews/sec):97.48 #Correct:60759 #Trained:65001 Training Accuracy:93.4%
Progress:7.27% Speed(reviews/sec):97.67 #Correct:63253 #Trained:67501 Training Accuracy:93.7%
Progress:7.54% Speed(reviews/sec):97.89 #Correct:65747 #Trained:70001 Training Accuracy:93.9%
Progress:7.81% Speed(reviews/sec):98.14 #Correct:68245 #Trained:72501 Training Accuracy:94.1%
Progress:8.08% Speed(reviews/sec):98.34 #Correct:70745 #Trained:75001 Training Accuracy:94.3%
Progress:8.35% Speed(reviews/sec):98.53 #Correct:73244 #Trained:77501 Training Accuracy:94.5%
Progress:8.62% Speed(reviews/sec):98.73 #Correct:75744 #Trained:80001 Training Accuracy:94.6%
Progress:8.89% Speed(reviews/sec):98.92 #Correct:78241 #Trained:82501 Training Accuracy:94.8%
Progress:9.16% Speed(reviews/sec):99.10 #Correct:80741 #Trained:85001 Training Accuracy:94.9%
Progress:9.43% Speed(reviews/sec):99.24 #Correct:83240 #Trained:87501 Training Accuracy:95.1%
Progress:9.70% Speed(reviews/sec):99.38 #Correct:85740 #Trained:90001 Training Accuracy:95.2%
Progress:9.97% Speed(reviews/sec):99.52 #Correct:88238 #Trained:92501 Training Accuracy:95.3%
Progress:10.2% Speed(reviews/sec):99.66 #Correct:90737 #Trained:95001 Training Accuracy:95.5%
Progress:10.5% Speed(reviews/sec):99.79 #Correct:93235 #Trained:97501 Training Accuracy:95.6%
Progress:10.7% Speed(reviews/sec):99.89 #Correct:95734 #Trained:100001 Training Accuracy:95.7%
Progress:11.0% Speed(reviews/sec):99.89 #Correct:98230 #Trained:102501 Training Accuracy:95.8%
Progress:11.3% Speed(reviews/sec):99.97 #Correct:100728 #Trained:105001 Training Accuracy:95.9%
Progress:11.5% Speed(reviews/sec):100.0 #Correct:103226 #Trained:107501 Training Accuracy:96.0%
Progress:11.8% Speed(reviews/sec):100.1 #Correct:105722 #Trained:110001 Training Accuracy:96.1%
Progress:12.1% Speed(reviews/sec):100.2 #Correct:108219 #Trained:112501 Training Accuracy:96.1%
Progress:12.3% Speed(reviews/sec):100.3 #Correct:110714 #Trained:115001 Training Accuracy:96.2%
Progress:12.6% Speed(reviews/sec):100.4 #Correct:113211 #Trained:117501 Training Accuracy:96.3%
Progress:12.9% Speed(reviews/sec):100.5 #Correct:115709 #Trained:120001 Training Accuracy:96.4%
Progress:13.2% Speed(reviews/sec):100.6 #Correct:118208 #Trained:122501 Training Accuracy:96.4%
Progress:13.4% Speed(reviews/sec):100.7 #Correct:120706 #Trained:125001 Training Accuracy:96.5%
Progress:13.7% Speed(reviews/sec):100.7 #Correct:123205 #Trained:127501 Training Accuracy:96.6%
Progress:14.0% Speed(reviews/sec):100.8 #Correct:125704 #Trained:130001 Training Accuracy:96.6%
Progress:14.2% Speed(reviews/sec):100.9 #Correct:128203 #Trained:132501 Training Accuracy:96.7%
Progress:14.5% Speed(reviews/sec):101.0 #Correct:130702 #Trained:135001 Training Accuracy:96.8%
Progress:14.8% Speed(reviews/sec):101.1 #Correct:133200 #Trained:137501 Training Accuracy:96.8%
Progress:15.0% Speed(reviews/sec):101.1 #Correct:135700 #Trained:140001 Training Accuracy:96.9%
Progress:15.3% Speed(reviews/sec):101.2 #Correct:138198 #Trained:142501 Training Accuracy:96.9%
Progress:15.6% Speed(reviews/sec):101.3 #Correct:140698 #Trained:145001 Training Accuracy:97.0%
Progress:15.9% Speed(reviews/sec):101.4 #Correct:143197 #Trained:147501 Training Accuracy:97.0%
Progress:16.1% Speed(reviews/sec):101.5 #Correct:145697 #Trained:150001 Training Accuracy:97.1%
Progress:16.4% Speed(reviews/sec):101.5 #Correct:148196 #Trained:152501 Training Accuracy:97.1%
Progress:16.7% Speed(reviews/sec):101.6 #Correct:150694 #Trained:155001 Training Accuracy:97.2%
Progress:16.9% Speed(reviews/sec):101.6 #Correct:153192 #Trained:157501 Training Accuracy:97.2%
Progress:17.2% Speed(reviews/sec):101.6 #Correct:155690 #Trained:160001 Training Accuracy:97.3%
Progress:17.5% Speed(reviews/sec):101.6 #Correct:158189 #Trained:162501 Training Accuracy:97.3%
Progress:17.7% Speed(reviews/sec):101.5 #Correct:160687 #Trained:165001 Training Accuracy:97.3%
Progress:18.0% Speed(reviews/sec):101.4 #Correct:163186 #Trained:167501 Training Accuracy:97.4%
Progress:18.3% Speed(reviews/sec):101.3 #Correct:165686 #Trained:170001 Training Accuracy:97.4%
Progress:18.5% Speed(reviews/sec):101.4 #Correct:168184 #Trained:172501 Training Accuracy:97.4%
Progress:18.8% Speed(reviews/sec):101.2 #Correct:170682 #Trained:175001 Training Accuracy:97.5%
Progress:19.1% Speed(reviews/sec):101.2 #Correct:173182 #Trained:177501 Training Accuracy:97.5%
Progress:19.4% Speed(reviews/sec):101.2 #Correct:175682 #Trained:180001 Training Accuracy:97.6%
Progress:19.6% Speed(reviews/sec):101.2 #Correct:178182 #Trained:182501 Training Accuracy:97.6%
Progress:19.9% Speed(reviews/sec):101.1 #Correct:180681 #Trained:185001 Training Accuracy:97.6%
Progress:20.2% Speed(reviews/sec):100.8 #Correct:183180 #Trained:187501 Training Accuracy:97.6%
Progress:20.4% Speed(reviews/sec):100.7 #Correct:185679 #Trained:190001 Training Accuracy:97.7%
Progress:20.7% Speed(reviews/sec):100.6 #Correct:188175 #Trained:192501 Training Accuracy:97.7%
Progress:21.0% Speed(reviews/sec):100.7 #Correct:190674 #Trained:195001 Training Accuracy:97.7%
Progress:21.2% Speed(reviews/sec):100.8 #Correct:193173 #Trained:197501 Training Accuracy:97.8%
Progress:21.5% Speed(reviews/sec):100.8 #Correct:195672 #Trained:200001 Training Accuracy:97.8%
Progress:21.8% Speed(reviews/sec):100.8 #Correct:198169 #Trained:202501 Training Accuracy:97.8%
Progress:22.1% Speed(reviews/sec):100.9 #Correct:200667 #Trained:205001 Training Accuracy:97.8%
Progress:22.3% Speed(reviews/sec):101.0 #Correct:203165 #Trained:207501 Training Accuracy:97.9%
Progress:22.6% Speed(reviews/sec):101.0 #Correct:205663 #Trained:210001 Training Accuracy:97.9%
Progress:22.9% Speed(reviews/sec):100.9 #Correct:208162 #Trained:212501 Training Accuracy:97.9%
Progress:23.1% Speed(reviews/sec):100.9 #Correct:210661 #Trained:215001 Training Accuracy:97.9%
Progress:23.4% Speed(reviews/sec):101.0 #Correct:213161 #Trained:217501 Training Accuracy:98.0%
Progress:23.7% Speed(reviews/sec):101.0 #Correct:215661 #Trained:220001 Training Accuracy:98.0%
Progress:23.9% Speed(reviews/sec):101.0 #Correct:218159 #Trained:222501 Training Accuracy:98.0%
Progress:24.2% Speed(reviews/sec):101.0 #Correct:220656 #Trained:225001 Training Accuracy:98.0%
Progress:24.5% Speed(reviews/sec):101.0 #Correct:223155 #Trained:227501 Training Accuracy:98.0%
Progress:24.7% Speed(reviews/sec):100.9 #Correct:225655 #Trained:230001 Training Accuracy:98.1%
Progress:25.0% Speed(reviews/sec):100.9 #Correct:228153 #Trained:232501 Training Accuracy:98.1%
Progress:25.3% Speed(reviews/sec):100.9 #Correct:230652 #Trained:235001 Training Accuracy:98.1%
Progress:25.6% Speed(reviews/sec):100.9 #Correct:233152 #Trained:237501 Training Accuracy:98.1%
Progress:25.8% Speed(reviews/sec):100.9 #Correct:235650 #Trained:240001 Training Accuracy:98.1%
Progress:26.1% Speed(reviews/sec):100.9 #Correct:238150 #Trained:242501 Training Accuracy:98.2%
Progress:26.4% Speed(reviews/sec):101.0 #Correct:240648 #Trained:245001 Training Accuracy:98.2%
Progress:26.6% Speed(reviews/sec):100.9 #Correct:243145 #Trained:247501 Training Accuracy:98.2%
Progress:26.9% Speed(reviews/sec):100.9 #Correct:245644 #Trained:250001 Training Accuracy:98.2%
Progress:27.2% Speed(reviews/sec):100.9 #Correct:248143 #Trained:252501 Training Accuracy:98.2%
Progress:27.4% Speed(reviews/sec):100.8 #Correct:250642 #Trained:255001 Training Accuracy:98.2%
Progress:27.7% Speed(reviews/sec):100.9 #Correct:253140 #Trained:257501 Training Accuracy:98.3%
Progress:28.0% Speed(reviews/sec):100.9 #Correct:255638 #Trained:260001 Training Accuracy:98.3%
Progress:28.3% Speed(reviews/sec):100.9 #Correct:258138 #Trained:262501 Training Accuracy:98.3%
Progress:28.5% Speed(reviews/sec):100.9 #Correct:260635 #Trained:265001 Training Accuracy:98.3%
Progress:28.8% Speed(reviews/sec):100.9 #Correct:263133 #Trained:267501 Training Accuracy:98.3%
Progress:29.1% Speed(reviews/sec):100.8 #Correct:265633 #Trained:270001 Training Accuracy:98.3%
Progress:29.3% Speed(reviews/sec):100.8 #Correct:268133 #Trained:272501 Training Accuracy:98.3%
Progress:29.6% Speed(reviews/sec):100.8 #Correct:270632 #Trained:275001 Training Accuracy:98.4%
Progress:29.9% Speed(reviews/sec):100.8 #Correct:273132 #Trained:277501 Training Accuracy:98.4%
Progress:30.1% Speed(reviews/sec):100.9 #Correct:275631 #Trained:280001 Training Accuracy:98.4%
Progress:30.4% Speed(reviews/sec):100.9 #Correct:278131 #Trained:282501 Training Accuracy:98.4%
Progress:30.7% Speed(reviews/sec):100.9 #Correct:280630 #Trained:285001 Training Accuracy:98.4%
Progress:30.9% Speed(reviews/sec):100.9 #Correct:283130 #Trained:287501 Training Accuracy:98.4%
Progress:31.2% Speed(reviews/sec):100.9 #Correct:285630 #Trained:290001 Training Accuracy:98.4%
Progress:31.5% Speed(reviews/sec):100.9 #Correct:288129 #Trained:292501 Training Accuracy:98.5%
Progress:31.8% Speed(reviews/sec):100.9 #Correct:290627 #Trained:295001 Training Accuracy:98.5%
Progress:32.0% Speed(reviews/sec):101.0 #Correct:293126 #Trained:297501 Training Accuracy:98.5%
Progress:32.3% Speed(reviews/sec):100.9 #Correct:295625 #Trained:300001 Training Accuracy:98.5%
Progress:32.6% Speed(reviews/sec):100.9 #Correct:298124 #Trained:302501 Training Accuracy:98.5%
Progress:32.8% Speed(reviews/sec):100.8 #Correct:300623 #Trained:305001 Training Accuracy:98.5%
Progress:33.1% Speed(reviews/sec):100.7 #Correct:303123 #Trained:307501 Training Accuracy:98.5%
Progress:33.4% Speed(reviews/sec):100.7 #Correct:305621 #Trained:310001 Training Accuracy:98.5%
Progress:33.6% Speed(reviews/sec):100.7 #Correct:308118 #Trained:312501 Training Accuracy:98.5%
Progress:33.9% Speed(reviews/sec):100.6 #Correct:310615 #Trained:315001 Training Accuracy:98.6%
Progress:34.2% Speed(reviews/sec):100.6 #Correct:313114 #Trained:317501 Training Accuracy:98.6%
Progress:34.5% Speed(reviews/sec):100.5 #Correct:315614 #Trained:320001 Training Accuracy:98.6%
Progress:34.7% Speed(reviews/sec):100.5 #Correct:318112 #Trained:322501 Training Accuracy:98.6%
Progress:35.0% Speed(reviews/sec):100.4 #Correct:320610 #Trained:325001 Training Accuracy:98.6%
Progress:35.3% Speed(reviews/sec):100.4 #Correct:323109 #Trained:327501 Training Accuracy:98.6%
Progress:35.5% Speed(reviews/sec):100.4 #Correct:325607 #Trained:330001 Training Accuracy:98.6%
Progress:35.8% Speed(reviews/sec):100.3 #Correct:328106 #Trained:332501 Training Accuracy:98.6%
Progress:36.1% Speed(reviews/sec):100.3 #Correct:330604 #Trained:335001 Training Accuracy:98.6%
Progress:36.3% Speed(reviews/sec):100.2 #Correct:333102 #Trained:337501 Training Accuracy:98.6%
Progress:36.6% Speed(reviews/sec):100.2 #Correct:335602 #Trained:340001 Training Accuracy:98.7%
Progress:36.9% Speed(reviews/sec):100.2 #Correct:338101 #Trained:342501 Training Accuracy:98.7%
Progress:37.1% Speed(reviews/sec):100.2 #Correct:340598 #Trained:345001 Training Accuracy:98.7%
Progress:37.4% Speed(reviews/sec):100.2 #Correct:343096 #Trained:347501 Training Accuracy:98.7%
Progress:37.7% Speed(reviews/sec):100.2 #Correct:345595 #Trained:350001 Training Accuracy:98.7%
Progress:38.0% Speed(reviews/sec):100.2 #Correct:348093 #Trained:352501 Training Accuracy:98.7%
Progress:38.2% Speed(reviews/sec):100.2 #Correct:350591 #Trained:355001 Training Accuracy:98.7%
Progress:38.5% Speed(reviews/sec):100.2 #Correct:353091 #Trained:357501 Training Accuracy:98.7%
Progress:38.8% Speed(reviews/sec):100.2 #Correct:355590 #Trained:360001 Training Accuracy:98.7%
Progress:39.0% Speed(reviews/sec):100.2 #Correct:358088 #Trained:362501 Training Accuracy:98.7%
Progress:39.3% Speed(reviews/sec):100.2 #Correct:360588 #Trained:365001 Training Accuracy:98.7%
Progress:39.6% Speed(reviews/sec):100.2 #Correct:363088 #Trained:367501 Training Accuracy:98.7%
Progress:39.8% Speed(reviews/sec):100.2 #Correct:365585 #Trained:370001 Training Accuracy:98.8%
Progress:40.1% Speed(reviews/sec):100.1 #Correct:368083 #Trained:372501 Training Accuracy:98.8%
Progress:40.4% Speed(reviews/sec):100.2 #Correct:370582 #Trained:375001 Training Accuracy:98.8%
Progress:40.7% Speed(reviews/sec):100.2 #Correct:373081 #Trained:377501 Training Accuracy:98.8%
Progress:40.9% Speed(reviews/sec):100.2 #Correct:375580 #Trained:380001 Training Accuracy:98.8%
Progress:41.2% Speed(reviews/sec):100.2 #Correct:378080 #Trained:382501 Training Accuracy:98.8%
Progress:41.5% Speed(reviews/sec):100.2 #Correct:380580 #Trained:385001 Training Accuracy:98.8%
Progress:41.7% Speed(reviews/sec):100.2 #Correct:383079 #Trained:387501 Training Accuracy:98.8%
Progress:42.0% Speed(reviews/sec):100.2 #Correct:385578 #Trained:390001 Training Accuracy:98.8%
Progress:42.3% Speed(reviews/sec):100.2 #Correct:388077 #Trained:392501 Training Accuracy:98.8%
Progress:42.5% Speed(reviews/sec):100.2 #Correct:390575 #Trained:395001 Training Accuracy:98.8%
Progress:42.8% Speed(reviews/sec):100.3 #Correct:393073 #Trained:397501 Training Accuracy:98.8%
Progress:43.1% Speed(reviews/sec):100.2 #Correct:395572 #Trained:400001 Training Accuracy:98.8%
Progress:43.3% Speed(reviews/sec):100.2 #Correct:398072 #Trained:402501 Training Accuracy:98.8%
Progress:43.6% Speed(reviews/sec):100.2 #Correct:400571 #Trained:405001 Training Accuracy:98.9%
Progress:43.9% Speed(reviews/sec):100.2 #Correct:403070 #Trained:407501 Training Accuracy:98.9%
Progress:44.2% Speed(reviews/sec):100.2 #Correct:405570 #Trained:410001 Training Accuracy:98.9%
Progress:44.4% Speed(reviews/sec):100.2 #Correct:408070 #Trained:412501 Training Accuracy:98.9%
Progress:44.7% Speed(reviews/sec):100.1 #Correct:410567 #Trained:415001 Training Accuracy:98.9%
Progress:45.0% Speed(reviews/sec):100.1 #Correct:413067 #Trained:417501 Training Accuracy:98.9%
Progress:45.2% Speed(reviews/sec):100.1 #Correct:415564 #Trained:420001 Training Accuracy:98.9%
Progress:45.5% Speed(reviews/sec):100.1 #Correct:418064 #Trained:422501 Training Accuracy:98.9%
Progress:45.8% Speed(reviews/sec):100.2 #Correct:420561 #Trained:425001 Training Accuracy:98.9%
Progress:46.0% Speed(reviews/sec):100.2 #Correct:423060 #Trained:427501 Training Accuracy:98.9%
Progress:46.3% Speed(reviews/sec):100.1 #Correct:425559 #Trained:430001 Training Accuracy:98.9%
Progress:46.6% Speed(reviews/sec):100.1 #Correct:428056 #Trained:432501 Training Accuracy:98.9%
Progress:46.9% Speed(reviews/sec):100.1 #Correct:430556 #Trained:435001 Training Accuracy:98.9%
Progress:47.1% Speed(reviews/sec):100.1 #Correct:433056 #Trained:437501 Training Accuracy:98.9%
Progress:47.4% Speed(reviews/sec):100.1 #Correct:435556 #Trained:440001 Training Accuracy:98.9%
Progress:47.7% Speed(reviews/sec):100.1 #Correct:438055 #Trained:442501 Training Accuracy:98.9%
Progress:47.9% Speed(reviews/sec):100.1 #Correct:440555 #Trained:445001 Training Accuracy:99.0%
Progress:48.2% Speed(reviews/sec):100.1 #Correct:443054 #Trained:447501 Training Accuracy:99.0%
Progress:48.5% Speed(reviews/sec):100.1 #Correct:445553 #Trained:450001 Training Accuracy:99.0%
Progress:48.7% Speed(reviews/sec):100.1 #Correct:448052 #Trained:452501 Training Accuracy:99.0%
Progress:49.0% Speed(reviews/sec):100.0 #Correct:450551 #Trained:455001 Training Accuracy:99.0%
Progress:49.3% Speed(reviews/sec):100.0 #Correct:453050 #Trained:457501 Training Accuracy:99.0%
Progress:49.5% Speed(reviews/sec):100.0 #Correct:455550 #Trained:460001 Training Accuracy:99.0%
Progress:49.8% Speed(reviews/sec):100.0 #Correct:458048 #Trained:462501 Training Accuracy:99.0%
Progress:50.1% Speed(reviews/sec):100.0 #Correct:460547 #Trained:465001 Training Accuracy:99.0%
Progress:50.4% Speed(reviews/sec):100.0 #Correct:463046 #Trained:467501 Training Accuracy:99.0%
Progress:50.6% Speed(reviews/sec):100.0 #Correct:465546 #Trained:470001 Training Accuracy:99.0%
Progress:50.9% Speed(reviews/sec):100.0 #Correct:468045 #Trained:472501 Training Accuracy:99.0%
Progress:51.2% Speed(reviews/sec):100.0 #Correct:470545 #Trained:475001 Training Accuracy:99.0%
Progress:51.4% Speed(reviews/sec):100.0 #Correct:473042 #Trained:477501 Training Accuracy:99.0%
Progress:51.7% Speed(reviews/sec):100.0 #Correct:475542 #Trained:480001 Training Accuracy:99.0%
Progress:52.0% Speed(reviews/sec):100.0 #Correct:478040 #Trained:482501 Training Accuracy:99.0%
Progress:52.2% Speed(reviews/sec):99.99 #Correct:480540 #Trained:485001 Training Accuracy:99.0%
Progress:52.5% Speed(reviews/sec):99.98 #Correct:483037 #Trained:487501 Training Accuracy:99.0%
Progress:52.8% Speed(reviews/sec):99.97 #Correct:485536 #Trained:490001 Training Accuracy:99.0%
Progress:53.1% Speed(reviews/sec):99.97 #Correct:488035 #Trained:492501 Training Accuracy:99.0%
Progress:53.3% Speed(reviews/sec):99.96 #Correct:490533 #Trained:495001 Training Accuracy:99.0%
Progress:53.6% Speed(reviews/sec):99.94 #Correct:493032 #Trained:497501 Training Accuracy:99.1%
Progress:53.9% Speed(reviews/sec):99.94 #Correct:495531 #Trained:500001 Training Accuracy:99.1%
Progress:54.1% Speed(reviews/sec):99.93 #Correct:498031 #Trained:502501 Training Accuracy:99.1%
Progress:54.4% Speed(reviews/sec):99.93 #Correct:500531 #Trained:505001 Training Accuracy:99.1%
Progress:54.7% Speed(reviews/sec):99.92 #Correct:503031 #Trained:507501 Training Accuracy:99.1%
Progress:54.9% Speed(reviews/sec):99.91 #Correct:505530 #Trained:510001 Training Accuracy:99.1%
Progress:55.2% Speed(reviews/sec):99.90 #Correct:508030 #Trained:512501 Training Accuracy:99.1%
Progress:55.5% Speed(reviews/sec):99.89 #Correct:510527 #Trained:515001 Training Accuracy:99.1%
Progress:55.7% Speed(reviews/sec):99.88 #Correct:512245 #Trained:517501 Training Accuracy:98.9%
Progress:56.0% Speed(reviews/sec):99.87 #Correct:514700 #Trained:520001 Training Accuracy:98.9%
Progress:56.3% Speed(reviews/sec):99.86 #Correct:517131 #Trained:522501 Training Accuracy:98.9%
Progress:56.6% Speed(reviews/sec):99.85 #Correct:519576 #Trained:525001 Training Accuracy:98.9%
Progress:56.8% Speed(reviews/sec):99.84 #Correct:521989 #Trained:527501 Training Accuracy:98.9%
Progress:57.1% Speed(reviews/sec):99.84 #Correct:524413 #Trained:530001 Training Accuracy:98.9%
Progress:57.4% Speed(reviews/sec):99.82 #Correct:526736 #Trained:532501 Training Accuracy:98.9%
Progress:57.6% Speed(reviews/sec):99.81 #Correct:529149 #Trained:535001 Training Accuracy:98.9%
Progress:57.9% Speed(reviews/sec):99.81 #Correct:531536 #Trained:537501 Training Accuracy:98.8%
Progress:58.2% Speed(reviews/sec):99.81 #Correct:533937 #Trained:540001 Training Accuracy:98.8%
Progress:58.4% Speed(reviews/sec):99.81 #Correct:536358 #Trained:542501 Training Accuracy:98.8%
Progress:58.7% Speed(reviews/sec):99.80 #Correct:538752 #Trained:545001 Training Accuracy:98.8%
Progress:59.0% Speed(reviews/sec):99.80 #Correct:541149 #Trained:547501 Training Accuracy:98.8%
Progress:59.3% Speed(reviews/sec):99.80 #Correct:543576 #Trained:550001 Training Accuracy:98.8%
Progress:59.5% Speed(reviews/sec):99.79 #Correct:546006 #Trained:552501 Training Accuracy:98.8%
Progress:59.8% Speed(reviews/sec):99.79 #Correct:548430 #Trained:555001 Training Accuracy:98.8%
Progress:60.1% Speed(reviews/sec):99.78 #Correct:550850 #Trained:557501 Training Accuracy:98.8%
Progress:60.3% Speed(reviews/sec):99.77 #Correct:553281 #Trained:560001 Training Accuracy:98.8%
Progress:60.6% Speed(reviews/sec):99.73 #Correct:555670 #Trained:562501 Training Accuracy:98.7%
Progress:60.9% Speed(reviews/sec):99.70 #Correct:558084 #Trained:565001 Training Accuracy:98.7%
Progress:61.1% Speed(reviews/sec):99.66 #Correct:560508 #Trained:567501 Training Accuracy:98.7%
Progress:61.4% Speed(reviews/sec):99.61 #Correct:562889 #Trained:570001 Training Accuracy:98.7%
Progress:61.7% Speed(reviews/sec):99.61 #Correct:565302 #Trained:572501 Training Accuracy:98.7%
Progress:61.9% Speed(reviews/sec):99.61 #Correct:567695 #Trained:575001 Training Accuracy:98.7%
Progress:62.2% Speed(reviews/sec):99.61 #Correct:570089 #Trained:577501 Training Accuracy:98.7%
Progress:62.5% Speed(reviews/sec):99.60 #Correct:572517 #Trained:580001 Training Accuracy:98.7%
Progress:62.8% Speed(reviews/sec):99.59 #Correct:574979 #Trained:582501 Training Accuracy:98.7%
Progress:63.0% Speed(reviews/sec):99.60 #Correct:577412 #Trained:585001 Training Accuracy:98.7%
Progress:63.3% Speed(reviews/sec):99.58 #Correct:579827 #Trained:587501 Training Accuracy:98.6%
Progress:63.6% Speed(reviews/sec):99.57 #Correct:582247 #Trained:590001 Training Accuracy:98.6%
Progress:63.8% Speed(reviews/sec):99.54 #Correct:584647 #Trained:592501 Training Accuracy:98.6%
Progress:64.1% Speed(reviews/sec):99.53 #Correct:587069 #Trained:595001 Training Accuracy:98.6%
Progress:64.4% Speed(reviews/sec):99.53 #Correct:589504 #Trained:597501 Training Accuracy:98.6%
Progress:64.6% Speed(reviews/sec):99.53 #Correct:591904 #Trained:600001 Training Accuracy:98.6%
Progress:64.9% Speed(reviews/sec):99.48 #Correct:594297 #Trained:602501 Training Accuracy:98.6%
Progress:65.2% Speed(reviews/sec):99.46 #Correct:596709 #Trained:605001 Training Accuracy:98.6%
Progress:65.5% Speed(reviews/sec):99.45 #Correct:599138 #Trained:607501 Training Accuracy:98.6%
Progress:65.7% Speed(reviews/sec):99.44 #Correct:601521 #Trained:610001 Training Accuracy:98.6%
Progress:66.0% Speed(reviews/sec):99.43 #Correct:603918 #Trained:612501 Training Accuracy:98.5%
Progress:66.3% Speed(reviews/sec):99.42 #Correct:606334 #Trained:615001 Training Accuracy:98.5%
Progress:66.5% Speed(reviews/sec):99.41 #Correct:608752 #Trained:617501 Training Accuracy:98.5%
Progress:66.8% Speed(reviews/sec):99.41 #Correct:611206 #Trained:620001 Training Accuracy:98.5%
Progress:67.1% Speed(reviews/sec):99.40 #Correct:613633 #Trained:622501 Training Accuracy:98.5%
Progress:67.3% Speed(reviews/sec):99.40 #Correct:615997 #Trained:625001 Training Accuracy:98.5%
Progress:67.6% Speed(reviews/sec):99.39 #Correct:618408 #Trained:627501 Training Accuracy:98.5%
Progress:67.9% Speed(reviews/sec):99.39 #Correct:620842 #Trained:630001 Training Accuracy:98.5%
Progress:68.1% Speed(reviews/sec):99.39 #Correct:623287 #Trained:632501 Training Accuracy:98.5%
Progress:68.4% Speed(reviews/sec):99.38 #Correct:625693 #Trained:635001 Training Accuracy:98.5%
Progress:68.7% Speed(reviews/sec):99.35 #Correct:628106 #Trained:637501 Training Accuracy:98.5%
Progress:69.0% Speed(reviews/sec):99.35 #Correct:630514 #Trained:640001 Training Accuracy:98.5%
Progress:69.2% Speed(reviews/sec):99.34 #Correct:632961 #Trained:642501 Training Accuracy:98.5%
Progress:69.5% Speed(reviews/sec):99.35 #Correct:635389 #Trained:645001 Training Accuracy:98.5%
Progress:69.8% Speed(reviews/sec):99.32 #Correct:637846 #Trained:647501 Training Accuracy:98.5%
Progress:70.0% Speed(reviews/sec):99.32 #Correct:640277 #Trained:650001 Training Accuracy:98.5%
Progress:70.3% Speed(reviews/sec):99.31 #Correct:642690 #Trained:652501 Training Accuracy:98.4%
Progress:70.6% Speed(reviews/sec):99.31 #Correct:645098 #Trained:655001 Training Accuracy:98.4%
Progress:70.8% Speed(reviews/sec):99.31 #Correct:647524 #Trained:657501 Training Accuracy:98.4%
Progress:71.1% Speed(reviews/sec):99.32 #Correct:649939 #Trained:660001 Training Accuracy:98.4%
Progress:71.4% Speed(reviews/sec):99.32 #Correct:652328 #Trained:662501 Training Accuracy:98.4%
Progress:71.7% Speed(reviews/sec):99.32 #Correct:654724 #Trained:665001 Training Accuracy:98.4%
Progress:71.9% Speed(reviews/sec):99.30 #Correct:657112 #Trained:667501 Training Accuracy:98.4%
Progress:72.2% Speed(reviews/sec):99.29 #Correct:659539 #Trained:670001 Training Accuracy:98.4%
Progress:72.5% Speed(reviews/sec):99.26 #Correct:661979 #Trained:672501 Training Accuracy:98.4%
Progress:72.7% Speed(reviews/sec):99.25 #Correct:664401 #Trained:675001 Training Accuracy:98.4%
Progress:73.0% Speed(reviews/sec):99.25 #Correct:666811 #Trained:677501 Training Accuracy:98.4%
Progress:73.3% Speed(reviews/sec):99.23 #Correct:669251 #Trained:680001 Training Accuracy:98.4%
Progress:73.5% Speed(reviews/sec):99.20 #Correct:671691 #Trained:682501 Training Accuracy:98.4%
Progress:73.8% Speed(reviews/sec):99.19 #Correct:674119 #Trained:685001 Training Accuracy:98.4%
Progress:74.1% Speed(reviews/sec):99.18 #Correct:676527 #Trained:687501 Training Accuracy:98.4%
Progress:74.3% Speed(reviews/sec):99.17 #Correct:678935 #Trained:690001 Training Accuracy:98.3%
Progress:74.6% Speed(reviews/sec):99.17 #Correct:681340 #Trained:692501 Training Accuracy:98.3%
Progress:74.9% Speed(reviews/sec):99.15 #Correct:683738 #Trained:695001 Training Accuracy:98.3%
Progress:75.2% Speed(reviews/sec):99.14 #Correct:686144 #Trained:697501 Training Accuracy:98.3%
Progress:75.4% Speed(reviews/sec):99.14 #Correct:688545 #Trained:700001 Training Accuracy:98.3%
Progress:75.7% Speed(reviews/sec):99.13 #Correct:690976 #Trained:702501 Training Accuracy:98.3%
Progress:76.0% Speed(reviews/sec):99.13 #Correct:693376 #Trained:705001 Training Accuracy:98.3%
Progress:76.2% Speed(reviews/sec):99.10 #Correct:695789 #Trained:707501 Training Accuracy:98.3%
Progress:76.5% Speed(reviews/sec):99.08 #Correct:698202 #Trained:710001 Training Accuracy:98.3%
Progress:76.8% Speed(reviews/sec):99.07 #Correct:700629 #Trained:712501 Training Accuracy:98.3%
Progress:77.0% Speed(reviews/sec):99.07 #Correct:703022 #Trained:715001 Training Accuracy:98.3%
Progress:77.3% Speed(reviews/sec):99.02 #Correct:705404 #Trained:717501 Training Accuracy:98.3%
Progress:77.6% Speed(reviews/sec):98.96 #Correct:707815 #Trained:720001 Training Accuracy:98.3%
Progress:77.9% Speed(reviews/sec):98.92 #Correct:710254 #Trained:722501 Training Accuracy:98.3%
Progress:78.1% Speed(reviews/sec):98.88 #Correct:712680 #Trained:725001 Training Accuracy:98.3%
Progress:78.4% Speed(reviews/sec):98.89 #Correct:715085 #Trained:727501 Training Accuracy:98.2%
Progress:78.7% Speed(reviews/sec):98.90 #Correct:717539 #Trained:730001 Training Accuracy:98.2%
Progress:78.9% Speed(reviews/sec):98.93 #Correct:719964 #Trained:732501 Training Accuracy:98.2%
Progress:79.2% Speed(reviews/sec):98.95 #Correct:722375 #Trained:735001 Training Accuracy:98.2%
Progress:79.5% Speed(reviews/sec):98.97 #Correct:724787 #Trained:737501 Training Accuracy:98.2%
Progress:79.7% Speed(reviews/sec):99.00 #Correct:727164 #Trained:740001 Training Accuracy:98.2%
Progress:80.0% Speed(reviews/sec):99.01 #Correct:729595 #Trained:742501 Training Accuracy:98.2%
Progress:80.3% Speed(reviews/sec):99.04 #Correct:731996 #Trained:745001 Training Accuracy:98.2%
Progress:80.5% Speed(reviews/sec):99.06 #Correct:734436 #Trained:747501 Training Accuracy:98.2%
Progress:80.8% Speed(reviews/sec):99.08 #Correct:736870 #Trained:750001 Training Accuracy:98.2%
Progress:81.1% Speed(reviews/sec):99.10 #Correct:739301 #Trained:752501 Training Accuracy:98.2%
Progress:81.4% Speed(reviews/sec):99.11 #Correct:741700 #Trained:755001 Training Accuracy:98.2%
Progress:81.6% Speed(reviews/sec):99.13 #Correct:744124 #Trained:757501 Training Accuracy:98.2%
Progress:81.9% Speed(reviews/sec):99.14 #Correct:746568 #Trained:760001 Training Accuracy:98.2%
Progress:82.2% Speed(reviews/sec):99.16 #Correct:748999 #Trained:762501 Training Accuracy:98.2%
Progress:82.4% Speed(reviews/sec):99.18 #Correct:751404 #Trained:765001 Training Accuracy:98.2%
Progress:82.7% Speed(reviews/sec):99.20 #Correct:753829 #Trained:767501 Training Accuracy:98.2%
Progress:83.0% Speed(reviews/sec):99.22 #Correct:756244 #Trained:770001 Training Accuracy:98.2%
Progress:83.2% Speed(reviews/sec):99.24 #Correct:758682 #Trained:772501 Training Accuracy:98.2%
Progress:83.5% Speed(reviews/sec):99.26 #Correct:761083 #Trained:775001 Training Accuracy:98.2%
Progress:83.8% Speed(reviews/sec):99.28 #Correct:763512 #Trained:777501 Training Accuracy:98.2%
Progress:84.1% Speed(reviews/sec):99.30 #Correct:765938 #Trained:780001 Training Accuracy:98.1%
Progress:84.3% Speed(reviews/sec):99.32 #Correct:768371 #Trained:782501 Training Accuracy:98.1%
Progress:84.6% Speed(reviews/sec):99.34 #Correct:770794 #Trained:785001 Training Accuracy:98.1%
Progress:84.9% Speed(reviews/sec):99.36 #Correct:773220 #Trained:787501 Training Accuracy:98.1%
Progress:85.1% Speed(reviews/sec):99.38 #Correct:775638 #Trained:790001 Training Accuracy:98.1%
Progress:85.4% Speed(reviews/sec):99.39 #Correct:778075 #Trained:792501 Training Accuracy:98.1%
Progress:85.7% Speed(reviews/sec):99.41 #Correct:780501 #Trained:795001 Training Accuracy:98.1%
Progress:85.9% Speed(reviews/sec):99.43 #Correct:782924 #Trained:797501 Training Accuracy:98.1%
Progress:86.2% Speed(reviews/sec):99.45 #Correct:785333 #Trained:800001 Training Accuracy:98.1%
Progress:86.5% Speed(reviews/sec):99.47 #Correct:787730 #Trained:802501 Training Accuracy:98.1%
Progress:86.7% Speed(reviews/sec):99.49 #Correct:790150 #Trained:805001 Training Accuracy:98.1%
Progress:87.0% Speed(reviews/sec):99.50 #Correct:792498 #Trained:807501 Training Accuracy:98.1%
Progress:87.3% Speed(reviews/sec):99.52 #Correct:794918 #Trained:810001 Training Accuracy:98.1%
Progress:87.6% Speed(reviews/sec):99.53 #Correct:797338 #Trained:812501 Training Accuracy:98.1%
Progress:87.8% Speed(reviews/sec):99.55 #Correct:799720 #Trained:815001 Training Accuracy:98.1%
Progress:88.1% Speed(reviews/sec):99.57 #Correct:802133 #Trained:817501 Training Accuracy:98.1%
Progress:88.4% Speed(reviews/sec):99.58 #Correct:804565 #Trained:820001 Training Accuracy:98.1%
Progress:88.6% Speed(reviews/sec):99.60 #Correct:806988 #Trained:822501 Training Accuracy:98.1%
Progress:88.9% Speed(reviews/sec):99.62 #Correct:809408 #Trained:825001 Training Accuracy:98.1%
Progress:89.2% Speed(reviews/sec):99.65 #Correct:811818 #Trained:827501 Training Accuracy:98.1%
Progress:89.4% Speed(reviews/sec):99.67 #Correct:814247 #Trained:830001 Training Accuracy:98.1%
Progress:89.7% Speed(reviews/sec):99.68 #Correct:816676 #Trained:832501 Training Accuracy:98.0%
Progress:90.0% Speed(reviews/sec):99.70 #Correct:819090 #Trained:835001 Training Accuracy:98.0%
Progress:90.3% Speed(reviews/sec):99.72 #Correct:821487 #Trained:837501 Training Accuracy:98.0%
Progress:90.5% Speed(reviews/sec):99.73 #Correct:823886 #Trained:840001 Training Accuracy:98.0%
Progress:90.8% Speed(reviews/sec):99.70 #Correct:826308 #Trained:842501 Training Accuracy:98.0%
Progress:91.1% Speed(reviews/sec):99.66 #Correct:828735 #Trained:845001 Training Accuracy:98.0%
Progress:91.3% Speed(reviews/sec):99.60 #Correct:831104 #Trained:847501 Training Accuracy:98.0%
Progress:91.6% Speed(reviews/sec):99.61 #Correct:833543 #Trained:850001 Training Accuracy:98.0%
Progress:91.9% Speed(reviews/sec):99.63 #Correct:835985 #Trained:852501 Training Accuracy:98.0%
Progress:92.1% Speed(reviews/sec):99.64 #Correct:838385 #Trained:855001 Training Accuracy:98.0%
Progress:92.4% Speed(reviews/sec):99.66 #Correct:840775 #Trained:857501 Training Accuracy:98.0%
Progress:92.7% Speed(reviews/sec):99.68 #Correct:843241 #Trained:860001 Training Accuracy:98.0%
Progress:92.9% Speed(reviews/sec):99.69 #Correct:845663 #Trained:862501 Training Accuracy:98.0%
Progress:93.2% Speed(reviews/sec):99.71 #Correct:848083 #Trained:865001 Training Accuracy:98.0%
Progress:93.5% Speed(reviews/sec):99.73 #Correct:850504 #Trained:867501 Training Accuracy:98.0%
Progress:93.8% Speed(reviews/sec):99.75 #Correct:852913 #Trained:870001 Training Accuracy:98.0%
Progress:94.0% Speed(reviews/sec):99.77 #Correct:855339 #Trained:872501 Training Accuracy:98.0%
Progress:94.3% Speed(reviews/sec):99.78 #Correct:857774 #Trained:875001 Training Accuracy:98.0%
Progress:94.6% Speed(reviews/sec):99.79 #Correct:860189 #Trained:877501 Training Accuracy:98.0%
Progress:94.8% Speed(reviews/sec):99.77 #Correct:862612 #Trained:880001 Training Accuracy:98.0%
Progress:95.1% Speed(reviews/sec):99.76 #Correct:865037 #Trained:882501 Training Accuracy:98.0%
Progress:95.4% Speed(reviews/sec):99.74 #Correct:867453 #Trained:885001 Training Accuracy:98.0%
Progress:95.6% Speed(reviews/sec):99.70 #Correct:869870 #Trained:887501 Training Accuracy:98.0%
Progress:95.9% Speed(reviews/sec):99.71 #Correct:872287 #Trained:890001 Training Accuracy:98.0%
Progress:96.2% Speed(reviews/sec):99.69 #Correct:874694 #Trained:892501 Training Accuracy:98.0%
Progress:96.5% Speed(reviews/sec):99.69 #Correct:877135 #Trained:895001 Training Accuracy:98.0%
Progress:96.7% Speed(reviews/sec):99.71 #Correct:879526 #Trained:897501 Training Accuracy:97.9%
Progress:97.0% Speed(reviews/sec):99.73 #Correct:881951 #Trained:900001 Training Accuracy:97.9%
Progress:97.3% Speed(reviews/sec):99.76 #Correct:884363 #Trained:902501 Training Accuracy:97.9%
Progress:97.5% Speed(reviews/sec):99.77 #Correct:886770 #Trained:905001 Training Accuracy:97.9%
Progress:97.8% Speed(reviews/sec):99.79 #Correct:889170 #Trained:907501 Training Accuracy:97.9%
Progress:98.1% Speed(reviews/sec):99.80 #Correct:891589 #Trained:910001 Training Accuracy:97.9%
Progress:98.3% Speed(reviews/sec):99.82 #Correct:893970 #Trained:912501 Training Accuracy:97.9%
Progress:98.6% Speed(reviews/sec):99.83 #Correct:896382 #Trained:915001 Training Accuracy:97.9%
Progress:98.9% Speed(reviews/sec):99.84 #Correct:898799 #Trained:917501 Training Accuracy:97.9%
Progress:99.1% Speed(reviews/sec):99.85 #Correct:901192 #Trained:920001 Training Accuracy:97.9%
Progress:99.4% Speed(reviews/sec):99.87 #Correct:903555 #Trained:922501 Training Accuracy:97.9%
Progress:99.7% Speed(reviews/sec):99.88 #Correct:905971 #Trained:925001 Training Accuracy:97.9%
Progress:99.9% Speed(reviews/sec):99.89 #Correct:908308 #Trained:927422 Training Accuracy:97.9%</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Testing-neural-network">Testing neural network<a class="anchor-link" href="#Testing-neural-network">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[74]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mlp</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">reviews</span><span class="p">[</span><span class="o">-</span><span class="mi">103000</span><span class="p">:],</span><span class="n">labels</span><span class="p">[</span><span class="o">-</span><span class="mi">103000</span><span class="p">:])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Progress:71.4% Speed(reviews/sec):1339. #Correct:70932 #Tested:73608 Testing Accuracy:96.3%Progress:99.9% Speed(reviews/sec):1348. #Correct:99480 #Tested:103000 Testing Accuracy:96.5%</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[40]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">update_input_layer</span><span class="p">(</span><span class="n">review</span><span class="p">):</span>
    
    <span class="k">global</span> <span class="n">layer_0</span>
    
    <span class="c1"># clear out previous state, reset the layer to be all 0s</span>
    <span class="n">layer_0</span> <span class="o">*=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">review</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
        <span class="n">layer_0</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]]</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">update_input_layer</span><span class="p">(</span><span class="n">reviews</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[41]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">layer_0</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[41]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[2., 0., 0., ..., 0., 0., 0.]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[42]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">review_counter</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[43]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">reviews</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
    <span class="n">review_counter</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[44]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">review_counter</span><span class="o">.</span><span class="n">most_common</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[44]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[(&#39;&#39;, 2),
 (&#39;the&#39;, 2),
 (&#39;only&#39;, 1),
 (&#39;park&#39;, 1),
 (&#39;outside&#39;, 1),
 (&#39;of&#39;, 1),
 (&#39;hotel&#39;, 1),
 (&#39;was&#39;, 1),
 (&#39;beautiful&#39;, 1)]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Reducing-Noise-in-Our-Input-Data">Reducing Noise in Our Input Data<a class="anchor-link" href="#Reducing-Noise-in-Our-Input-Data">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[47]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Encapsulate our neural network in a class</span>
<span class="k">class</span> <span class="nc">SentimentNetwork</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reviews</span><span class="p">,</span><span class="n">labels</span><span class="p">,</span><span class="n">hidden_nodes</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create a SentimenNetwork with the given settings</span>
<span class="sd">        Args:</span>
<span class="sd">            reviews(list) - List of reviews used for training</span>
<span class="sd">            labels(list) - List of POSITIVE/NEGATIVE labels associated with the given reviews</span>
<span class="sd">            hidden_nodes(int) - Number of nodes to create in the hidden layer</span>
<span class="sd">            learning_rate(float) - Learning rate to use while training</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Assign a seed to our random number generator to ensure we get</span>
        <span class="c1"># reproducable results during development </span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># process the reviews and their associated labels so that everything</span>
        <span class="c1"># is ready for training</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_process_data</span><span class="p">(</span><span class="n">reviews</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        
        <span class="c1"># Build the network to have the number of hidden nodes and the learning rate that</span>
        <span class="c1"># were passed into this initializer. Make the same number of input nodes as</span>
        <span class="c1"># there are vocabulary words and create a single output node.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_network</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">review_vocab</span><span class="p">),</span><span class="n">hidden_nodes</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">pre_process_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reviews</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        
        <span class="c1"># populate review_vocab with all of the words in the given reviews</span>
        <span class="n">review_vocab</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">review</span> <span class="ow">in</span> <span class="n">reviews</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">review</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
                <span class="n">review_vocab</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

        <span class="c1"># Convert the vocabulary set to a list so we can access words via indices</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">review_vocab</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">review_vocab</span><span class="p">)</span>
        
        <span class="c1"># populate label_vocab with all of the words in the given labels.</span>
        <span class="n">label_vocab</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">:</span>
            <span class="n">label_vocab</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
        
        <span class="c1"># Convert the label vocabulary set to a list so we can access labels via indices</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_vocab</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">label_vocab</span><span class="p">)</span>
        
        <span class="c1"># Store the sizes of the review and label vocabularies.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">review_vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">review_vocab</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_vocab</span><span class="p">)</span>
        
        <span class="c1"># Create a dictionary of words in the vocabulary mapped to index positions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">review_vocab</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
        
        <span class="c1"># Create a dictionary of labels mapped to index positions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label2index</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_vocab</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">label2index</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
        
    <span class="k">def</span> <span class="nf">init_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_nodes</span><span class="p">,</span> <span class="n">hidden_nodes</span><span class="p">,</span> <span class="n">output_nodes</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
        <span class="c1"># Set number of nodes in input, hidden and output layers.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_nodes</span> <span class="o">=</span> <span class="n">input_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_nodes</span> <span class="o">=</span> <span class="n">hidden_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_nodes</span> <span class="o">=</span> <span class="n">output_nodes</span>

        <span class="c1"># Store the learning rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>

        <span class="c1"># Initialize weights</span>

        <span class="c1"># These are the weights between the input layer and the hidden layer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_0_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">input_nodes</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_nodes</span><span class="p">))</span>
    
        <span class="c1"># These are the weights between the hidden layer and the output layer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_1_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_nodes</span><span class="o">**-</span><span class="mf">0.5</span><span class="p">,</span> 
                                                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_nodes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_nodes</span><span class="p">))</span>
        
        <span class="c1"># The input layer, a two-dimensional matrix with shape 1 x input_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">input_nodes</span><span class="p">))</span>
    
        
    <span class="k">def</span> <span class="nf">update_input_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">review</span><span class="p">):</span>

        <span class="c1"># clear out previous state, reset the layer to be all 0s</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_0</span> <span class="o">*=</span> <span class="mi">0</span>
        
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">review</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
        
            <span class="k">if</span><span class="p">(</span><span class="n">word</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
                
                <span class="bp">self</span><span class="o">.</span><span class="n">layer_0</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
                
    <span class="k">def</span> <span class="nf">get_target_for_label</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">label</span><span class="p">):</span>
        <span class="k">if</span><span class="p">(</span><span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">return</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
        
    <span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">sigmoid_output_2_derivative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">output</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">output</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">output</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_reviews</span><span class="p">,</span> <span class="n">training_labels</span><span class="p">):</span>
        
        <span class="c1"># make sure out we have a matching number of reviews and labels</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">training_reviews</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">training_labels</span><span class="p">))</span>
        
        <span class="c1"># Keep track of correct predictions to display accuracy during training </span>
        <span class="n">correct_so_far</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Remember when we started for printing time statistics</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        
        <span class="c1"># loop through all the given reviews and run a forward and backward pass,</span>
        <span class="c1"># updating weights for every item</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">training_reviews</span><span class="p">)):</span>
            
            <span class="c1"># Get the next review and its correct label</span>
            <span class="n">review</span> <span class="o">=</span> <span class="n">training_reviews</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">label</span> <span class="o">=</span> <span class="n">training_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            
            <span class="c1">#### Implement the forward pass here ####</span>
            <span class="c1">### Forward pass ###</span>

            <span class="c1"># Input Layer</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update_input_layer</span><span class="p">(</span><span class="n">review</span><span class="p">)</span>

            <span class="c1"># Hidden layer</span>
            <span class="n">layer_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_0</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_0_1</span><span class="p">)</span>

            <span class="c1"># Output layer</span>
            <span class="n">layer_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">layer_1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_1_2</span><span class="p">))</span>
            
            <span class="c1">#### Implement the backward pass here ####</span>
            <span class="c1">### Backward pass ###</span>

            <span class="c1"># Output error</span>
            <span class="n">layer_2_error</span> <span class="o">=</span> <span class="n">layer_2</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_target_for_label</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="c1"># Output layer error is the difference between desired target and actual output.</span>
            <span class="n">layer_2_delta</span> <span class="o">=</span> <span class="n">layer_2_error</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid_output_2_derivative</span><span class="p">(</span><span class="n">layer_2</span><span class="p">)</span>

            <span class="c1"># Backpropagated error</span>
            <span class="n">layer_1_error</span> <span class="o">=</span> <span class="n">layer_2_delta</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_1_2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="c1"># errors propagated to the hidden layer</span>
            <span class="n">layer_1_delta</span> <span class="o">=</span> <span class="n">layer_1_error</span> <span class="c1"># hidden layer gradients - no nonlinearity so it&#39;s the same as the error</span>

            <span class="c1"># Update the weights</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights_1_2</span> <span class="o">-=</span> <span class="n">layer_1</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">layer_2_delta</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="c1"># update hidden-to-output weights with gradient descent step</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights_0_1</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_0</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">layer_1_delta</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="c1"># update input-to-hidden weights with gradient descent step</span>

            <span class="c1"># Keep track of correct predictions.</span>
            <span class="k">if</span><span class="p">(</span><span class="n">layer_2</span> <span class="o">&gt;=</span> <span class="mf">0.5</span> <span class="ow">and</span> <span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
                <span class="n">correct_so_far</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">elif</span><span class="p">(</span><span class="n">layer_2</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">and</span> <span class="n">label</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                <span class="n">correct_so_far</span> <span class="o">+=</span> <span class="mi">1</span>
            
            <span class="c1"># For debug purposes, print out our prediction accuracy and speed </span>
            <span class="c1"># throughout the training process. </span>
            <span class="n">elapsed_time</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>
            <span class="n">reviews_per_second</span> <span class="o">=</span> <span class="n">i</span> <span class="o">/</span> <span class="n">elapsed_time</span> <span class="k">if</span> <span class="n">elapsed_time</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
            
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">Progress:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">i</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">training_reviews</span><span class="p">)))[:</span><span class="mi">4</span><span class="p">]</span> \
                             <span class="o">+</span> <span class="s2">&quot;% Speed(reviews/sec):&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">reviews_per_second</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span> \
                             <span class="o">+</span> <span class="s2">&quot; #Correct:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">correct_so_far</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; #Trained:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> \
                             <span class="o">+</span> <span class="s2">&quot; Training Accuracy:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">correct_so_far</span> <span class="o">*</span> <span class="mi">100</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))[:</span><span class="mi">4</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;%&quot;</span><span class="p">)</span>
            <span class="k">if</span><span class="p">(</span><span class="n">i</span> <span class="o">%</span> <span class="mi">2500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">testing_reviews</span><span class="p">,</span> <span class="n">testing_labels</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Attempts to predict the labels for the given testing_reviews,</span>
<span class="sd">        and uses the test_labels to calculate the accuracy of those predictions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="c1"># keep track of how many correct predictions we make</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># we&#39;ll time how many predictions per second we make</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="c1"># Loop through each of the given reviews and call run to predict</span>
        <span class="c1"># its label. </span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">testing_reviews</span><span class="p">)):</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">testing_reviews</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="k">if</span><span class="p">(</span><span class="n">pred</span> <span class="o">==</span> <span class="n">testing_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span>
                <span class="n">correct</span> <span class="o">+=</span> <span class="mi">1</span>
            
            <span class="c1"># For debug purposes, print out our prediction accuracy and speed </span>
            <span class="c1"># throughout the prediction process. </span>

            <span class="n">elapsed_time</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>
            <span class="n">reviews_per_second</span> <span class="o">=</span> <span class="n">i</span> <span class="o">/</span> <span class="n">elapsed_time</span> <span class="k">if</span> <span class="n">elapsed_time</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
            
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">Progress:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">i</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">testing_reviews</span><span class="p">)))[:</span><span class="mi">4</span><span class="p">]</span> \
                             <span class="o">+</span> <span class="s2">&quot;% Speed(reviews/sec):&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">reviews_per_second</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span> \
                             <span class="o">+</span> <span class="s2">&quot; #Correct:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">correct</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; #Tested:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> \
                             <span class="o">+</span> <span class="s2">&quot; Testing Accuracy:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">correct</span> <span class="o">*</span> <span class="mi">100</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))[:</span><span class="mi">4</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;%&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">review</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a POSITIVE or NEGATIVE prediction for the given review.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Run a forward pass through the network, like in the &quot;train&quot; function.</span>
        
        <span class="c1"># Input Layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_input_layer</span><span class="p">(</span><span class="n">review</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>

        <span class="c1"># Hidden layer</span>
        <span class="n">layer_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_0</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_0_1</span><span class="p">)</span>

        <span class="c1"># Output layer</span>
        <span class="n">layer_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">layer_1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_1_2</span><span class="p">))</span>
        
        <span class="c1"># Return POSITIVE for values above greater-than-or-equal-to 0.5 in the output layer;</span>
        <span class="c1"># return NEGATIVE for other values</span>
        <span class="k">if</span><span class="p">(</span><span class="n">layer_2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">):</span>
            <span class="k">return</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
        
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Training-and-testing-the-model">Training and testing the model<a class="anchor-link" href="#Training-and-testing-the-model">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[48]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mlp</span> <span class="o">=</span> <span class="n">SentimentNetwork</span><span class="p">(</span><span class="n">reviews</span><span class="p">[:</span><span class="o">-</span><span class="mi">103000</span><span class="p">],</span><span class="n">labels</span><span class="p">[:</span><span class="o">-</span><span class="mi">103000</span><span class="p">],</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">mlp</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">reviews</span><span class="p">[:</span><span class="o">-</span><span class="mi">103000</span><span class="p">],</span><span class="n">labels</span><span class="p">[:</span><span class="o">-</span><span class="mi">103000</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Progress:0.0% Speed(reviews/sec):0.0 #Correct:1 #Trained:1 Training Accuracy:100.%
Progress:0.26% Speed(reviews/sec):111.4 #Correct:2497 #Trained:2501 Training Accuracy:99.8%
Progress:0.53% Speed(reviews/sec):109.3 #Correct:4980 #Trained:5001 Training Accuracy:99.5%
Progress:0.80% Speed(reviews/sec):105.5 #Correct:7478 #Trained:7501 Training Accuracy:99.6%
Progress:1.07% Speed(reviews/sec):101.7 #Correct:9969 #Trained:10001 Training Accuracy:99.6%
Progress:1.34% Speed(reviews/sec):98.67 #Correct:12460 #Trained:12501 Training Accuracy:99.6%
Progress:1.61% Speed(reviews/sec):98.87 #Correct:14957 #Trained:15001 Training Accuracy:99.7%
Progress:1.88% Speed(reviews/sec):100.4 #Correct:17455 #Trained:17501 Training Accuracy:99.7%
Progress:2.15% Speed(reviews/sec):101.7 #Correct:19953 #Trained:20001 Training Accuracy:99.7%
Progress:2.42% Speed(reviews/sec):102.8 #Correct:22451 #Trained:22501 Training Accuracy:99.7%
Progress:2.69% Speed(reviews/sec):103.6 #Correct:24950 #Trained:25001 Training Accuracy:99.7%
Progress:2.96% Speed(reviews/sec):104.1 #Correct:27444 #Trained:27501 Training Accuracy:99.7%
Progress:3.23% Speed(reviews/sec):104.5 #Correct:29941 #Trained:30001 Training Accuracy:99.8%
Progress:3.50% Speed(reviews/sec):104.8 #Correct:32438 #Trained:32501 Training Accuracy:99.8%
Progress:3.77% Speed(reviews/sec):104.6 #Correct:34938 #Trained:35001 Training Accuracy:99.8%
Progress:4.04% Speed(reviews/sec):104.1 #Correct:37433 #Trained:37501 Training Accuracy:99.8%
Progress:4.31% Speed(reviews/sec):103.2 #Correct:39931 #Trained:40001 Training Accuracy:99.8%
Progress:4.58% Speed(reviews/sec):103.3 #Correct:42428 #Trained:42501 Training Accuracy:99.8%
Progress:4.85% Speed(reviews/sec):103.8 #Correct:44921 #Trained:45001 Training Accuracy:99.8%
Progress:5.12% Speed(reviews/sec):104.2 #Correct:47420 #Trained:47501 Training Accuracy:99.8%
Progress:5.39% Speed(reviews/sec):104.6 #Correct:49918 #Trained:50001 Training Accuracy:99.8%
Progress:5.66% Speed(reviews/sec):105.1 #Correct:52416 #Trained:52501 Training Accuracy:99.8%
Progress:5.93% Speed(reviews/sec):105.4 #Correct:54913 #Trained:55001 Training Accuracy:99.8%
Progress:6.19% Speed(reviews/sec):105.7 #Correct:57410 #Trained:57501 Training Accuracy:99.8%
Progress:6.46% Speed(reviews/sec):106.0 #Correct:59905 #Trained:60001 Training Accuracy:99.8%
Progress:6.73% Speed(reviews/sec):106.1 #Correct:62401 #Trained:62501 Training Accuracy:99.8%
Progress:7.00% Speed(reviews/sec):106.3 #Correct:64893 #Trained:65001 Training Accuracy:99.8%
Progress:7.27% Speed(reviews/sec):106.4 #Correct:67374 #Trained:67501 Training Accuracy:99.8%
Progress:7.54% Speed(reviews/sec):106.4 #Correct:69862 #Trained:70001 Training Accuracy:99.8%
Progress:7.81% Speed(reviews/sec):106.3 #Correct:72358 #Trained:72501 Training Accuracy:99.8%
Progress:8.08% Speed(reviews/sec):106.0 #Correct:74857 #Trained:75001 Training Accuracy:99.8%
Progress:8.35% Speed(reviews/sec):106.0 #Correct:77355 #Trained:77501 Training Accuracy:99.8%
Progress:8.62% Speed(reviews/sec):106.0 #Correct:79853 #Trained:80001 Training Accuracy:99.8%
Progress:8.89% Speed(reviews/sec):106.0 #Correct:82348 #Trained:82501 Training Accuracy:99.8%
Progress:9.16% Speed(reviews/sec):105.9 #Correct:84848 #Trained:85001 Training Accuracy:99.8%
Progress:9.43% Speed(reviews/sec):105.8 #Correct:87346 #Trained:87501 Training Accuracy:99.8%
Progress:9.70% Speed(reviews/sec):105.1 #Correct:89846 #Trained:90001 Training Accuracy:99.8%
Progress:9.97% Speed(reviews/sec):104.3 #Correct:92342 #Trained:92501 Training Accuracy:99.8%
Progress:10.2% Speed(reviews/sec):104.1 #Correct:94841 #Trained:95001 Training Accuracy:99.8%
Progress:10.5% Speed(reviews/sec):104.1 #Correct:97339 #Trained:97501 Training Accuracy:99.8%
Progress:10.7% Speed(reviews/sec):104.1 #Correct:99838 #Trained:100001 Training Accuracy:99.8%
Progress:11.0% Speed(reviews/sec):104.2 #Correct:102334 #Trained:102501 Training Accuracy:99.8%
Progress:11.3% Speed(reviews/sec):103.6 #Correct:104829 #Trained:105001 Training Accuracy:99.8%
Progress:11.5% Speed(reviews/sec):103.1 #Correct:107327 #Trained:107501 Training Accuracy:99.8%
Progress:11.8% Speed(reviews/sec):102.5 #Correct:109822 #Trained:110001 Training Accuracy:99.8%
Progress:12.1% Speed(reviews/sec):102.3 #Correct:112317 #Trained:112501 Training Accuracy:99.8%
Progress:12.3% Speed(reviews/sec):102.5 #Correct:114810 #Trained:115001 Training Accuracy:99.8%
Progress:12.6% Speed(reviews/sec):102.6 #Correct:117303 #Trained:117501 Training Accuracy:99.8%
Progress:12.9% Speed(reviews/sec):102.7 #Correct:119801 #Trained:120001 Training Accuracy:99.8%
Progress:13.2% Speed(reviews/sec):102.7 #Correct:122299 #Trained:122501 Training Accuracy:99.8%
Progress:13.4% Speed(reviews/sec):102.8 #Correct:124793 #Trained:125001 Training Accuracy:99.8%
Progress:13.7% Speed(reviews/sec):102.7 #Correct:127292 #Trained:127501 Training Accuracy:99.8%
Progress:14.0% Speed(reviews/sec):102.5 #Correct:129790 #Trained:130001 Training Accuracy:99.8%
Progress:14.2% Speed(reviews/sec):102.5 #Correct:132286 #Trained:132501 Training Accuracy:99.8%
Progress:14.5% Speed(reviews/sec):102.4 #Correct:134785 #Trained:135001 Training Accuracy:99.8%
Progress:14.8% Speed(reviews/sec):102.5 #Correct:137277 #Trained:137501 Training Accuracy:99.8%
Progress:15.0% Speed(reviews/sec):102.3 #Correct:139776 #Trained:140001 Training Accuracy:99.8%
Progress:15.3% Speed(reviews/sec):102.2 #Correct:142272 #Trained:142501 Training Accuracy:99.8%
Progress:15.6% Speed(reviews/sec):102.2 #Correct:144771 #Trained:145001 Training Accuracy:99.8%
Progress:15.9% Speed(reviews/sec):102.2 #Correct:147270 #Trained:147501 Training Accuracy:99.8%
Progress:16.1% Speed(reviews/sec):102.3 #Correct:149769 #Trained:150001 Training Accuracy:99.8%
Progress:16.4% Speed(reviews/sec):102.5 #Correct:152268 #Trained:152501 Training Accuracy:99.8%
Progress:16.7% Speed(reviews/sec):102.6 #Correct:154767 #Trained:155001 Training Accuracy:99.8%
Progress:16.9% Speed(reviews/sec):102.8 #Correct:157265 #Trained:157501 Training Accuracy:99.8%
Progress:17.2% Speed(reviews/sec):102.9 #Correct:159759 #Trained:160001 Training Accuracy:99.8%
Progress:17.5% Speed(reviews/sec):103.0 #Correct:162256 #Trained:162501 Training Accuracy:99.8%
Progress:17.7% Speed(reviews/sec):102.9 #Correct:164751 #Trained:165001 Training Accuracy:99.8%
Progress:18.0% Speed(reviews/sec):103.0 #Correct:167250 #Trained:167501 Training Accuracy:99.8%
Progress:18.3% Speed(reviews/sec):102.9 #Correct:169748 #Trained:170001 Training Accuracy:99.8%
Progress:18.5% Speed(reviews/sec):102.9 #Correct:172244 #Trained:172501 Training Accuracy:99.8%
Progress:18.8% Speed(reviews/sec):102.9 #Correct:174742 #Trained:175001 Training Accuracy:99.8%
Progress:19.1% Speed(reviews/sec):102.9 #Correct:177237 #Trained:177501 Training Accuracy:99.8%
Progress:19.4% Speed(reviews/sec):102.8 #Correct:179736 #Trained:180001 Training Accuracy:99.8%
Progress:19.6% Speed(reviews/sec):102.7 #Correct:182236 #Trained:182501 Training Accuracy:99.8%
Progress:19.9% Speed(reviews/sec):102.6 #Correct:184733 #Trained:185001 Training Accuracy:99.8%
Progress:20.2% Speed(reviews/sec):102.7 #Correct:187228 #Trained:187501 Training Accuracy:99.8%
Progress:20.4% Speed(reviews/sec):102.8 #Correct:189727 #Trained:190001 Training Accuracy:99.8%
Progress:20.7% Speed(reviews/sec):102.9 #Correct:192220 #Trained:192501 Training Accuracy:99.8%
Progress:21.0% Speed(reviews/sec):103.0 #Correct:194719 #Trained:195001 Training Accuracy:99.8%
Progress:21.2% Speed(reviews/sec):102.9 #Correct:197219 #Trained:197501 Training Accuracy:99.8%
Progress:21.5% Speed(reviews/sec):102.8 #Correct:199717 #Trained:200001 Training Accuracy:99.8%
Progress:21.8% Speed(reviews/sec):102.7 #Correct:202208 #Trained:202501 Training Accuracy:99.8%
Progress:22.1% Speed(reviews/sec):102.5 #Correct:204699 #Trained:205001 Training Accuracy:99.8%
Progress:22.3% Speed(reviews/sec):102.6 #Correct:207195 #Trained:207501 Training Accuracy:99.8%
Progress:22.6% Speed(reviews/sec):102.6 #Correct:209692 #Trained:210001 Training Accuracy:99.8%
Progress:22.9% Speed(reviews/sec):102.7 #Correct:212190 #Trained:212501 Training Accuracy:99.8%
Progress:23.1% Speed(reviews/sec):102.7 #Correct:214686 #Trained:215001 Training Accuracy:99.8%
Progress:23.4% Speed(reviews/sec):102.8 #Correct:217184 #Trained:217501 Training Accuracy:99.8%
Progress:23.7% Speed(reviews/sec):102.8 #Correct:219682 #Trained:220001 Training Accuracy:99.8%
Progress:23.9% Speed(reviews/sec):102.8 #Correct:222178 #Trained:222501 Training Accuracy:99.8%
Progress:24.2% Speed(reviews/sec):102.9 #Correct:224675 #Trained:225001 Training Accuracy:99.8%
Progress:24.5% Speed(reviews/sec):102.9 #Correct:227173 #Trained:227501 Training Accuracy:99.8%
Progress:24.7% Speed(reviews/sec):103.0 #Correct:229673 #Trained:230001 Training Accuracy:99.8%
Progress:25.0% Speed(reviews/sec):103.0 #Correct:232171 #Trained:232501 Training Accuracy:99.8%
Progress:25.3% Speed(reviews/sec):103.0 #Correct:234669 #Trained:235001 Training Accuracy:99.8%
Progress:25.6% Speed(reviews/sec):102.9 #Correct:237169 #Trained:237501 Training Accuracy:99.8%
Progress:25.8% Speed(reviews/sec):102.8 #Correct:239667 #Trained:240001 Training Accuracy:99.8%
Progress:26.1% Speed(reviews/sec):102.7 #Correct:242163 #Trained:242501 Training Accuracy:99.8%
Progress:26.4% Speed(reviews/sec):102.6 #Correct:244659 #Trained:245001 Training Accuracy:99.8%
Progress:26.6% Speed(reviews/sec):102.6 #Correct:247153 #Trained:247501 Training Accuracy:99.8%
Progress:26.9% Speed(reviews/sec):102.6 #Correct:249652 #Trained:250001 Training Accuracy:99.8%
Progress:27.2% Speed(reviews/sec):102.6 #Correct:252151 #Trained:252501 Training Accuracy:99.8%
Progress:27.4% Speed(reviews/sec):102.6 #Correct:254649 #Trained:255001 Training Accuracy:99.8%
Progress:27.7% Speed(reviews/sec):102.6 #Correct:257147 #Trained:257501 Training Accuracy:99.8%
Progress:28.0% Speed(reviews/sec):102.6 #Correct:259644 #Trained:260001 Training Accuracy:99.8%
Progress:28.3% Speed(reviews/sec):102.6 #Correct:262144 #Trained:262501 Training Accuracy:99.8%
Progress:28.5% Speed(reviews/sec):102.6 #Correct:264638 #Trained:265001 Training Accuracy:99.8%
Progress:28.8% Speed(reviews/sec):102.5 #Correct:267133 #Trained:267501 Training Accuracy:99.8%
Progress:29.1% Speed(reviews/sec):102.5 #Correct:269632 #Trained:270001 Training Accuracy:99.8%
Progress:29.3% Speed(reviews/sec):102.5 #Correct:272131 #Trained:272501 Training Accuracy:99.8%
Progress:29.6% Speed(reviews/sec):102.5 #Correct:274628 #Trained:275001 Training Accuracy:99.8%
Progress:29.9% Speed(reviews/sec):102.6 #Correct:277126 #Trained:277501 Training Accuracy:99.8%
Progress:30.1% Speed(reviews/sec):102.6 #Correct:279624 #Trained:280001 Training Accuracy:99.8%
Progress:30.4% Speed(reviews/sec):102.7 #Correct:282123 #Trained:282501 Training Accuracy:99.8%
Progress:30.7% Speed(reviews/sec):102.8 #Correct:284622 #Trained:285001 Training Accuracy:99.8%
Progress:30.9% Speed(reviews/sec):102.8 #Correct:287121 #Trained:287501 Training Accuracy:99.8%
Progress:31.2% Speed(reviews/sec):102.8 #Correct:289621 #Trained:290001 Training Accuracy:99.8%
Progress:31.5% Speed(reviews/sec):102.7 #Correct:292119 #Trained:292501 Training Accuracy:99.8%
Progress:31.8% Speed(reviews/sec):102.8 #Correct:294614 #Trained:295001 Training Accuracy:99.8%
Progress:32.0% Speed(reviews/sec):102.8 #Correct:297113 #Trained:297501 Training Accuracy:99.8%
Progress:32.3% Speed(reviews/sec):102.8 #Correct:299609 #Trained:300001 Training Accuracy:99.8%
Progress:32.6% Speed(reviews/sec):102.8 #Correct:302104 #Trained:302501 Training Accuracy:99.8%
Progress:32.8% Speed(reviews/sec):102.9 #Correct:304603 #Trained:305001 Training Accuracy:99.8%
Progress:33.1% Speed(reviews/sec):102.8 #Correct:307101 #Trained:307501 Training Accuracy:99.8%
Progress:33.4% Speed(reviews/sec):102.8 #Correct:309598 #Trained:310001 Training Accuracy:99.8%
Progress:33.6% Speed(reviews/sec):102.9 #Correct:312093 #Trained:312501 Training Accuracy:99.8%
Progress:33.9% Speed(reviews/sec):102.9 #Correct:314589 #Trained:315001 Training Accuracy:99.8%
Progress:34.2% Speed(reviews/sec):102.9 #Correct:317086 #Trained:317501 Training Accuracy:99.8%
Progress:34.5% Speed(reviews/sec):102.9 #Correct:319584 #Trained:320001 Training Accuracy:99.8%
Progress:34.7% Speed(reviews/sec):102.9 #Correct:322082 #Trained:322501 Training Accuracy:99.8%
Progress:35.0% Speed(reviews/sec):102.9 #Correct:324577 #Trained:325001 Training Accuracy:99.8%
Progress:35.3% Speed(reviews/sec):102.9 #Correct:327075 #Trained:327501 Training Accuracy:99.8%
Progress:35.5% Speed(reviews/sec):102.9 #Correct:329571 #Trained:330001 Training Accuracy:99.8%
Progress:35.8% Speed(reviews/sec):102.9 #Correct:332068 #Trained:332501 Training Accuracy:99.8%
Progress:36.1% Speed(reviews/sec):102.9 #Correct:334564 #Trained:335001 Training Accuracy:99.8%
Progress:36.3% Speed(reviews/sec):102.9 #Correct:337060 #Trained:337501 Training Accuracy:99.8%
Progress:36.6% Speed(reviews/sec):102.9 #Correct:339560 #Trained:340001 Training Accuracy:99.8%
Progress:36.9% Speed(reviews/sec):102.9 #Correct:342059 #Trained:342501 Training Accuracy:99.8%
Progress:37.1% Speed(reviews/sec):102.9 #Correct:344553 #Trained:345001 Training Accuracy:99.8%
Progress:37.4% Speed(reviews/sec):103.0 #Correct:347051 #Trained:347501 Training Accuracy:99.8%
Progress:37.7% Speed(reviews/sec):102.9 #Correct:349548 #Trained:350001 Training Accuracy:99.8%
Progress:38.0% Speed(reviews/sec):102.9 #Correct:352045 #Trained:352501 Training Accuracy:99.8%
Progress:38.2% Speed(reviews/sec):102.9 #Correct:354541 #Trained:355001 Training Accuracy:99.8%
Progress:38.5% Speed(reviews/sec):103.0 #Correct:357040 #Trained:357501 Training Accuracy:99.8%
Progress:38.8% Speed(reviews/sec):102.9 #Correct:359539 #Trained:360001 Training Accuracy:99.8%
Progress:39.0% Speed(reviews/sec):102.9 #Correct:362036 #Trained:362501 Training Accuracy:99.8%
Progress:39.3% Speed(reviews/sec):102.9 #Correct:364535 #Trained:365001 Training Accuracy:99.8%
Progress:39.6% Speed(reviews/sec):102.9 #Correct:367030 #Trained:367501 Training Accuracy:99.8%
Progress:39.8% Speed(reviews/sec):102.9 #Correct:369527 #Trained:370001 Training Accuracy:99.8%
Progress:40.1% Speed(reviews/sec):102.9 #Correct:372025 #Trained:372501 Training Accuracy:99.8%
Progress:40.4% Speed(reviews/sec):103.0 #Correct:374523 #Trained:375001 Training Accuracy:99.8%
Progress:40.7% Speed(reviews/sec):103.0 #Correct:377020 #Trained:377501 Training Accuracy:99.8%
Progress:40.9% Speed(reviews/sec):103.1 #Correct:379518 #Trained:380001 Training Accuracy:99.8%
Progress:41.2% Speed(reviews/sec):103.1 #Correct:382015 #Trained:382501 Training Accuracy:99.8%
Progress:41.5% Speed(reviews/sec):103.2 #Correct:384515 #Trained:385001 Training Accuracy:99.8%
Progress:41.7% Speed(reviews/sec):103.1 #Correct:387013 #Trained:387501 Training Accuracy:99.8%
Progress:42.0% Speed(reviews/sec):103.1 #Correct:389511 #Trained:390001 Training Accuracy:99.8%
Progress:42.3% Speed(reviews/sec):103.1 #Correct:392010 #Trained:392501 Training Accuracy:99.8%
Progress:42.5% Speed(reviews/sec):103.2 #Correct:394507 #Trained:395001 Training Accuracy:99.8%
Progress:42.8% Speed(reviews/sec):103.2 #Correct:397004 #Trained:397501 Training Accuracy:99.8%
Progress:43.1% Speed(reviews/sec):103.2 #Correct:399502 #Trained:400001 Training Accuracy:99.8%
Progress:43.3% Speed(reviews/sec):103.2 #Correct:402001 #Trained:402501 Training Accuracy:99.8%
Progress:43.6% Speed(reviews/sec):103.2 #Correct:404499 #Trained:405001 Training Accuracy:99.8%
Progress:43.9% Speed(reviews/sec):103.3 #Correct:406997 #Trained:407501 Training Accuracy:99.8%
Progress:44.2% Speed(reviews/sec):103.3 #Correct:409496 #Trained:410001 Training Accuracy:99.8%
Progress:44.4% Speed(reviews/sec):103.3 #Correct:411994 #Trained:412501 Training Accuracy:99.8%
Progress:44.7% Speed(reviews/sec):103.3 #Correct:414491 #Trained:415001 Training Accuracy:99.8%
Progress:45.0% Speed(reviews/sec):103.4 #Correct:416991 #Trained:417501 Training Accuracy:99.8%
Progress:45.2% Speed(reviews/sec):103.4 #Correct:419487 #Trained:420001 Training Accuracy:99.8%
Progress:45.5% Speed(reviews/sec):103.4 #Correct:421987 #Trained:422501 Training Accuracy:99.8%
Progress:45.8% Speed(reviews/sec):103.4 #Correct:424482 #Trained:425001 Training Accuracy:99.8%
Progress:46.0% Speed(reviews/sec):103.4 #Correct:426980 #Trained:427501 Training Accuracy:99.8%
Progress:46.3% Speed(reviews/sec):103.5 #Correct:429477 #Trained:430001 Training Accuracy:99.8%
Progress:46.6% Speed(reviews/sec):103.5 #Correct:431974 #Trained:432501 Training Accuracy:99.8%
Progress:46.9% Speed(reviews/sec):103.5 #Correct:434473 #Trained:435001 Training Accuracy:99.8%
Progress:47.1% Speed(reviews/sec):103.6 #Correct:436973 #Trained:437501 Training Accuracy:99.8%
Progress:47.4% Speed(reviews/sec):103.6 #Correct:439473 #Trained:440001 Training Accuracy:99.8%
Progress:47.7% Speed(reviews/sec):103.6 #Correct:441971 #Trained:442501 Training Accuracy:99.8%
Progress:47.9% Speed(reviews/sec):103.6 #Correct:444470 #Trained:445001 Training Accuracy:99.8%
Progress:48.2% Speed(reviews/sec):103.6 #Correct:446969 #Trained:447501 Training Accuracy:99.8%
Progress:48.5% Speed(reviews/sec):103.6 #Correct:449468 #Trained:450001 Training Accuracy:99.8%
Progress:48.7% Speed(reviews/sec):103.6 #Correct:451965 #Trained:452501 Training Accuracy:99.8%
Progress:49.0% Speed(reviews/sec):103.6 #Correct:454463 #Trained:455001 Training Accuracy:99.8%
Progress:49.3% Speed(reviews/sec):103.6 #Correct:456962 #Trained:457501 Training Accuracy:99.8%
Progress:49.5% Speed(reviews/sec):103.6 #Correct:459462 #Trained:460001 Training Accuracy:99.8%
Progress:49.8% Speed(reviews/sec):103.6 #Correct:461959 #Trained:462501 Training Accuracy:99.8%
Progress:50.1% Speed(reviews/sec):103.7 #Correct:464458 #Trained:465001 Training Accuracy:99.8%
Progress:50.4% Speed(reviews/sec):103.7 #Correct:466956 #Trained:467501 Training Accuracy:99.8%
Progress:50.6% Speed(reviews/sec):103.7 #Correct:469456 #Trained:470001 Training Accuracy:99.8%
Progress:50.9% Speed(reviews/sec):103.8 #Correct:471953 #Trained:472501 Training Accuracy:99.8%
Progress:51.2% Speed(reviews/sec):103.8 #Correct:474450 #Trained:475001 Training Accuracy:99.8%
Progress:51.4% Speed(reviews/sec):103.8 #Correct:476939 #Trained:477501 Training Accuracy:99.8%
Progress:51.7% Speed(reviews/sec):103.8 #Correct:479437 #Trained:480001 Training Accuracy:99.8%
Progress:52.0% Speed(reviews/sec):103.8 #Correct:481932 #Trained:482501 Training Accuracy:99.8%
Progress:52.2% Speed(reviews/sec):103.8 #Correct:484430 #Trained:485001 Training Accuracy:99.8%
Progress:52.5% Speed(reviews/sec):103.8 #Correct:486926 #Trained:487501 Training Accuracy:99.8%
Progress:52.8% Speed(reviews/sec):103.7 #Correct:489421 #Trained:490001 Training Accuracy:99.8%
Progress:53.1% Speed(reviews/sec):103.8 #Correct:491919 #Trained:492501 Training Accuracy:99.8%
Progress:53.3% Speed(reviews/sec):103.7 #Correct:494414 #Trained:495001 Training Accuracy:99.8%
Progress:53.6% Speed(reviews/sec):103.7 #Correct:496911 #Trained:497501 Training Accuracy:99.8%
Progress:53.9% Speed(reviews/sec):103.6 #Correct:499406 #Trained:500001 Training Accuracy:99.8%
Progress:54.1% Speed(reviews/sec):103.6 #Correct:501904 #Trained:502501 Training Accuracy:99.8%
Progress:54.4% Speed(reviews/sec):103.6 #Correct:504404 #Trained:505001 Training Accuracy:99.8%
Progress:54.7% Speed(reviews/sec):103.5 #Correct:506903 #Trained:507501 Training Accuracy:99.8%
Progress:54.9% Speed(reviews/sec):103.5 #Correct:509401 #Trained:510001 Training Accuracy:99.8%
Progress:55.2% Speed(reviews/sec):103.5 #Correct:511899 #Trained:512501 Training Accuracy:99.8%
Progress:55.5% Speed(reviews/sec):103.5 #Correct:514389 #Trained:515001 Training Accuracy:99.8%
Progress:55.7% Speed(reviews/sec):103.5 #Correct:515897 #Trained:517501 Training Accuracy:99.6%
Progress:56.0% Speed(reviews/sec):103.5 #Correct:518354 #Trained:520001 Training Accuracy:99.6%
Progress:56.3% Speed(reviews/sec):103.4 #Correct:520787 #Trained:522501 Training Accuracy:99.6%
Progress:56.6% Speed(reviews/sec):103.4 #Correct:523234 #Trained:525001 Training Accuracy:99.6%
Progress:56.8% Speed(reviews/sec):103.4 #Correct:525648 #Trained:527501 Training Accuracy:99.6%
Progress:57.1% Speed(reviews/sec):103.4 #Correct:528072 #Trained:530001 Training Accuracy:99.6%
Progress:57.4% Speed(reviews/sec):103.3 #Correct:530395 #Trained:532501 Training Accuracy:99.6%
Progress:57.6% Speed(reviews/sec):103.3 #Correct:532808 #Trained:535001 Training Accuracy:99.5%
Progress:57.9% Speed(reviews/sec):103.3 #Correct:535195 #Trained:537501 Training Accuracy:99.5%
Progress:58.2% Speed(reviews/sec):103.1 #Correct:537596 #Trained:540001 Training Accuracy:99.5%
Progress:58.4% Speed(reviews/sec):103.1 #Correct:540017 #Trained:542501 Training Accuracy:99.5%
Progress:58.7% Speed(reviews/sec):103.1 #Correct:542411 #Trained:545001 Training Accuracy:99.5%
Progress:59.0% Speed(reviews/sec):103.1 #Correct:544809 #Trained:547501 Training Accuracy:99.5%
Progress:59.3% Speed(reviews/sec):103.1 #Correct:547236 #Trained:550001 Training Accuracy:99.4%
Progress:59.5% Speed(reviews/sec):103.1 #Correct:549666 #Trained:552501 Training Accuracy:99.4%
Progress:59.8% Speed(reviews/sec):103.1 #Correct:552090 #Trained:555001 Training Accuracy:99.4%
Progress:60.1% Speed(reviews/sec):103.1 #Correct:554510 #Trained:557501 Training Accuracy:99.4%
Progress:60.3% Speed(reviews/sec):103.0 #Correct:556941 #Trained:560001 Training Accuracy:99.4%
Progress:60.6% Speed(reviews/sec):102.9 #Correct:559330 #Trained:562501 Training Accuracy:99.4%
Progress:60.9% Speed(reviews/sec):102.9 #Correct:561744 #Trained:565001 Training Accuracy:99.4%
Progress:61.1% Speed(reviews/sec):102.9 #Correct:564168 #Trained:567501 Training Accuracy:99.4%
Progress:61.4% Speed(reviews/sec):102.9 #Correct:566549 #Trained:570001 Training Accuracy:99.3%
Progress:61.7% Speed(reviews/sec):102.9 #Correct:568962 #Trained:572501 Training Accuracy:99.3%
Progress:61.9% Speed(reviews/sec):102.9 #Correct:571355 #Trained:575001 Training Accuracy:99.3%
Progress:62.2% Speed(reviews/sec):102.9 #Correct:573749 #Trained:577501 Training Accuracy:99.3%
Progress:62.5% Speed(reviews/sec):102.9 #Correct:576177 #Trained:580001 Training Accuracy:99.3%
Progress:62.8% Speed(reviews/sec):102.9 #Correct:578639 #Trained:582501 Training Accuracy:99.3%
Progress:63.0% Speed(reviews/sec):102.8 #Correct:581072 #Trained:585001 Training Accuracy:99.3%
Progress:63.3% Speed(reviews/sec):102.8 #Correct:583487 #Trained:587501 Training Accuracy:99.3%
Progress:63.6% Speed(reviews/sec):102.8 #Correct:585907 #Trained:590001 Training Accuracy:99.3%
Progress:63.8% Speed(reviews/sec):102.8 #Correct:588307 #Trained:592501 Training Accuracy:99.2%
Progress:64.1% Speed(reviews/sec):102.8 #Correct:590729 #Trained:595001 Training Accuracy:99.2%
Progress:64.4% Speed(reviews/sec):102.7 #Correct:593164 #Trained:597501 Training Accuracy:99.2%
Progress:64.6% Speed(reviews/sec):102.7 #Correct:595564 #Trained:600001 Training Accuracy:99.2%
Progress:64.9% Speed(reviews/sec):102.7 #Correct:597957 #Trained:602501 Training Accuracy:99.2%
Progress:65.2% Speed(reviews/sec):102.7 #Correct:600369 #Trained:605001 Training Accuracy:99.2%
Progress:65.5% Speed(reviews/sec):102.6 #Correct:602798 #Trained:607501 Training Accuracy:99.2%
Progress:65.7% Speed(reviews/sec):102.6 #Correct:605181 #Trained:610001 Training Accuracy:99.2%
Progress:66.0% Speed(reviews/sec):102.6 #Correct:607578 #Trained:612501 Training Accuracy:99.1%
Progress:66.3% Speed(reviews/sec):102.6 #Correct:609994 #Trained:615001 Training Accuracy:99.1%
Progress:66.5% Speed(reviews/sec):102.6 #Correct:612412 #Trained:617501 Training Accuracy:99.1%
Progress:66.8% Speed(reviews/sec):102.5 #Correct:614866 #Trained:620001 Training Accuracy:99.1%
Progress:67.1% Speed(reviews/sec):102.5 #Correct:617293 #Trained:622501 Training Accuracy:99.1%
Progress:67.3% Speed(reviews/sec):102.5 #Correct:619658 #Trained:625001 Training Accuracy:99.1%
Progress:67.6% Speed(reviews/sec):102.5 #Correct:622069 #Trained:627501 Training Accuracy:99.1%
Progress:67.9% Speed(reviews/sec):102.5 #Correct:624503 #Trained:630001 Training Accuracy:99.1%
Progress:68.1% Speed(reviews/sec):102.5 #Correct:626948 #Trained:632501 Training Accuracy:99.1%
Progress:68.4% Speed(reviews/sec):102.5 #Correct:629354 #Trained:635001 Training Accuracy:99.1%
Progress:68.7% Speed(reviews/sec):102.5 #Correct:631767 #Trained:637501 Training Accuracy:99.1%
Progress:69.0% Speed(reviews/sec):102.5 #Correct:634175 #Trained:640001 Training Accuracy:99.0%
Progress:69.2% Speed(reviews/sec):102.5 #Correct:636622 #Trained:642501 Training Accuracy:99.0%
Progress:69.5% Speed(reviews/sec):102.5 #Correct:639050 #Trained:645001 Training Accuracy:99.0%
Progress:69.8% Speed(reviews/sec):102.5 #Correct:641507 #Trained:647501 Training Accuracy:99.0%
Progress:70.0% Speed(reviews/sec):102.4 #Correct:643938 #Trained:650001 Training Accuracy:99.0%
Progress:70.3% Speed(reviews/sec):102.4 #Correct:646351 #Trained:652501 Training Accuracy:99.0%
Progress:70.6% Speed(reviews/sec):102.4 #Correct:648759 #Trained:655001 Training Accuracy:99.0%
Progress:70.8% Speed(reviews/sec):102.4 #Correct:651185 #Trained:657501 Training Accuracy:99.0%
Progress:71.1% Speed(reviews/sec):102.4 #Correct:653600 #Trained:660001 Training Accuracy:99.0%
Progress:71.4% Speed(reviews/sec):102.4 #Correct:655989 #Trained:662501 Training Accuracy:99.0%
Progress:71.7% Speed(reviews/sec):102.4 #Correct:658385 #Trained:665001 Training Accuracy:99.0%
Progress:71.9% Speed(reviews/sec):102.4 #Correct:660773 #Trained:667501 Training Accuracy:98.9%
Progress:72.2% Speed(reviews/sec):102.3 #Correct:663200 #Trained:670001 Training Accuracy:98.9%
Progress:72.5% Speed(reviews/sec):102.3 #Correct:665640 #Trained:672501 Training Accuracy:98.9%
Progress:72.7% Speed(reviews/sec):102.3 #Correct:668062 #Trained:675001 Training Accuracy:98.9%
Progress:73.0% Speed(reviews/sec):102.3 #Correct:670472 #Trained:677501 Training Accuracy:98.9%
Progress:73.3% Speed(reviews/sec):102.3 #Correct:672912 #Trained:680001 Training Accuracy:98.9%
Progress:73.5% Speed(reviews/sec):102.3 #Correct:675352 #Trained:682501 Training Accuracy:98.9%
Progress:73.8% Speed(reviews/sec):102.2 #Correct:677780 #Trained:685001 Training Accuracy:98.9%
Progress:74.1% Speed(reviews/sec):102.2 #Correct:680187 #Trained:687501 Training Accuracy:98.9%
Progress:74.3% Speed(reviews/sec):102.2 #Correct:682595 #Trained:690001 Training Accuracy:98.9%
Progress:74.6% Speed(reviews/sec):102.2 #Correct:685000 #Trained:692501 Training Accuracy:98.9%
Progress:74.9% Speed(reviews/sec):102.2 #Correct:687398 #Trained:695001 Training Accuracy:98.9%
Progress:75.2% Speed(reviews/sec):102.2 #Correct:689804 #Trained:697501 Training Accuracy:98.8%
Progress:75.4% Speed(reviews/sec):102.2 #Correct:692205 #Trained:700001 Training Accuracy:98.8%
Progress:75.7% Speed(reviews/sec):102.2 #Correct:694636 #Trained:702501 Training Accuracy:98.8%
Progress:76.0% Speed(reviews/sec):102.2 #Correct:697036 #Trained:705001 Training Accuracy:98.8%
Progress:76.2% Speed(reviews/sec):102.2 #Correct:699449 #Trained:707501 Training Accuracy:98.8%
Progress:76.5% Speed(reviews/sec):102.3 #Correct:701862 #Trained:710001 Training Accuracy:98.8%
Progress:76.8% Speed(reviews/sec):102.3 #Correct:704289 #Trained:712501 Training Accuracy:98.8%
Progress:77.0% Speed(reviews/sec):102.3 #Correct:706682 #Trained:715001 Training Accuracy:98.8%
Progress:77.3% Speed(reviews/sec):102.3 #Correct:709064 #Trained:717501 Training Accuracy:98.8%
Progress:77.6% Speed(reviews/sec):102.3 #Correct:711475 #Trained:720001 Training Accuracy:98.8%
Progress:77.9% Speed(reviews/sec):102.3 #Correct:713914 #Trained:722501 Training Accuracy:98.8%
Progress:78.1% Speed(reviews/sec):102.3 #Correct:716340 #Trained:725001 Training Accuracy:98.8%
Progress:78.4% Speed(reviews/sec):102.3 #Correct:718745 #Trained:727501 Training Accuracy:98.7%
Progress:78.7% Speed(reviews/sec):102.3 #Correct:721199 #Trained:730001 Training Accuracy:98.7%
Progress:78.9% Speed(reviews/sec):102.3 #Correct:723624 #Trained:732501 Training Accuracy:98.7%
Progress:79.2% Speed(reviews/sec):102.3 #Correct:726035 #Trained:735001 Training Accuracy:98.7%
Progress:79.5% Speed(reviews/sec):102.3 #Correct:728447 #Trained:737501 Training Accuracy:98.7%
Progress:79.7% Speed(reviews/sec):102.3 #Correct:730824 #Trained:740001 Training Accuracy:98.7%
Progress:80.0% Speed(reviews/sec):102.3 #Correct:733256 #Trained:742501 Training Accuracy:98.7%
Progress:80.3% Speed(reviews/sec):102.4 #Correct:735657 #Trained:745001 Training Accuracy:98.7%
Progress:80.5% Speed(reviews/sec):102.4 #Correct:738097 #Trained:747501 Training Accuracy:98.7%
Progress:80.8% Speed(reviews/sec):102.4 #Correct:740531 #Trained:750001 Training Accuracy:98.7%
Progress:81.1% Speed(reviews/sec):102.4 #Correct:742962 #Trained:752501 Training Accuracy:98.7%
Progress:81.4% Speed(reviews/sec):102.4 #Correct:745361 #Trained:755001 Training Accuracy:98.7%
Progress:81.6% Speed(reviews/sec):102.4 #Correct:747785 #Trained:757501 Training Accuracy:98.7%
Progress:81.9% Speed(reviews/sec):102.3 #Correct:750229 #Trained:760001 Training Accuracy:98.7%
Progress:82.2% Speed(reviews/sec):102.3 #Correct:752660 #Trained:762501 Training Accuracy:98.7%
Progress:82.4% Speed(reviews/sec):102.4 #Correct:755065 #Trained:765001 Training Accuracy:98.7%
Progress:82.7% Speed(reviews/sec):102.3 #Correct:757490 #Trained:767501 Training Accuracy:98.6%
Progress:83.0% Speed(reviews/sec):102.3 #Correct:759905 #Trained:770001 Training Accuracy:98.6%
Progress:83.2% Speed(reviews/sec):102.3 #Correct:762343 #Trained:772501 Training Accuracy:98.6%
Progress:83.5% Speed(reviews/sec):102.3 #Correct:764744 #Trained:775001 Training Accuracy:98.6%
Progress:83.8% Speed(reviews/sec):102.3 #Correct:767173 #Trained:777501 Training Accuracy:98.6%
Progress:84.1% Speed(reviews/sec):102.3 #Correct:769599 #Trained:780001 Training Accuracy:98.6%
Progress:84.3% Speed(reviews/sec):102.3 #Correct:772032 #Trained:782501 Training Accuracy:98.6%
Progress:84.6% Speed(reviews/sec):102.3 #Correct:774455 #Trained:785001 Training Accuracy:98.6%
Progress:84.9% Speed(reviews/sec):102.3 #Correct:776881 #Trained:787501 Training Accuracy:98.6%
Progress:85.1% Speed(reviews/sec):102.2 #Correct:779299 #Trained:790001 Training Accuracy:98.6%
Progress:85.4% Speed(reviews/sec):102.2 #Correct:781736 #Trained:792501 Training Accuracy:98.6%
Progress:85.7% Speed(reviews/sec):102.2 #Correct:784162 #Trained:795001 Training Accuracy:98.6%
Progress:85.9% Speed(reviews/sec):102.2 #Correct:786585 #Trained:797501 Training Accuracy:98.6%
Progress:86.2% Speed(reviews/sec):102.2 #Correct:788994 #Trained:800001 Training Accuracy:98.6%
Progress:86.5% Speed(reviews/sec):102.2 #Correct:791391 #Trained:802501 Training Accuracy:98.6%
Progress:86.7% Speed(reviews/sec):102.2 #Correct:793811 #Trained:805001 Training Accuracy:98.6%
Progress:87.0% Speed(reviews/sec):102.2 #Correct:796159 #Trained:807501 Training Accuracy:98.5%
Progress:87.3% Speed(reviews/sec):102.2 #Correct:798579 #Trained:810001 Training Accuracy:98.5%
Progress:87.6% Speed(reviews/sec):102.2 #Correct:800999 #Trained:812501 Training Accuracy:98.5%
Progress:87.8% Speed(reviews/sec):102.1 #Correct:803381 #Trained:815001 Training Accuracy:98.5%
Progress:88.1% Speed(reviews/sec):102.1 #Correct:805794 #Trained:817501 Training Accuracy:98.5%
Progress:88.4% Speed(reviews/sec):102.1 #Correct:808226 #Trained:820001 Training Accuracy:98.5%
Progress:88.6% Speed(reviews/sec):102.1 #Correct:810649 #Trained:822501 Training Accuracy:98.5%
Progress:88.9% Speed(reviews/sec):102.1 #Correct:813069 #Trained:825001 Training Accuracy:98.5%
Progress:89.2% Speed(reviews/sec):102.1 #Correct:815479 #Trained:827501 Training Accuracy:98.5%
Progress:89.4% Speed(reviews/sec):102.1 #Correct:817908 #Trained:830001 Training Accuracy:98.5%
Progress:89.7% Speed(reviews/sec):102.0 #Correct:820337 #Trained:832501 Training Accuracy:98.5%
Progress:90.0% Speed(reviews/sec):101.9 #Correct:822751 #Trained:835001 Training Accuracy:98.5%
Progress:90.3% Speed(reviews/sec):101.8 #Correct:825148 #Trained:837501 Training Accuracy:98.5%
Progress:90.5% Speed(reviews/sec):101.8 #Correct:827547 #Trained:840001 Training Accuracy:98.5%
Progress:90.8% Speed(reviews/sec):101.8 #Correct:829969 #Trained:842501 Training Accuracy:98.5%
Progress:91.1% Speed(reviews/sec):101.8 #Correct:832396 #Trained:845001 Training Accuracy:98.5%
Progress:91.3% Speed(reviews/sec):101.8 #Correct:834765 #Trained:847501 Training Accuracy:98.4%
Progress:91.6% Speed(reviews/sec):101.8 #Correct:837204 #Trained:850001 Training Accuracy:98.4%
Progress:91.9% Speed(reviews/sec):101.8 #Correct:839646 #Trained:852501 Training Accuracy:98.4%
Progress:92.1% Speed(reviews/sec):101.8 #Correct:842046 #Trained:855001 Training Accuracy:98.4%
Progress:92.4% Speed(reviews/sec):101.8 #Correct:844436 #Trained:857501 Training Accuracy:98.4%
Progress:92.7% Speed(reviews/sec):101.9 #Correct:846902 #Trained:860001 Training Accuracy:98.4%
Progress:92.9% Speed(reviews/sec):101.9 #Correct:849324 #Trained:862501 Training Accuracy:98.4%
Progress:93.2% Speed(reviews/sec):101.9 #Correct:851744 #Trained:865001 Training Accuracy:98.4%
Progress:93.5% Speed(reviews/sec):101.9 #Correct:854165 #Trained:867501 Training Accuracy:98.4%
Progress:93.8% Speed(reviews/sec):101.9 #Correct:856574 #Trained:870001 Training Accuracy:98.4%
Progress:94.0% Speed(reviews/sec):101.9 #Correct:859000 #Trained:872501 Training Accuracy:98.4%
Progress:94.3% Speed(reviews/sec):101.9 #Correct:861435 #Trained:875001 Training Accuracy:98.4%
Progress:94.6% Speed(reviews/sec):101.9 #Correct:863850 #Trained:877501 Training Accuracy:98.4%
Progress:94.8% Speed(reviews/sec):101.9 #Correct:866273 #Trained:880001 Training Accuracy:98.4%
Progress:95.1% Speed(reviews/sec):101.9 #Correct:868698 #Trained:882501 Training Accuracy:98.4%
Progress:95.4% Speed(reviews/sec):102.0 #Correct:871114 #Trained:885001 Training Accuracy:98.4%
Progress:95.6% Speed(reviews/sec):102.0 #Correct:873531 #Trained:887501 Training Accuracy:98.4%
Progress:95.9% Speed(reviews/sec):102.0 #Correct:875948 #Trained:890001 Training Accuracy:98.4%
Progress:96.2% Speed(reviews/sec):102.0 #Correct:878355 #Trained:892501 Training Accuracy:98.4%
Progress:96.5% Speed(reviews/sec):102.0 #Correct:880796 #Trained:895001 Training Accuracy:98.4%
Progress:96.7% Speed(reviews/sec):102.0 #Correct:883187 #Trained:897501 Training Accuracy:98.4%
Progress:97.0% Speed(reviews/sec):102.0 #Correct:885612 #Trained:900001 Training Accuracy:98.4%
Progress:97.3% Speed(reviews/sec):102.0 #Correct:888024 #Trained:902501 Training Accuracy:98.3%
Progress:97.5% Speed(reviews/sec):102.1 #Correct:890431 #Trained:905001 Training Accuracy:98.3%
Progress:97.8% Speed(reviews/sec):102.1 #Correct:892831 #Trained:907501 Training Accuracy:98.3%
Progress:98.1% Speed(reviews/sec):102.1 #Correct:895250 #Trained:910001 Training Accuracy:98.3%
Progress:98.3% Speed(reviews/sec):102.1 #Correct:897631 #Trained:912501 Training Accuracy:98.3%
Progress:98.6% Speed(reviews/sec):102.1 #Correct:900043 #Trained:915001 Training Accuracy:98.3%
Progress:98.9% Speed(reviews/sec):102.1 #Correct:902460 #Trained:917501 Training Accuracy:98.3%
Progress:99.1% Speed(reviews/sec):102.1 #Correct:904853 #Trained:920001 Training Accuracy:98.3%
Progress:99.4% Speed(reviews/sec):102.1 #Correct:907216 #Trained:922501 Training Accuracy:98.3%
Progress:99.7% Speed(reviews/sec):102.2 #Correct:909632 #Trained:925001 Training Accuracy:98.3%
Progress:99.9% Speed(reviews/sec):102.2 #Correct:911969 #Trained:927422 Training Accuracy:98.3%</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[49]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mlp</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">reviews</span><span class="p">[</span><span class="o">-</span><span class="mi">103000</span><span class="p">:],</span><span class="n">labels</span><span class="p">[</span><span class="o">-</span><span class="mi">103000</span><span class="p">:])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Progress:99.9% Speed(reviews/sec):1391. #Correct:99480 #Tested:103000 Testing Accuracy:96.5%</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[50]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">layer_0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[51]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">layer_0</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">layer_0</span><span class="p">[</span><span class="mi">9</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[52]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">weights_0_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[53]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">layer_0</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">weights_0_1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[53]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([-0.10503756,  0.44222989,  0.24392938, -0.55961832,  0.21389503])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[54]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">indices</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">9</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[55]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">layer_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[56]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">:</span>
    <span class="n">layer_1</span> <span class="o">+=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">*</span> <span class="n">weights_0_1</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[57]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">layer_1</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[57]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([-0.10503756,  0.44222989,  0.24392938, -0.55961832,  0.21389503])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[58]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">layer_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[59]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">:</span>
    <span class="n">layer_1</span> <span class="o">+=</span> <span class="p">(</span><span class="n">weights_0_1</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[60]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">layer_1</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[60]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([-0.10503756,  0.44222989,  0.24392938, -0.55961832,  0.21389503])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Making-the-network-more-efficient">Making the network more efficient<a class="anchor-link" href="#Making-the-network-more-efficient">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[61]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Encapsulate our neural network in a class</span>
<span class="k">class</span> <span class="nc">SentimentNetwork</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reviews</span><span class="p">,</span><span class="n">labels</span><span class="p">,</span><span class="n">hidden_nodes</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create a SentimenNetwork with the given settings</span>
<span class="sd">        Args:</span>
<span class="sd">            reviews(list) - List of reviews used for training</span>
<span class="sd">            labels(list) - List of POSITIVE/NEGATIVE labels associated with the given reviews</span>
<span class="sd">            hidden_nodes(int) - Number of nodes to create in the hidden layer</span>
<span class="sd">            learning_rate(float) - Learning rate to use while training</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Assign a seed to our random number generator to ensure we get</span>
        <span class="c1"># reproducable results during development </span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># process the reviews and their associated labels so that everything</span>
        <span class="c1"># is ready for training</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_process_data</span><span class="p">(</span><span class="n">reviews</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        
        <span class="c1"># Build the network to have the number of hidden nodes and the learning rate that</span>
        <span class="c1"># were passed into this initializer. Make the same number of input nodes as</span>
        <span class="c1"># there are vocabulary words and create a single output node.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_network</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">review_vocab</span><span class="p">),</span><span class="n">hidden_nodes</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">pre_process_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reviews</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        
        <span class="c1"># populate review_vocab with all of the words in the given reviews</span>
        <span class="n">review_vocab</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">review</span> <span class="ow">in</span> <span class="n">reviews</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">review</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
                <span class="n">review_vocab</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

        <span class="c1"># Convert the vocabulary set to a list so we can access words via indices</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">review_vocab</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">review_vocab</span><span class="p">)</span>
        
        <span class="c1"># populate label_vocab with all of the words in the given labels.</span>
        <span class="n">label_vocab</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">:</span>
            <span class="n">label_vocab</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
        
        <span class="c1"># Convert the label vocabulary set to a list so we can access labels via indices</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_vocab</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">label_vocab</span><span class="p">)</span>
        
        <span class="c1"># Store the sizes of the review and label vocabularies.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">review_vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">review_vocab</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_vocab</span><span class="p">)</span>
        
        <span class="c1"># Create a dictionary of words in the vocabulary mapped to index positions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">review_vocab</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
        
        <span class="c1"># Create a dictionary of labels mapped to index positions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label2index</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_vocab</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">label2index</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>

    <span class="k">def</span> <span class="nf">init_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_nodes</span><span class="p">,</span> <span class="n">hidden_nodes</span><span class="p">,</span> <span class="n">output_nodes</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
        <span class="c1"># Set number of nodes in input, hidden and output layers.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_nodes</span> <span class="o">=</span> <span class="n">input_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_nodes</span> <span class="o">=</span> <span class="n">hidden_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_nodes</span> <span class="o">=</span> <span class="n">output_nodes</span>

        <span class="c1"># Store the learning rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>

        <span class="c1"># Initialize weights</span>

        <span class="c1"># These are the weights between the input layer and the hidden layer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_0_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">input_nodes</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_nodes</span><span class="p">))</span>

        <span class="c1"># These are the weights between the hidden layer and the output layer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_1_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_nodes</span><span class="o">**-</span><span class="mf">0.5</span><span class="p">,</span> 
                                                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_nodes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_nodes</span><span class="p">))</span>
        
      
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">hidden_nodes</span><span class="p">))</span>
    
 
    
    <span class="k">def</span> <span class="nf">get_target_for_label</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">label</span><span class="p">):</span>
        <span class="k">if</span><span class="p">(</span><span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">return</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
        
    <span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">sigmoid_output_2_derivative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">output</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">output</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">output</span><span class="p">)</span>
    
    
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_reviews_raw</span><span class="p">,</span> <span class="n">training_labels</span><span class="p">):</span>

      
        <span class="n">training_reviews</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">review</span> <span class="ow">in</span> <span class="n">training_reviews_raw</span><span class="p">:</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">review</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
                <span class="k">if</span><span class="p">(</span><span class="n">word</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
                    <span class="n">indices</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">])</span>
            <span class="n">training_reviews</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">indices</span><span class="p">))</span>

        <span class="c1"># make sure out we have a matching number of reviews and labels</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">training_reviews</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">training_labels</span><span class="p">))</span>
        
        <span class="c1"># Keep track of correct predictions to display accuracy during training </span>
        <span class="n">correct_so_far</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Remember when we started for printing time statistics</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        
        <span class="c1"># loop through all the given reviews and run a forward and backward pass,</span>
        <span class="c1"># updating weights for every item</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">training_reviews</span><span class="p">)):</span>
            
            <span class="c1"># Get the next review and its correct label</span>
            <span class="n">review</span> <span class="o">=</span> <span class="n">training_reviews</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">label</span> <span class="o">=</span> <span class="n">training_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            
            <span class="c1">#### Implement the forward pass here ####</span>
            <span class="c1">### Forward pass ###</span>

        <span class="c1"># Removed call to &#39;update_input_layer&#39; function</span>
            <span class="c1">#                     because &#39;layer_0&#39; is no longer used</span>

            <span class="c1"># Hidden layer</span>
            <span class="c1">## Add in only the weights for non-zero items</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layer_1</span> <span class="o">*=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">review</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">layer_1</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_0_1</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

            <span class="c1"># Output layer</span>
            <span class="c1">## : changed to use &#39;self.layer_1&#39; instead of &#39;local layer_1&#39;</span>
            <span class="n">layer_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_1_2</span><span class="p">))</span>            
            
            <span class="c1">#### Implement the backward pass here ####</span>
            <span class="c1">### Backward pass ###</span>

            <span class="c1"># Output error</span>
            <span class="n">layer_2_error</span> <span class="o">=</span> <span class="n">layer_2</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_target_for_label</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="c1"># Output layer error is the difference between desired target and actual output.</span>
            <span class="n">layer_2_delta</span> <span class="o">=</span> <span class="n">layer_2_error</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid_output_2_derivative</span><span class="p">(</span><span class="n">layer_2</span><span class="p">)</span>

            <span class="c1"># Backpropagated error</span>
            <span class="n">layer_1_error</span> <span class="o">=</span> <span class="n">layer_2_delta</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_1_2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="c1"># errors propagated to the hidden layer</span>
            <span class="n">layer_1_delta</span> <span class="o">=</span> <span class="n">layer_1_error</span> <span class="c1"># hidden layer gradients - no nonlinearity so it&#39;s the same as the error</span>

            <span class="c1"># Update the weights</span>
            <span class="c1">##  changed to use &#39;self.layer_1&#39; instead of local &#39;layer_1&#39;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights_1_2</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_1</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">layer_2_delta</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="c1"># update hidden-to-output weights with gradient descent step</span>
            
            <span class="c1">## New for Only update the weights that were used in the forward pass</span>
            <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">review</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">weights_0_1</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">-=</span> <span class="n">layer_1_delta</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="c1"># update input-to-hidden weights with gradient descent step</span>

            <span class="c1"># Keep track of correct predictions.</span>
            <span class="k">if</span><span class="p">(</span><span class="n">layer_2</span> <span class="o">&gt;=</span> <span class="mf">0.5</span> <span class="ow">and</span> <span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
                <span class="n">correct_so_far</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">elif</span><span class="p">(</span><span class="n">layer_2</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">and</span> <span class="n">label</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                <span class="n">correct_so_far</span> <span class="o">+=</span> <span class="mi">1</span>
            
            <span class="c1"># For debug purposes, print out our prediction accuracy and speed </span>
            <span class="c1"># throughout the training process. </span>
            <span class="n">elapsed_time</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>
            <span class="n">reviews_per_second</span> <span class="o">=</span> <span class="n">i</span> <span class="o">/</span> <span class="n">elapsed_time</span> <span class="k">if</span> <span class="n">elapsed_time</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
            
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">Progress:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">i</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">training_reviews</span><span class="p">)))[:</span><span class="mi">4</span><span class="p">]</span> \
                             <span class="o">+</span> <span class="s2">&quot;% Speed(reviews/sec):&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">reviews_per_second</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span> \
                             <span class="o">+</span> <span class="s2">&quot; #Correct:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">correct_so_far</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; #Trained:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> \
                             <span class="o">+</span> <span class="s2">&quot; Training Accuracy:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">correct_so_far</span> <span class="o">*</span> <span class="mi">100</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))[:</span><span class="mi">4</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;%&quot;</span><span class="p">)</span>
            <span class="k">if</span><span class="p">(</span><span class="n">i</span> <span class="o">%</span> <span class="mi">2500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">testing_reviews</span><span class="p">,</span> <span class="n">testing_labels</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Attempts to predict the labels for the given testing_reviews,</span>
<span class="sd">        and uses the test_labels to calculate the accuracy of those predictions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="c1"># keep track of how many correct predictions we make</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># we&#39;ll time how many predictions per second we make</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="c1"># Loop through each of the given reviews and call run to predict</span>
        <span class="c1"># its label. </span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">testing_reviews</span><span class="p">)):</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">testing_reviews</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="k">if</span><span class="p">(</span><span class="n">pred</span> <span class="o">==</span> <span class="n">testing_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span>
                <span class="n">correct</span> <span class="o">+=</span> <span class="mi">1</span>
            
            <span class="c1"># For debug purposes, print out our prediction accuracy and speed </span>
            <span class="c1"># throughout the prediction process. </span>

            <span class="n">elapsed_time</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>
            <span class="n">reviews_per_second</span> <span class="o">=</span> <span class="n">i</span> <span class="o">/</span> <span class="n">elapsed_time</span> <span class="k">if</span> <span class="n">elapsed_time</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
            
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">Progress:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">i</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">testing_reviews</span><span class="p">)))[:</span><span class="mi">4</span><span class="p">]</span> \
                             <span class="o">+</span> <span class="s2">&quot;% Speed(reviews/sec):&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">reviews_per_second</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span> \
                             <span class="o">+</span> <span class="s2">&quot; #Correct:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">correct</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; #Tested:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> \
                             <span class="o">+</span> <span class="s2">&quot; Testing Accuracy:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">correct</span> <span class="o">*</span> <span class="mi">100</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))[:</span><span class="mi">4</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;%&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">review</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a POSITIVE or NEGATIVE prediction for the given review.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Run a forward pass through the network, like in the &quot;train&quot; function.</span>
        
        <span class="c1">##Removed call to update_input_layer function</span>
        <span class="c1">#                     because layer_0 is no longer used</span>

        <span class="c1"># Hidden layer</span>
        <span class="c1">## Identify the indices used in the review and then add</span>
        <span class="c1">#                     just those weights to layer_1 </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_1</span> <span class="o">*=</span> <span class="mi">0</span>
        <span class="n">unique_indices</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">review</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">unique_indices</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">unique_indices</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layer_1</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_0_1</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        
        <span class="c1"># Output layer</span>
        <span class="c1">## changed to use self.layer_1 instead of local layer_1</span>
        <span class="n">layer_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_1_2</span><span class="p">))</span>
        
        <span class="c1"># Return POSITIVE for values above greater-than-or-equal-to 0.5 in the output layer;</span>
        <span class="c1"># return NEGATIVE for other values</span>
        <span class="k">if</span><span class="p">(</span><span class="n">layer_2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">):</span>
            <span class="k">return</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[62]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mlp</span> <span class="o">=</span> <span class="n">SentimentNetwork</span><span class="p">(</span><span class="n">reviews</span><span class="p">[:</span><span class="o">-</span><span class="mi">103000</span><span class="p">],</span><span class="n">labels</span><span class="p">[:</span><span class="o">-</span><span class="mi">103000</span><span class="p">],</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">mlp</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">reviews</span><span class="p">[:</span><span class="o">-</span><span class="mi">103000</span><span class="p">],</span><span class="n">labels</span><span class="p">[:</span><span class="o">-</span><span class="mi">103000</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Progress:0.0% Speed(reviews/sec):0 #Correct:1 #Trained:1 Training Accuracy:100.%
Progress:0.26% Speed(reviews/sec):5402. #Correct:2497 #Trained:2501 Training Accuracy:99.8%
Progress:0.53% Speed(reviews/sec):5601. #Correct:4980 #Trained:5001 Training Accuracy:99.5%
Progress:0.80% Speed(reviews/sec):5497. #Correct:7478 #Trained:7501 Training Accuracy:99.6%
Progress:1.07% Speed(reviews/sec):5491. #Correct:9969 #Trained:10001 Training Accuracy:99.6%
Progress:1.34% Speed(reviews/sec):5506. #Correct:12460 #Trained:12501 Training Accuracy:99.6%
Progress:1.61% Speed(reviews/sec):5547. #Correct:14957 #Trained:15001 Training Accuracy:99.7%
Progress:1.88% Speed(reviews/sec):5495. #Correct:17455 #Trained:17501 Training Accuracy:99.7%
Progress:2.15% Speed(reviews/sec):5542. #Correct:19953 #Trained:20001 Training Accuracy:99.7%
Progress:2.42% Speed(reviews/sec):5491. #Correct:22451 #Trained:22501 Training Accuracy:99.7%
Progress:2.69% Speed(reviews/sec):5411. #Correct:24950 #Trained:25001 Training Accuracy:99.7%
Progress:2.96% Speed(reviews/sec):5395. #Correct:27444 #Trained:27501 Training Accuracy:99.7%
Progress:3.23% Speed(reviews/sec):5406. #Correct:29941 #Trained:30001 Training Accuracy:99.8%
Progress:3.50% Speed(reviews/sec):5392. #Correct:32438 #Trained:32501 Training Accuracy:99.8%
Progress:3.77% Speed(reviews/sec):5413. #Correct:34938 #Trained:35001 Training Accuracy:99.8%
Progress:4.04% Speed(reviews/sec):5321. #Correct:37433 #Trained:37501 Training Accuracy:99.8%
Progress:4.31% Speed(reviews/sec):5277. #Correct:39931 #Trained:40001 Training Accuracy:99.8%
Progress:4.58% Speed(reviews/sec):5232. #Correct:42428 #Trained:42501 Training Accuracy:99.8%
Progress:4.85% Speed(reviews/sec):5192. #Correct:44921 #Trained:45001 Training Accuracy:99.8%
Progress:5.12% Speed(reviews/sec):5174. #Correct:47420 #Trained:47501 Training Accuracy:99.8%
Progress:5.39% Speed(reviews/sec):5149. #Correct:49918 #Trained:50001 Training Accuracy:99.8%
Progress:5.66% Speed(reviews/sec):5182. #Correct:52416 #Trained:52501 Training Accuracy:99.8%
Progress:5.93% Speed(reviews/sec):5163. #Correct:54913 #Trained:55001 Training Accuracy:99.8%
Progress:6.19% Speed(reviews/sec):5181. #Correct:57410 #Trained:57501 Training Accuracy:99.8%
Progress:6.46% Speed(reviews/sec):5153. #Correct:59905 #Trained:60001 Training Accuracy:99.8%
Progress:6.73% Speed(reviews/sec):5151. #Correct:62401 #Trained:62501 Training Accuracy:99.8%
Progress:7.00% Speed(reviews/sec):5143. #Correct:64893 #Trained:65001 Training Accuracy:99.8%
Progress:7.27% Speed(reviews/sec):5198. #Correct:67374 #Trained:67501 Training Accuracy:99.8%
Progress:7.54% Speed(reviews/sec):5214. #Correct:69862 #Trained:70001 Training Accuracy:99.8%
Progress:7.81% Speed(reviews/sec):5229. #Correct:72358 #Trained:72501 Training Accuracy:99.8%
Progress:8.08% Speed(reviews/sec):5213. #Correct:74857 #Trained:75001 Training Accuracy:99.8%
Progress:8.35% Speed(reviews/sec):5238. #Correct:77355 #Trained:77501 Training Accuracy:99.8%
Progress:8.62% Speed(reviews/sec):5216. #Correct:79853 #Trained:80001 Training Accuracy:99.8%
Progress:8.89% Speed(reviews/sec):5229. #Correct:82348 #Trained:82501 Training Accuracy:99.8%
Progress:9.16% Speed(reviews/sec):5194. #Correct:84848 #Trained:85001 Training Accuracy:99.8%
Progress:9.43% Speed(reviews/sec):5201. #Correct:87346 #Trained:87501 Training Accuracy:99.8%
Progress:9.70% Speed(reviews/sec):5186. #Correct:89846 #Trained:90001 Training Accuracy:99.8%
Progress:9.97% Speed(reviews/sec):5200. #Correct:92342 #Trained:92501 Training Accuracy:99.8%
Progress:10.2% Speed(reviews/sec):5152. #Correct:94841 #Trained:95001 Training Accuracy:99.8%
Progress:10.5% Speed(reviews/sec):5162. #Correct:97339 #Trained:97501 Training Accuracy:99.8%
Progress:10.7% Speed(reviews/sec):5143. #Correct:99838 #Trained:100001 Training Accuracy:99.8%
Progress:11.0% Speed(reviews/sec):5149. #Correct:102334 #Trained:102501 Training Accuracy:99.8%
Progress:11.3% Speed(reviews/sec):5139. #Correct:104829 #Trained:105001 Training Accuracy:99.8%
Progress:11.5% Speed(reviews/sec):5141. #Correct:107327 #Trained:107501 Training Accuracy:99.8%
Progress:11.8% Speed(reviews/sec):5137. #Correct:109822 #Trained:110001 Training Accuracy:99.8%
Progress:12.1% Speed(reviews/sec):5144. #Correct:112317 #Trained:112501 Training Accuracy:99.8%
Progress:12.3% Speed(reviews/sec):5153. #Correct:114810 #Trained:115001 Training Accuracy:99.8%
Progress:12.6% Speed(reviews/sec):5156. #Correct:117303 #Trained:117501 Training Accuracy:99.8%
Progress:12.9% Speed(reviews/sec):5141. #Correct:119801 #Trained:120001 Training Accuracy:99.8%
Progress:13.2% Speed(reviews/sec):5151. #Correct:122299 #Trained:122501 Training Accuracy:99.8%
Progress:13.4% Speed(reviews/sec):5148. #Correct:124793 #Trained:125001 Training Accuracy:99.8%
Progress:13.7% Speed(reviews/sec):5148. #Correct:127292 #Trained:127501 Training Accuracy:99.8%
Progress:14.0% Speed(reviews/sec):5143. #Correct:129790 #Trained:130001 Training Accuracy:99.8%
Progress:14.2% Speed(reviews/sec):5149. #Correct:132286 #Trained:132501 Training Accuracy:99.8%
Progress:14.5% Speed(reviews/sec):5136. #Correct:134785 #Trained:135001 Training Accuracy:99.8%
Progress:14.8% Speed(reviews/sec):5149. #Correct:137277 #Trained:137501 Training Accuracy:99.8%
Progress:15.0% Speed(reviews/sec):5137. #Correct:139776 #Trained:140001 Training Accuracy:99.8%
Progress:15.3% Speed(reviews/sec):5142. #Correct:142272 #Trained:142501 Training Accuracy:99.8%
Progress:15.6% Speed(reviews/sec):5137. #Correct:144771 #Trained:145001 Training Accuracy:99.8%
Progress:15.9% Speed(reviews/sec):5146. #Correct:147270 #Trained:147501 Training Accuracy:99.8%
Progress:16.1% Speed(reviews/sec):5135. #Correct:149769 #Trained:150001 Training Accuracy:99.8%
Progress:16.4% Speed(reviews/sec):5147. #Correct:152268 #Trained:152501 Training Accuracy:99.8%
Progress:16.7% Speed(reviews/sec):5135. #Correct:154767 #Trained:155001 Training Accuracy:99.8%
Progress:16.9% Speed(reviews/sec):5139. #Correct:157265 #Trained:157501 Training Accuracy:99.8%
Progress:17.2% Speed(reviews/sec):5138. #Correct:159759 #Trained:160001 Training Accuracy:99.8%
Progress:17.5% Speed(reviews/sec):5140. #Correct:162256 #Trained:162501 Training Accuracy:99.8%
Progress:17.7% Speed(reviews/sec):5132. #Correct:164751 #Trained:165001 Training Accuracy:99.8%
Progress:18.0% Speed(reviews/sec):5144. #Correct:167250 #Trained:167501 Training Accuracy:99.8%
Progress:18.3% Speed(reviews/sec):5143. #Correct:169748 #Trained:170001 Training Accuracy:99.8%
Progress:18.5% Speed(reviews/sec):5143. #Correct:172244 #Trained:172501 Training Accuracy:99.8%
Progress:18.8% Speed(reviews/sec):5129. #Correct:174742 #Trained:175001 Training Accuracy:99.8%
Progress:19.1% Speed(reviews/sec):5126. #Correct:177237 #Trained:177501 Training Accuracy:99.8%
Progress:19.4% Speed(reviews/sec):5111. #Correct:179736 #Trained:180001 Training Accuracy:99.8%
Progress:19.6% Speed(reviews/sec):5117. #Correct:182236 #Trained:182501 Training Accuracy:99.8%
Progress:19.9% Speed(reviews/sec):5111. #Correct:184733 #Trained:185001 Training Accuracy:99.8%
Progress:20.2% Speed(reviews/sec):5112. #Correct:187228 #Trained:187501 Training Accuracy:99.8%
Progress:20.4% Speed(reviews/sec):5099. #Correct:189727 #Trained:190001 Training Accuracy:99.8%
Progress:20.7% Speed(reviews/sec):5107. #Correct:192220 #Trained:192501 Training Accuracy:99.8%
Progress:21.0% Speed(reviews/sec):5104. #Correct:194719 #Trained:195001 Training Accuracy:99.8%
Progress:21.2% Speed(reviews/sec):5106. #Correct:197219 #Trained:197501 Training Accuracy:99.8%
Progress:21.5% Speed(reviews/sec):5099. #Correct:199717 #Trained:200001 Training Accuracy:99.8%
Progress:21.8% Speed(reviews/sec):5106. #Correct:202208 #Trained:202501 Training Accuracy:99.8%
Progress:22.1% Speed(reviews/sec):5094. #Correct:204699 #Trained:205001 Training Accuracy:99.8%
Progress:22.3% Speed(reviews/sec):5084. #Correct:207195 #Trained:207501 Training Accuracy:99.8%
Progress:22.6% Speed(reviews/sec):5071. #Correct:209692 #Trained:210001 Training Accuracy:99.8%
Progress:22.9% Speed(reviews/sec):5069. #Correct:212190 #Trained:212501 Training Accuracy:99.8%
Progress:23.1% Speed(reviews/sec):5064. #Correct:214686 #Trained:215001 Training Accuracy:99.8%
Progress:23.4% Speed(reviews/sec):5064. #Correct:217184 #Trained:217501 Training Accuracy:99.8%
Progress:23.7% Speed(reviews/sec):5052. #Correct:219682 #Trained:220001 Training Accuracy:99.8%
Progress:23.9% Speed(reviews/sec):5031. #Correct:222178 #Trained:222501 Training Accuracy:99.8%
Progress:24.2% Speed(reviews/sec):5007. #Correct:224675 #Trained:225001 Training Accuracy:99.8%
Progress:24.5% Speed(reviews/sec):4990. #Correct:227173 #Trained:227501 Training Accuracy:99.8%
Progress:24.7% Speed(reviews/sec):4959. #Correct:229673 #Trained:230001 Training Accuracy:99.8%
Progress:25.0% Speed(reviews/sec):4929. #Correct:232171 #Trained:232501 Training Accuracy:99.8%
Progress:25.3% Speed(reviews/sec):4900. #Correct:234669 #Trained:235001 Training Accuracy:99.8%
Progress:25.6% Speed(reviews/sec):4881. #Correct:237169 #Trained:237501 Training Accuracy:99.8%
Progress:25.8% Speed(reviews/sec):4852. #Correct:239667 #Trained:240001 Training Accuracy:99.8%
Progress:26.1% Speed(reviews/sec):4831. #Correct:242163 #Trained:242501 Training Accuracy:99.8%
Progress:26.4% Speed(reviews/sec):4813. #Correct:244659 #Trained:245001 Training Accuracy:99.8%
Progress:26.6% Speed(reviews/sec):4800. #Correct:247153 #Trained:247501 Training Accuracy:99.8%
Progress:26.9% Speed(reviews/sec):4781. #Correct:249652 #Trained:250001 Training Accuracy:99.8%
Progress:27.2% Speed(reviews/sec):4773. #Correct:252151 #Trained:252501 Training Accuracy:99.8%
Progress:27.4% Speed(reviews/sec):4771. #Correct:254649 #Trained:255001 Training Accuracy:99.8%
Progress:27.7% Speed(reviews/sec):4772. #Correct:257147 #Trained:257501 Training Accuracy:99.8%
Progress:28.0% Speed(reviews/sec):4757. #Correct:259644 #Trained:260001 Training Accuracy:99.8%
Progress:28.3% Speed(reviews/sec):4743. #Correct:262144 #Trained:262501 Training Accuracy:99.8%
Progress:28.5% Speed(reviews/sec):4735. #Correct:264638 #Trained:265001 Training Accuracy:99.8%
Progress:28.8% Speed(reviews/sec):4740. #Correct:267133 #Trained:267501 Training Accuracy:99.8%
Progress:29.1% Speed(reviews/sec):4723. #Correct:269632 #Trained:270001 Training Accuracy:99.8%
Progress:29.3% Speed(reviews/sec):4721. #Correct:272131 #Trained:272501 Training Accuracy:99.8%
Progress:29.6% Speed(reviews/sec):4716. #Correct:274628 #Trained:275001 Training Accuracy:99.8%
Progress:29.9% Speed(reviews/sec):4711. #Correct:277126 #Trained:277501 Training Accuracy:99.8%
Progress:30.1% Speed(reviews/sec):4697. #Correct:279624 #Trained:280001 Training Accuracy:99.8%
Progress:30.4% Speed(reviews/sec):4691. #Correct:282123 #Trained:282501 Training Accuracy:99.8%
Progress:30.7% Speed(reviews/sec):4687. #Correct:284622 #Trained:285001 Training Accuracy:99.8%
Progress:30.9% Speed(reviews/sec):4688. #Correct:287121 #Trained:287501 Training Accuracy:99.8%
Progress:31.2% Speed(reviews/sec):4685. #Correct:289621 #Trained:290001 Training Accuracy:99.8%
Progress:31.5% Speed(reviews/sec):4694. #Correct:292119 #Trained:292501 Training Accuracy:99.8%
Progress:31.8% Speed(reviews/sec):4693. #Correct:294614 #Trained:295001 Training Accuracy:99.8%
Progress:32.0% Speed(reviews/sec):4697. #Correct:297113 #Trained:297501 Training Accuracy:99.8%
Progress:32.3% Speed(reviews/sec):4686. #Correct:299609 #Trained:300001 Training Accuracy:99.8%
Progress:32.6% Speed(reviews/sec):4680. #Correct:302104 #Trained:302501 Training Accuracy:99.8%
Progress:32.8% Speed(reviews/sec):4665. #Correct:304603 #Trained:305001 Training Accuracy:99.8%
Progress:33.1% Speed(reviews/sec):4672. #Correct:307101 #Trained:307501 Training Accuracy:99.8%
Progress:33.4% Speed(reviews/sec):4671. #Correct:309598 #Trained:310001 Training Accuracy:99.8%
Progress:33.6% Speed(reviews/sec):4675. #Correct:312093 #Trained:312501 Training Accuracy:99.8%
Progress:33.9% Speed(reviews/sec):4668. #Correct:314589 #Trained:315001 Training Accuracy:99.8%
Progress:34.2% Speed(reviews/sec):4662. #Correct:317086 #Trained:317501 Training Accuracy:99.8%
Progress:34.5% Speed(reviews/sec):4659. #Correct:319584 #Trained:320001 Training Accuracy:99.8%
Progress:34.7% Speed(reviews/sec):4666. #Correct:322082 #Trained:322501 Training Accuracy:99.8%
Progress:35.0% Speed(reviews/sec):4658. #Correct:324577 #Trained:325001 Training Accuracy:99.8%
Progress:35.3% Speed(reviews/sec):4658. #Correct:327075 #Trained:327501 Training Accuracy:99.8%
Progress:35.5% Speed(reviews/sec):4649. #Correct:329571 #Trained:330001 Training Accuracy:99.8%
Progress:35.8% Speed(reviews/sec):4646. #Correct:332068 #Trained:332501 Training Accuracy:99.8%
Progress:36.1% Speed(reviews/sec):4646. #Correct:334564 #Trained:335001 Training Accuracy:99.8%
Progress:36.3% Speed(reviews/sec):4645. #Correct:337060 #Trained:337501 Training Accuracy:99.8%
Progress:36.6% Speed(reviews/sec):4636. #Correct:339560 #Trained:340001 Training Accuracy:99.8%
Progress:36.9% Speed(reviews/sec):4629. #Correct:342059 #Trained:342501 Training Accuracy:99.8%
Progress:37.1% Speed(reviews/sec):4633. #Correct:344553 #Trained:345001 Training Accuracy:99.8%
Progress:37.4% Speed(reviews/sec):4630. #Correct:347051 #Trained:347501 Training Accuracy:99.8%
Progress:37.7% Speed(reviews/sec):4634. #Correct:349548 #Trained:350001 Training Accuracy:99.8%
Progress:38.0% Speed(reviews/sec):4627. #Correct:352045 #Trained:352501 Training Accuracy:99.8%
Progress:38.2% Speed(reviews/sec):4625. #Correct:354541 #Trained:355001 Training Accuracy:99.8%
Progress:38.5% Speed(reviews/sec):4613. #Correct:357040 #Trained:357501 Training Accuracy:99.8%
Progress:38.8% Speed(reviews/sec):4606. #Correct:359539 #Trained:360001 Training Accuracy:99.8%
Progress:39.0% Speed(reviews/sec):4607. #Correct:362036 #Trained:362501 Training Accuracy:99.8%
Progress:39.3% Speed(reviews/sec):4614. #Correct:364535 #Trained:365001 Training Accuracy:99.8%
Progress:39.6% Speed(reviews/sec):4614. #Correct:367030 #Trained:367501 Training Accuracy:99.8%
Progress:39.8% Speed(reviews/sec):4614. #Correct:369527 #Trained:370001 Training Accuracy:99.8%
Progress:40.1% Speed(reviews/sec):4605. #Correct:372025 #Trained:372501 Training Accuracy:99.8%
Progress:40.4% Speed(reviews/sec):4605. #Correct:374523 #Trained:375001 Training Accuracy:99.8%
Progress:40.7% Speed(reviews/sec):4605. #Correct:377020 #Trained:377501 Training Accuracy:99.8%
Progress:40.9% Speed(reviews/sec):4603. #Correct:379518 #Trained:380001 Training Accuracy:99.8%
Progress:41.2% Speed(reviews/sec):4600. #Correct:382015 #Trained:382501 Training Accuracy:99.8%
Progress:41.5% Speed(reviews/sec):4600. #Correct:384515 #Trained:385001 Training Accuracy:99.8%
Progress:41.7% Speed(reviews/sec):4598. #Correct:387013 #Trained:387501 Training Accuracy:99.8%
Progress:42.0% Speed(reviews/sec):4594. #Correct:389511 #Trained:390001 Training Accuracy:99.8%
Progress:42.3% Speed(reviews/sec):4590. #Correct:392010 #Trained:392501 Training Accuracy:99.8%
Progress:42.5% Speed(reviews/sec):4584. #Correct:394507 #Trained:395001 Training Accuracy:99.8%
Progress:42.8% Speed(reviews/sec):4580. #Correct:397004 #Trained:397501 Training Accuracy:99.8%
Progress:43.1% Speed(reviews/sec):4581. #Correct:399502 #Trained:400001 Training Accuracy:99.8%
Progress:43.3% Speed(reviews/sec):4581. #Correct:402001 #Trained:402501 Training Accuracy:99.8%
Progress:43.6% Speed(reviews/sec):4579. #Correct:404499 #Trained:405001 Training Accuracy:99.8%
Progress:43.9% Speed(reviews/sec):4579. #Correct:406997 #Trained:407501 Training Accuracy:99.8%
Progress:44.2% Speed(reviews/sec):4579. #Correct:409496 #Trained:410001 Training Accuracy:99.8%
Progress:44.4% Speed(reviews/sec):4577. #Correct:411994 #Trained:412501 Training Accuracy:99.8%
Progress:44.7% Speed(reviews/sec):4574. #Correct:414491 #Trained:415001 Training Accuracy:99.8%
Progress:45.0% Speed(reviews/sec):4575. #Correct:416991 #Trained:417501 Training Accuracy:99.8%
Progress:45.2% Speed(reviews/sec):4579. #Correct:419487 #Trained:420001 Training Accuracy:99.8%
Progress:45.5% Speed(reviews/sec):4579. #Correct:421987 #Trained:422501 Training Accuracy:99.8%
Progress:45.8% Speed(reviews/sec):4582. #Correct:424482 #Trained:425001 Training Accuracy:99.8%
Progress:46.0% Speed(reviews/sec):4583. #Correct:426980 #Trained:427501 Training Accuracy:99.8%
Progress:46.3% Speed(reviews/sec):4585. #Correct:429477 #Trained:430001 Training Accuracy:99.8%
Progress:46.6% Speed(reviews/sec):4586. #Correct:431974 #Trained:432501 Training Accuracy:99.8%
Progress:46.9% Speed(reviews/sec):4587. #Correct:434473 #Trained:435001 Training Accuracy:99.8%
Progress:47.1% Speed(reviews/sec):4584. #Correct:436973 #Trained:437501 Training Accuracy:99.8%
Progress:47.4% Speed(reviews/sec):4583. #Correct:439473 #Trained:440001 Training Accuracy:99.8%
Progress:47.7% Speed(reviews/sec):4581. #Correct:441971 #Trained:442501 Training Accuracy:99.8%
Progress:47.9% Speed(reviews/sec):4588. #Correct:444470 #Trained:445001 Training Accuracy:99.8%
Progress:48.2% Speed(reviews/sec):4584. #Correct:446969 #Trained:447501 Training Accuracy:99.8%
Progress:48.5% Speed(reviews/sec):4583. #Correct:449468 #Trained:450001 Training Accuracy:99.8%
Progress:48.7% Speed(reviews/sec):4579. #Correct:451965 #Trained:452501 Training Accuracy:99.8%
Progress:49.0% Speed(reviews/sec):4580. #Correct:454463 #Trained:455001 Training Accuracy:99.8%
Progress:49.3% Speed(reviews/sec):4581. #Correct:456962 #Trained:457501 Training Accuracy:99.8%
Progress:49.5% Speed(reviews/sec):4584. #Correct:459462 #Trained:460001 Training Accuracy:99.8%
Progress:49.8% Speed(reviews/sec):4583. #Correct:461959 #Trained:462501 Training Accuracy:99.8%
Progress:50.1% Speed(reviews/sec):4581. #Correct:464458 #Trained:465001 Training Accuracy:99.8%
Progress:50.4% Speed(reviews/sec):4577. #Correct:466956 #Trained:467501 Training Accuracy:99.8%
Progress:50.6% Speed(reviews/sec):4572. #Correct:469456 #Trained:470001 Training Accuracy:99.8%
Progress:50.9% Speed(reviews/sec):4577. #Correct:471953 #Trained:472501 Training Accuracy:99.8%
Progress:51.2% Speed(reviews/sec):4579. #Correct:474450 #Trained:475001 Training Accuracy:99.8%
Progress:51.4% Speed(reviews/sec):4583. #Correct:476939 #Trained:477501 Training Accuracy:99.8%
Progress:51.7% Speed(reviews/sec):4588. #Correct:479437 #Trained:480001 Training Accuracy:99.8%
Progress:52.0% Speed(reviews/sec):4592. #Correct:481932 #Trained:482501 Training Accuracy:99.8%
Progress:52.2% Speed(reviews/sec):4596. #Correct:484430 #Trained:485001 Training Accuracy:99.8%
Progress:52.5% Speed(reviews/sec):4601. #Correct:486926 #Trained:487501 Training Accuracy:99.8%
Progress:52.8% Speed(reviews/sec):4606. #Correct:489421 #Trained:490001 Training Accuracy:99.8%
Progress:53.1% Speed(reviews/sec):4609. #Correct:491919 #Trained:492501 Training Accuracy:99.8%
Progress:53.3% Speed(reviews/sec):4614. #Correct:494414 #Trained:495001 Training Accuracy:99.8%
Progress:53.6% Speed(reviews/sec):4616. #Correct:496911 #Trained:497501 Training Accuracy:99.8%
Progress:53.9% Speed(reviews/sec):4619. #Correct:499406 #Trained:500001 Training Accuracy:99.8%
Progress:54.1% Speed(reviews/sec):4620. #Correct:501904 #Trained:502501 Training Accuracy:99.8%
Progress:54.4% Speed(reviews/sec):4623. #Correct:504404 #Trained:505001 Training Accuracy:99.8%
Progress:54.7% Speed(reviews/sec):4628. #Correct:506903 #Trained:507501 Training Accuracy:99.8%
Progress:54.9% Speed(reviews/sec):4631. #Correct:509401 #Trained:510001 Training Accuracy:99.8%
Progress:55.2% Speed(reviews/sec):4632. #Correct:511899 #Trained:512501 Training Accuracy:99.8%
Progress:55.5% Speed(reviews/sec):4638. #Correct:514389 #Trained:515001 Training Accuracy:99.8%
Progress:55.7% Speed(reviews/sec):4641. #Correct:515897 #Trained:517501 Training Accuracy:99.6%
Progress:56.0% Speed(reviews/sec):4642. #Correct:518354 #Trained:520001 Training Accuracy:99.6%
Progress:56.3% Speed(reviews/sec):4643. #Correct:520787 #Trained:522501 Training Accuracy:99.6%
Progress:56.6% Speed(reviews/sec):4643. #Correct:523234 #Trained:525001 Training Accuracy:99.6%
Progress:56.8% Speed(reviews/sec):4644. #Correct:525648 #Trained:527501 Training Accuracy:99.6%
Progress:57.1% Speed(reviews/sec):4647. #Correct:528072 #Trained:530001 Training Accuracy:99.6%
Progress:57.4% Speed(reviews/sec):4651. #Correct:530395 #Trained:532501 Training Accuracy:99.6%
Progress:57.6% Speed(reviews/sec):4654. #Correct:532808 #Trained:535001 Training Accuracy:99.5%
Progress:57.9% Speed(reviews/sec):4652. #Correct:535195 #Trained:537501 Training Accuracy:99.5%
Progress:58.2% Speed(reviews/sec):4652. #Correct:537596 #Trained:540001 Training Accuracy:99.5%
Progress:58.4% Speed(reviews/sec):4652. #Correct:540017 #Trained:542501 Training Accuracy:99.5%
Progress:58.7% Speed(reviews/sec):4656. #Correct:542411 #Trained:545001 Training Accuracy:99.5%
Progress:59.0% Speed(reviews/sec):4656. #Correct:544809 #Trained:547501 Training Accuracy:99.5%
Progress:59.3% Speed(reviews/sec):4652. #Correct:547236 #Trained:550001 Training Accuracy:99.4%
Progress:59.5% Speed(reviews/sec):4644. #Correct:549666 #Trained:552501 Training Accuracy:99.4%
Progress:59.8% Speed(reviews/sec):4642. #Correct:552090 #Trained:555001 Training Accuracy:99.4%
Progress:60.1% Speed(reviews/sec):4642. #Correct:554510 #Trained:557501 Training Accuracy:99.4%
Progress:60.3% Speed(reviews/sec):4641. #Correct:556941 #Trained:560001 Training Accuracy:99.4%
Progress:60.6% Speed(reviews/sec):4636. #Correct:559330 #Trained:562501 Training Accuracy:99.4%
Progress:60.9% Speed(reviews/sec):4632. #Correct:561744 #Trained:565001 Training Accuracy:99.4%
Progress:61.1% Speed(reviews/sec):4628. #Correct:564168 #Trained:567501 Training Accuracy:99.4%
Progress:61.4% Speed(reviews/sec):4629. #Correct:566549 #Trained:570001 Training Accuracy:99.3%
Progress:61.7% Speed(reviews/sec):4632. #Correct:568962 #Trained:572501 Training Accuracy:99.3%
Progress:61.9% Speed(reviews/sec):4635. #Correct:571355 #Trained:575001 Training Accuracy:99.3%
Progress:62.1% Speed(reviews/sec):4636. #Correct:572466 #Trained:576146 Training Accuracy:99.3%</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>IOPub data rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_data_rate_limit`.

Current values:
NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)
NotebookApp.rate_limit_window=3.0 (secs)

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Progress:62.8% Speed(reviews/sec):4631. #Correct:578639 #Trained:582501 Training Accuracy:99.3%
Progress:63.0% Speed(reviews/sec):4633. #Correct:581072 #Trained:585001 Training Accuracy:99.3%
Progress:63.3% Speed(reviews/sec):4636. #Correct:583487 #Trained:587501 Training Accuracy:99.3%
Progress:63.6% Speed(reviews/sec):4637. #Correct:585907 #Trained:590001 Training Accuracy:99.3%
Progress:63.8% Speed(reviews/sec):4638. #Correct:588307 #Trained:592501 Training Accuracy:99.2%
Progress:64.1% Speed(reviews/sec):4639. #Correct:590729 #Trained:595001 Training Accuracy:99.2%
Progress:64.4% Speed(reviews/sec):4640. #Correct:593164 #Trained:597501 Training Accuracy:99.2%
Progress:64.6% Speed(reviews/sec):4640. #Correct:595564 #Trained:600001 Training Accuracy:99.2%
Progress:64.9% Speed(reviews/sec):4641. #Correct:597957 #Trained:602501 Training Accuracy:99.2%
Progress:65.2% Speed(reviews/sec):4645. #Correct:600369 #Trained:605001 Training Accuracy:99.2%
Progress:65.5% Speed(reviews/sec):4646. #Correct:602798 #Trained:607501 Training Accuracy:99.2%
Progress:65.7% Speed(reviews/sec):4648. #Correct:605181 #Trained:610001 Training Accuracy:99.2%
Progress:66.0% Speed(reviews/sec):4650. #Correct:607578 #Trained:612501 Training Accuracy:99.1%
Progress:66.3% Speed(reviews/sec):4650. #Correct:609994 #Trained:615001 Training Accuracy:99.1%
Progress:66.5% Speed(reviews/sec):4648. #Correct:612412 #Trained:617501 Training Accuracy:99.1%
Progress:66.8% Speed(reviews/sec):4641. #Correct:614866 #Trained:620001 Training Accuracy:99.1%
Progress:67.1% Speed(reviews/sec):4644. #Correct:617293 #Trained:622501 Training Accuracy:99.1%
Progress:67.3% Speed(reviews/sec):4648. #Correct:619658 #Trained:625001 Training Accuracy:99.1%
Progress:67.6% Speed(reviews/sec):4647. #Correct:622069 #Trained:627501 Training Accuracy:99.1%
Progress:67.9% Speed(reviews/sec):4648. #Correct:624503 #Trained:630001 Training Accuracy:99.1%
Progress:68.1% Speed(reviews/sec):4647. #Correct:626948 #Trained:632501 Training Accuracy:99.1%
Progress:68.4% Speed(reviews/sec):4649. #Correct:629354 #Trained:635001 Training Accuracy:99.1%
Progress:68.7% Speed(reviews/sec):4652. #Correct:631767 #Trained:637501 Training Accuracy:99.1%
Progress:69.0% Speed(reviews/sec):4653. #Correct:634175 #Trained:640001 Training Accuracy:99.0%
Progress:69.2% Speed(reviews/sec):4652. #Correct:636622 #Trained:642501 Training Accuracy:99.0%
Progress:69.5% Speed(reviews/sec):4655. #Correct:639050 #Trained:645001 Training Accuracy:99.0%
Progress:69.8% Speed(reviews/sec):4653. #Correct:641507 #Trained:647501 Training Accuracy:99.0%
Progress:70.0% Speed(reviews/sec):4656. #Correct:643938 #Trained:650001 Training Accuracy:99.0%
Progress:70.3% Speed(reviews/sec):4654. #Correct:646351 #Trained:652501 Training Accuracy:99.0%
Progress:70.6% Speed(reviews/sec):4657. #Correct:648759 #Trained:655001 Training Accuracy:99.0%
Progress:70.8% Speed(reviews/sec):4655. #Correct:651185 #Trained:657501 Training Accuracy:99.0%
Progress:71.1% Speed(reviews/sec):4657. #Correct:653600 #Trained:660001 Training Accuracy:99.0%
Progress:71.4% Speed(reviews/sec):4659. #Correct:655989 #Trained:662501 Training Accuracy:99.0%
Progress:71.7% Speed(reviews/sec):4660. #Correct:658385 #Trained:665001 Training Accuracy:99.0%
Progress:71.9% Speed(reviews/sec):4662. #Correct:660773 #Trained:667501 Training Accuracy:98.9%
Progress:72.2% Speed(reviews/sec):4665. #Correct:663200 #Trained:670001 Training Accuracy:98.9%
Progress:72.5% Speed(reviews/sec):4662. #Correct:665640 #Trained:672501 Training Accuracy:98.9%
Progress:72.7% Speed(reviews/sec):4665. #Correct:668062 #Trained:675001 Training Accuracy:98.9%
Progress:73.0% Speed(reviews/sec):4665. #Correct:670472 #Trained:677501 Training Accuracy:98.9%
Progress:73.3% Speed(reviews/sec):4663. #Correct:672912 #Trained:680001 Training Accuracy:98.9%
Progress:73.5% Speed(reviews/sec):4663. #Correct:675352 #Trained:682501 Training Accuracy:98.9%
Progress:73.8% Speed(reviews/sec):4666. #Correct:677776 #Trained:684997 Training Accuracy:98.9%Progress:73.8% Speed(reviews/sec):4664. #Correct:677780 #Trained:685001 Training Accuracy:98.9%
Progress:74.1% Speed(reviews/sec):4666. #Correct:680187 #Trained:687501 Training Accuracy:98.9%
Progress:74.3% Speed(reviews/sec):4668. #Correct:682595 #Trained:690001 Training Accuracy:98.9%
Progress:74.6% Speed(reviews/sec):4670. #Correct:685000 #Trained:692501 Training Accuracy:98.9%
Progress:74.9% Speed(reviews/sec):4671. #Correct:687398 #Trained:695001 Training Accuracy:98.9%
Progress:75.2% Speed(reviews/sec):4674. #Correct:689804 #Trained:697501 Training Accuracy:98.8%
Progress:75.4% Speed(reviews/sec):4674. #Correct:692205 #Trained:700001 Training Accuracy:98.8%
Progress:75.7% Speed(reviews/sec):4676. #Correct:694636 #Trained:702501 Training Accuracy:98.8%
Progress:76.0% Speed(reviews/sec):4678. #Correct:697036 #Trained:705001 Training Accuracy:98.8%
Progress:76.2% Speed(reviews/sec):4681. #Correct:699449 #Trained:707501 Training Accuracy:98.8%
Progress:76.5% Speed(reviews/sec):4681. #Correct:701862 #Trained:710001 Training Accuracy:98.8%
Progress:76.8% Speed(reviews/sec):4682. #Correct:704289 #Trained:712501 Training Accuracy:98.8%
Progress:77.0% Speed(reviews/sec):4683. #Correct:706682 #Trained:715001 Training Accuracy:98.8%
Progress:77.3% Speed(reviews/sec):4685. #Correct:709064 #Trained:717501 Training Accuracy:98.8%
Progress:77.6% Speed(reviews/sec):4687. #Correct:711475 #Trained:720001 Training Accuracy:98.8%
Progress:77.9% Speed(reviews/sec):4689. #Correct:713914 #Trained:722501 Training Accuracy:98.8%
Progress:78.1% Speed(reviews/sec):4689. #Correct:716340 #Trained:725001 Training Accuracy:98.8%
Progress:78.4% Speed(reviews/sec):4692. #Correct:718745 #Trained:727501 Training Accuracy:98.7%
Progress:78.7% Speed(reviews/sec):4692. #Correct:721199 #Trained:730001 Training Accuracy:98.7%
Progress:78.9% Speed(reviews/sec):4693. #Correct:723624 #Trained:732501 Training Accuracy:98.7%
Progress:79.2% Speed(reviews/sec):4694. #Correct:726035 #Trained:735001 Training Accuracy:98.7%
Progress:79.5% Speed(reviews/sec):4697. #Correct:728447 #Trained:737501 Training Accuracy:98.7%
Progress:79.7% Speed(reviews/sec):4699. #Correct:730824 #Trained:740001 Training Accuracy:98.7%
Progress:80.0% Speed(reviews/sec):4701. #Correct:733256 #Trained:742501 Training Accuracy:98.7%
Progress:80.3% Speed(reviews/sec):4703. #Correct:735657 #Trained:745001 Training Accuracy:98.7%
Progress:80.5% Speed(reviews/sec):4703. #Correct:738097 #Trained:747501 Training Accuracy:98.7%
Progress:80.8% Speed(reviews/sec):4703. #Correct:740531 #Trained:750001 Training Accuracy:98.7%
Progress:81.1% Speed(reviews/sec):4702. #Correct:742962 #Trained:752501 Training Accuracy:98.7%
Progress:81.4% Speed(reviews/sec):4705. #Correct:745361 #Trained:755001 Training Accuracy:98.7%
Progress:81.6% Speed(reviews/sec):4706. #Correct:747785 #Trained:757501 Training Accuracy:98.7%
Progress:81.9% Speed(reviews/sec):4707. #Correct:750229 #Trained:760001 Training Accuracy:98.7%
Progress:82.2% Speed(reviews/sec):4709. #Correct:752660 #Trained:762501 Training Accuracy:98.7%
Progress:82.4% Speed(reviews/sec):4707. #Correct:755065 #Trained:765001 Training Accuracy:98.7%
Progress:82.7% Speed(reviews/sec):4708. #Correct:757490 #Trained:767501 Training Accuracy:98.6%
Progress:83.0% Speed(reviews/sec):4708. #Correct:759905 #Trained:770001 Training Accuracy:98.6%
Progress:83.2% Speed(reviews/sec):4710. #Correct:762343 #Trained:772501 Training Accuracy:98.6%
Progress:83.5% Speed(reviews/sec):4711. #Correct:764744 #Trained:775001 Training Accuracy:98.6%
Progress:83.8% Speed(reviews/sec):4711. #Correct:767173 #Trained:777501 Training Accuracy:98.6%
Progress:84.1% Speed(reviews/sec):4710. #Correct:769599 #Trained:780001 Training Accuracy:98.6%
Progress:84.3% Speed(reviews/sec):4706. #Correct:772032 #Trained:782501 Training Accuracy:98.6%
Progress:84.6% Speed(reviews/sec):4704. #Correct:774455 #Trained:785001 Training Accuracy:98.6%
Progress:84.9% Speed(reviews/sec):4704. #Correct:776881 #Trained:787501 Training Accuracy:98.6%
Progress:85.1% Speed(reviews/sec):4702. #Correct:779299 #Trained:790001 Training Accuracy:98.6%
Progress:85.4% Speed(reviews/sec):4701. #Correct:781736 #Trained:792501 Training Accuracy:98.6%
Progress:85.7% Speed(reviews/sec):4697. #Correct:784162 #Trained:795001 Training Accuracy:98.6%
Progress:85.9% Speed(reviews/sec):4697. #Correct:786585 #Trained:797501 Training Accuracy:98.6%
Progress:86.2% Speed(reviews/sec):4695. #Correct:788994 #Trained:800001 Training Accuracy:98.6%
Progress:86.5% Speed(reviews/sec):4697. #Correct:791391 #Trained:802501 Training Accuracy:98.6%
Progress:86.7% Speed(reviews/sec):4695. #Correct:793811 #Trained:805001 Training Accuracy:98.6%
Progress:87.0% Speed(reviews/sec):4696. #Correct:796159 #Trained:807501 Training Accuracy:98.5%
Progress:87.3% Speed(reviews/sec):4696. #Correct:798579 #Trained:810001 Training Accuracy:98.5%
Progress:87.6% Speed(reviews/sec):4695. #Correct:800999 #Trained:812501 Training Accuracy:98.5%
Progress:87.8% Speed(reviews/sec):4695. #Correct:803381 #Trained:815001 Training Accuracy:98.5%
Progress:88.1% Speed(reviews/sec):4696. #Correct:805794 #Trained:817501 Training Accuracy:98.5%
Progress:88.4% Speed(reviews/sec):4695. #Correct:808226 #Trained:820001 Training Accuracy:98.5%
Progress:88.6% Speed(reviews/sec):4692. #Correct:810649 #Trained:822501 Training Accuracy:98.5%
Progress:88.9% Speed(reviews/sec):4692. #Correct:813069 #Trained:825001 Training Accuracy:98.5%
Progress:89.2% Speed(reviews/sec):4693. #Correct:815479 #Trained:827501 Training Accuracy:98.5%
Progress:89.4% Speed(reviews/sec):4691. #Correct:817908 #Trained:830001 Training Accuracy:98.5%
Progress:89.7% Speed(reviews/sec):4692. #Correct:820337 #Trained:832501 Training Accuracy:98.5%
Progress:90.0% Speed(reviews/sec):4692. #Correct:822751 #Trained:835001 Training Accuracy:98.5%
Progress:90.3% Speed(reviews/sec):4693. #Correct:825148 #Trained:837501 Training Accuracy:98.5%
Progress:90.5% Speed(reviews/sec):4692. #Correct:827547 #Trained:840001 Training Accuracy:98.5%
Progress:90.8% Speed(reviews/sec):4693. #Correct:829969 #Trained:842501 Training Accuracy:98.5%
Progress:91.1% Speed(reviews/sec):4692. #Correct:832396 #Trained:845001 Training Accuracy:98.5%
Progress:91.3% Speed(reviews/sec):4694. #Correct:834765 #Trained:847501 Training Accuracy:98.4%
Progress:91.6% Speed(reviews/sec):4693. #Correct:837204 #Trained:850001 Training Accuracy:98.4%
Progress:91.9% Speed(reviews/sec):4695. #Correct:839646 #Trained:852501 Training Accuracy:98.4%
Progress:92.1% Speed(reviews/sec):4695. #Correct:842046 #Trained:855001 Training Accuracy:98.4%
Progress:92.4% Speed(reviews/sec):4698. #Correct:844436 #Trained:857501 Training Accuracy:98.4%
Progress:92.7% Speed(reviews/sec):4696. #Correct:846902 #Trained:860001 Training Accuracy:98.4%
Progress:92.9% Speed(reviews/sec):4697. #Correct:849324 #Trained:862501 Training Accuracy:98.4%
Progress:93.2% Speed(reviews/sec):4698. #Correct:851744 #Trained:865001 Training Accuracy:98.4%
Progress:93.5% Speed(reviews/sec):4699. #Correct:854165 #Trained:867501 Training Accuracy:98.4%
Progress:93.8% Speed(reviews/sec):4699. #Correct:856574 #Trained:870001 Training Accuracy:98.4%
Progress:94.0% Speed(reviews/sec):4700. #Correct:859000 #Trained:872501 Training Accuracy:98.4%
Progress:94.3% Speed(reviews/sec):4701. #Correct:861435 #Trained:875001 Training Accuracy:98.4%
Progress:94.6% Speed(reviews/sec):4701. #Correct:863850 #Trained:877501 Training Accuracy:98.4%
Progress:94.8% Speed(reviews/sec):4702. #Correct:866273 #Trained:880001 Training Accuracy:98.4%
Progress:95.1% Speed(reviews/sec):4704. #Correct:868698 #Trained:882501 Training Accuracy:98.4%
Progress:95.4% Speed(reviews/sec):4704. #Correct:871114 #Trained:885001 Training Accuracy:98.4%
Progress:95.6% Speed(reviews/sec):4705. #Correct:873531 #Trained:887501 Training Accuracy:98.4%
Progress:95.9% Speed(reviews/sec):4705. #Correct:875948 #Trained:890001 Training Accuracy:98.4%
Progress:96.2% Speed(reviews/sec):4704. #Correct:878355 #Trained:892501 Training Accuracy:98.4%
Progress:96.5% Speed(reviews/sec):4703. #Correct:880796 #Trained:895001 Training Accuracy:98.4%
Progress:96.7% Speed(reviews/sec):4705. #Correct:883187 #Trained:897501 Training Accuracy:98.4%
Progress:97.0% Speed(reviews/sec):4706. #Correct:885612 #Trained:900001 Training Accuracy:98.4%
Progress:97.3% Speed(reviews/sec):4708. #Correct:888024 #Trained:902501 Training Accuracy:98.3%
Progress:97.5% Speed(reviews/sec):4708. #Correct:890431 #Trained:905001 Training Accuracy:98.3%
Progress:97.8% Speed(reviews/sec):4711. #Correct:892831 #Trained:907501 Training Accuracy:98.3%
Progress:98.1% Speed(reviews/sec):4711. #Correct:895250 #Trained:910001 Training Accuracy:98.3%
Progress:98.3% Speed(reviews/sec):4713. #Correct:897631 #Trained:912501 Training Accuracy:98.3%
Progress:98.6% Speed(reviews/sec):4714. #Correct:900043 #Trained:915001 Training Accuracy:98.3%
Progress:98.9% Speed(reviews/sec):4716. #Correct:902460 #Trained:917501 Training Accuracy:98.3%
Progress:99.1% Speed(reviews/sec):4717. #Correct:904853 #Trained:920001 Training Accuracy:98.3%
Progress:99.4% Speed(reviews/sec):4719. #Correct:907216 #Trained:922501 Training Accuracy:98.3%
Progress:99.7% Speed(reviews/sec):4721. #Correct:909632 #Trained:925001 Training Accuracy:98.3%
Progress:99.9% Speed(reviews/sec):4722. #Correct:911969 #Trained:927422 Training Accuracy:98.3%</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[63]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mlp</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">reviews</span><span class="p">[</span><span class="o">-</span><span class="mi">103000</span><span class="p">:],</span><span class="n">labels</span><span class="p">[</span><span class="o">-</span><span class="mi">103000</span><span class="p">:])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Progress:99.9% Speed(reviews/sec):6834. #Correct:99480 #Tested:103000 Testing Accuracy:96.5%</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[64]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pos_neg_ratios</span><span class="o">.</span><span class="n">most_common</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[64]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[(&#39;aerobus&#39;, 4.548599834499697),
 (&#39;negative&#39;, 4.411158948711202),
 (&#39;theatres&#39;, 4.076232812279055),
 (&#39;dame&#39;, 4.02733385193914),
 (&#39;wonderfully&#39;, 4.023117052933733),
 (&#39;notre&#39;, 4.017383521085972),
 (&#39;breathtaking&#39;, 3.9765615265657175),
 (&#39;divine&#39;, 3.7612001156935624),
 (&#39;oasis&#39;, 3.703768066607687),
 (&#39;immaculately&#39;, 3.6375861597263857),
 (&#39;hofburg&#39;, 3.6109179126442243),
 (&#39;spotlessly&#39;, 3.570988654030486),
 (&#39;sse&#39;, 3.5648268054439574),
 (&#39;museums&#39;, 3.491905620533111),
 (&#39;seine&#39;, 3.449987545831587),
 (&#39;buckingham&#39;, 3.448001447859958),
 (&#39;excelent&#39;, 3.4400173735117376),
 (&#39;galleries&#39;, 3.439349147626532),
 (&#39;orsay&#39;, 3.4094961844768505),
 (&#39;lush&#39;, 3.4011973816621555),
 (&#39;theaters&#39;, 3.4011973816621555),
 (&#39;impeccably&#39;, 3.3843902633457743),
 (&#39;harrods&#39;, 3.380994674344636),
 (&#39;lication&#39;, 3.3758795736778655),
 (&#39;albert&#39;, 3.3706543553936084),
 (&#39;tate&#39;, 3.3623575483458916),
 (&#39;wonderfull&#39;, 3.361532125269724),
 (&#39;yummy&#39;, 3.3512527051458987),
 (&#39;phenomenal&#39;, 3.3440389678222067),
 (&#39;helpfulness&#39;, 3.3349479961209547),
 (&#39;superb&#39;, 3.292449492816166),
 (&#39;gorgeous&#39;, 3.2799155854161217),
 (&#39;exquisite&#39;, 3.2724165917962305),
 (&#39;excellent&#39;, 3.26993061301413),
 (&#39;espanya&#39;, 3.265759410767051),
 (&#39;hyde&#39;, 3.262567484366249),
 (&#39;gaudi&#39;, 3.2516656476911914),
 (&#39;2min&#39;, 3.248434627109745),
 (&#39;musee&#39;, 3.2088254890146994),
 (&#39;awesome&#39;, 3.2052294157269103),
 (&#39;immaculate&#39;, 3.1918471524802814),
 (&#39;spacious&#39;, 3.189047598580155),
 (&#39;fantastic&#39;, 3.1838276633832576),
 (&#39;covent&#39;, 3.1828870925359647),
 (&#39;unbeatable&#39;, 3.1780538303479458),
 (&#39;comfy&#39;, 3.16599062078966),
 (&#39;louvre&#39;, 3.1653471790788306),
 (&#39;fantastically&#39;, 3.1612467120315646),
 (&#39;lafayette&#39;, 3.1135153092103742),
 (&#39;amazing&#39;, 3.113145640521723),
 (&#39;abbey&#39;, 3.106080330722856),
 (&#39;spacy&#39;, 3.0985896589936988),
 (&#39;stylish&#39;, 3.093187609704704),
 (&#39;beautifully&#39;, 3.091577069783773),
 (&#39;superbly&#39;, 3.077970371790963),
 (&#39;tastefully&#39;, 3.0741542353297944),
 (&#39;excellant&#39;, 3.0706335817271087),
 (&#39;amazingly&#39;, 3.069344090897237),
 (&#39;brera&#39;, 3.054001181677967),
 (&#39;delicious&#39;, 3.0462845527168225),
 (&#39;thoughtful&#39;, 3.0423555896383325),
 (&#39;rathaus&#39;, 3.0204248861443626),
 (&#39;beautiful&#39;, 3.0163160676690017),
 (&#39;parliament&#39;, 3.0122615755052013),
 (&#39;triomphe&#39;, 3.008977500304012),
 (&#39;obliging&#39;, 3.006782109740576),
 (&#39;royalty&#39;, 2.995732273553991),
 (&#39;trafalgar&#39;, 2.9894626605403958),
 (&#39;airy&#39;, 2.9869985935852363),
 (&#39;unforgettable&#39;, 2.9789251552376097),
 (&#39;fabulous&#39;, 2.966713579664955),
 (&#39;placa&#39;, 2.9628444067091557),
 (&#39;tasteful&#39;, 2.955458374416051),
 (&#39;courteous&#39;, 2.9513302774952814),
 (&#39;lys&#39;, 2.9444389791664403),
 (&#39;terrific&#39;, 2.928226391188618),
 (&#39;catalunya&#39;, 2.920769235080536),
 (&#39;exellent&#39;, 2.920224721045846),
 (&#39;outstanding&#39;, 2.917983520679613),
 (&#39;localization&#39;, 2.917770732084279),
 (&#39;friendly&#39;, 2.9121864937361397),
 (&#39;friendliness&#39;, 2.909240242200547),
 (&#39;stunning&#39;, 2.894636156682622),
 (&#39;arc&#39;, 2.8943321591122615),
 (&#39;strategic&#39;, 2.882403588246988),
 (&#39;elemis&#39;, 2.8693183486983322),
 (&#39;oxford&#39;, 2.8663531360302357),
 (&#39;sants&#39;, 2.863703510814003),
 (&#39;location&#39;, 2.8626448171189858),
 (&#39;impeccable&#39;, 2.860157979299668),
 (&#39;elegant&#39;, 2.8574276021768106),
 (&#39;helpful&#39;, 2.8547712560358787),
 (&#39;piccadilly&#39;, 2.851861903134289),
 (&#39;earls&#39;, 2.847812143477369),
 (&#39;closeness&#39;, 2.8455211917308127),
 (&#39;southbank&#39;, 2.833213344056216),
 (&#39;cute&#39;, 2.8315312578732312),
 (&#39;queensway&#39;, 2.829940018711247),
 (&#39;latin&#39;, 2.8273136219290276),
 (&#39;aldgate&#39;, 2.8247744754103516),
 (&#39;spotless&#39;, 2.8178650671094165),
 (&#39;pancras&#39;, 2.815988037774337),
 (&#39;wonderful&#39;, 2.811619095553118),
 (&#39;exceptional&#39;, 2.8115111034175593),
 (&#39;fab&#39;, 2.811504138489455),
 (&#39;heavenly&#39;, 2.803360380906535),
 (&#39;spacey&#39;, 2.803360380906535),
 (&#39;stephen&#39;, 2.803360380906535),
 (&#39;balloons&#39;, 2.7999876964278956),
 (&#39;rer&#39;, 2.7999876964278956),
 (&#39;regents&#39;, 2.7990219793079367),
 (&#39;delightful&#39;, 2.797281334830153),
 (&#39;westbahnhof&#39;, 2.793208009442517),
 (&#39;excellently&#39;, 2.785011242238338),
 (&#39;passeig&#39;, 2.779509165084355),
 (&#39;quietness&#39;, 2.7788192719904172),
 (&#39;centrale&#39;, 2.7771514677981997),
 (&#39;champs&#39;, 2.772588722239781),
 (&#39;splendid&#39;, 2.772588722239781),
 (&#39;macaroons&#39;, 2.772588722239781),
 (&#39;warmly&#39;, 2.765620052923688),
 (&#39;marylebone&#39;, 2.7580606216768717),
 (&#39;picadilly&#39;, 2.7568403652716422),
 (&#39;museum&#39;, 2.7563111247194634),
 (&#39;helpfull&#39;, 2.7470864294288453),
 (&#39;magical&#39;, 2.7454377331738304),
 (&#39;gem&#39;, 2.740840023925201),
 (&#39;freindly&#39;, 2.732003442124703),
 (&#39;belvedere&#39;, 2.731580698512404),
 (&#39;conveniently&#39;, 2.730397499794207),
 (&#39;sloterdijk&#39;, 2.7300291078209855),
 (&#39;village&#39;, 2.70805020110221),
 (&#39;lovely&#39;, 2.7054871924373205),
 (&#39;modern&#39;, 2.700141288956532),
 (&#39;germain&#39;, 2.6820747146989494),
 (&#39;elysees&#39;, 2.681021528714291),
 (&#39;peaceful&#39;, 2.6750556789671713),
 (&#39;vibrant&#39;, 2.672332118500131),
 (&#39;sacre&#39;, 2.670309873119363),
 (&#39;pleasantly&#39;, 2.6678593205189647),
 (&#39;opera&#39;, 2.6595825655599894),
 (&#39;bonus&#39;, 2.655440250829913),
 (&#39;brilliant&#39;, 2.6344152930702833),
 (&#39;shopping&#39;, 2.633239977549345),
 (&#39;vondelpark&#39;, 2.631888840136646),
 (&#39;cookie&#39;, 2.6280074934286737),
 (&#39;borough&#39;, 2.6210388241125804),
 (&#39;hop&#39;, 2.6135240276100937),
 (&#39;quirky&#39;, 2.6110181095508658),
 (&#39;scala&#39;, 2.606796467397037),
 (&#39;cheerful&#39;, 2.6060510331470885),
 (&#39;delight&#39;, 2.6026896854443837),
 (&#39;charming&#39;, 2.5900439262440957),
 (&#39;luxembourg&#39;, 2.5877640352277083),
 (&#39;montmartre&#39;, 2.586689344097943),
 (&#39;magnificent&#39;, 2.578124778620101),
 (&#39;heartbeat&#39;, 2.5745188084776873),
 (&#39;accommodating&#39;, 2.5690203139415586),
 (&#39;sights&#39;, 2.567369201352572),
 (&#39;eurostar&#39;, 2.567209245428974),
 (&#39;sagrada&#39;, 2.5666960827964784),
 (&#39;classy&#39;, 2.563409711275944),
 (&#39;history&#39;, 2.561499095269384),
 (&#39;neat&#39;, 2.5563656137701454),
 (&#39;schonbrunn&#39;, 2.5508646175797978),
 (&#39;casa&#39;, 2.550421256898627),
 (&#39;gothic&#39;, 2.545075171254453),
 (&#39;elegance&#39;, 2.5437471498109336),
 (&#39;gloucester&#39;, 2.5382217085557217),
 (&#39;bustle&#39;, 2.5347203555002196),
 (&#39;euston&#39;, 2.5319067038351837),
 (&#39;elysee&#39;, 2.531426665422893),
 (&#39;calm&#39;, 2.527417358472589),
 (&#39;thankyou&#39;, 2.5226469777708473),
 (&#39;landmarks&#39;, 2.51939282585917),
 (&#39;michel&#39;, 2.515678308454754),
 (&#39;attentive&#39;, 2.5133516813585204),
 (&#39;familia&#39;, 2.511076367521385),
 (&#39;nord&#39;, 2.508812170641555),
 (&#39;specious&#39;, 2.501435951739211),
 (&#39;cozy&#39;, 2.501134186409757),
 (&#39;mod&#39;, 2.499944527152541),
 (&#39;links&#39;, 2.4932054526026954),
 (&#39;unique&#39;, 2.4908413853078146),
 (&#39;accomodating&#39;, 2.477937980471907),
 (&#39;relaxed&#39;, 2.477013948989091),
 (&#39;appointed&#39;, 2.4760960201058455),
 (&#39;thumbs&#39;, 2.474435349920705),
 (&#39;gare&#39;, 2.4712078054298385),
 (&#39;hammersmith&#39;, 2.466214516775848),
 (&#39;sumptuous&#39;, 2.465488563930899),
 (&#39;westfield&#39;, 2.463853240590168),
 (&#39;regent&#39;, 2.4619171315633017),
 (&#39;proximity&#39;, 2.45963222669276),
 (&#39;vibe&#39;, 2.4411712562801924),
 (&#39;holborn&#39;, 2.439444275711243),
 (&#39;memorable&#39;, 2.4389969484839225),
 (&#39;ziggo&#39;, 2.4383866341531073),
 (&#39;loved&#39;, 2.4308889420473068),
 (&#39;bubbly&#39;, 2.4294768448486694),
 (&#39;olympic&#39;, 2.4292177439274116),
 (&#39;handy&#39;, 2.423168949182221),
 (&#39;stroll&#39;, 2.4203681286504293),
 (&#39;brilliantly&#39;, 2.414289082574047),
 (&#39;praise&#39;, 2.414289082574047),
 (&#39;danube&#39;, 2.412933150162911),
 (&#39;incredible&#39;, 2.4093731606430575),
 (&#39;palace&#39;, 2.4065160158422776),
 (&#39;decorated&#39;, 2.4004648673600015),
 (&#39;doorstep&#39;, 2.3999592570192223),
 (&#39;royal&#39;, 2.398832041016757),
 (&#39;alex&#39;, 2.3978952727983707),
 (&#39;cathedral&#39;, 2.3968497943968177),
 (&#39;gracia&#39;, 2.393754480132339),
 (&#39;gardens&#39;, 2.3916491563014177),
 (&#39;convenient&#39;, 2.3887091368488953),
 (&#39;comfortable&#39;, 2.3831481868782385),
 (&#39;marvellous&#39;, 2.379546134130174),
 (&#39;barbican&#39;, 2.379546134130174),
 (&#39;kensington&#39;, 2.3752242766340173),
 (&#39;roomy&#39;, 2.37242866636131),
 (&#39;paddington&#39;, 2.3713215213458567),
 (&#39;leicester&#39;, 2.3642786619993856),
 (&#39;great&#39;, 2.3600451028141833),
 (&#39;contemporary&#39;, 2.358376452622461),
 (&#39;saint&#39;, 2.3581549441488563),
 (&#39;bayswater&#39;, 2.3562892719659065),
 (&#39;nicely&#39;, 2.35509503826601),
 (&#39;homely&#39;, 2.3513752571634776),
 (&#39;petals&#39;, 2.3513752571634776),
 (&#39;quiet&#39;, 2.342573644719577),
 (&#39;hermes&#39;, 2.341805806147327),
 (&#39;hustle&#39;, 2.3363824725773363),
 (&#39;exemplary&#39;, 2.32949254591397),
 (&#39;duomo&#39;, 2.3292842993492857),
 (&#39;apollo&#39;, 2.32163328796474),
 (&#39;exploring&#39;, 2.319721375237033),
 (&#39;tidy&#39;, 2.3181414294087745),
 (&#39;cookies&#39;, 2.3171572998531365),
 (&#39;baker&#39;, 2.3116349285139637),
 (&#39;westminster&#39;, 2.311500456651998),
 (&#39;delighted&#39;, 2.306577114263583),
 (&#39;ambience&#39;, 2.2982901687111648),
 (&#39;montparnasse&#39;, 2.2975725511705014),
 (&#39;chocolates&#39;, 2.296887071879408),
 (&#39;shepherds&#39;, 2.295416603515433),
 (&#39;leidseplein&#39;, 2.2925347571405443),
 (&#39;strawberries&#39;, 2.2914117923959205),
 (&#39;architecture&#39;, 2.281531683796213),
 (&#39;marvelous&#39;, 2.2809235962128662),
 (&#39;moulin&#39;, 2.2809235962128662),
 (&#39;professional&#39;, 2.2804729224479714),
 (&#39;nou&#39;, 2.278774444300327),
 (&#39;knowledgable&#39;, 2.272984623217755),
 (&#39;liverpool&#39;, 2.272507637756768),
 (&#39;wonderland&#39;, 2.272125885509337),
 (&#39;heart&#39;, 2.2713325494899412),
 (&#39;plentiful&#39;, 2.264363880173848),
 (&#39;touches&#39;, 2.2629198366016143),
 (&#39;frendly&#39;, 2.2553322081435003),
 (&#39;daniel&#39;, 2.2512917986064953),
 (&#39;highly&#39;, 2.251163106758946),
 (&#39;canals&#39;, 2.2464956263430023),
 (&#39;efficient&#39;, 2.240549702074593),
 (&#39;circus&#39;, 2.240064736012712),
 (&#39;greenwich&#39;, 2.2398749646865896),
 (&#39;olympia&#39;, 2.2380465718564744),
 (&#39;heaven&#39;, 2.2380465718564744),
 (&#39;convinient&#39;, 2.2373445711256448),
 (&#39;iconic&#39;, 2.236833715431265),
 (&#39;polite&#39;, 2.236380619985695),
 (&#39;ideally&#39;, 2.2363785147557773),
 (&#39;artistic&#39;, 2.2300144001592104),
 (&#39;du&#39;, 2.2293816889707507),
 (&#39;piazza&#39;, 2.222542385320509),
 (&#39;arena&#39;, 2.2158669281454992),
 (&#39;quaint&#39;, 2.212538812309262),
 (&#39;kindness&#39;, 2.207274913189721),
 (&#39;soho&#39;, 2.207052666272482),
 (&#39;victoria&#39;, 2.205855466535495),
 (&#39;tranquil&#39;, 2.1972245773362196),
 (&#39;embankment&#39;, 2.1972245773362196),
 (&#39;favourite&#39;, 2.1952023319554517),
 (&#39;walkable&#39;, 2.192161275379673),
 (&#39;defo&#39;, 2.1897895988487015),
 (&#39;mall&#39;, 2.1838505178109626),
 (&#39;informative&#39;, 2.1771233980151323),
 (&#39;cake&#39;, 2.1745033051370877),
 (&#39;bahn&#39;, 2.172476407647025),
 (&#39;russell&#39;, 2.170413319885563),
 (&#39;knowledgeable&#39;, 2.168418578087138),
 (&#39;es&#39;, 2.1675488091901025),
 (&#39;comfiest&#39;, 2.164963715117998),
 (&#39;attractions&#39;, 2.1641691435885972),
 (&#39;marina&#39;, 2.1629746542931407),
 (&#39;array&#39;, 2.159484249353372),
 (&#39;camden&#39;, 2.158003864182938),
 (&#39;gogh&#39;, 2.1567332159814825),
 (&#39;super&#39;, 2.1566564057564674),
 (&#39;rambla&#39;, 2.1566462178518875),
 (&#39;pla&#39;, 2.1559816188021705),
 (&#39;thames&#39;, 2.1558832371797783),
 (&#39;doormen&#39;, 2.1552015875613715),
 (&#39;recommendations&#39;, 2.155153363415532),
 (&#39;dome&#39;, 2.1546649629174235),
 (&#39;personalised&#39;, 2.1498223384416355),
 (&#39;supermarkets&#39;, 2.146830563584813),
 (&#39;bush&#39;, 2.145742621501076),
 (&#39;easy&#39;, 2.143185867620253),
 (&#39;spectacular&#39;, 2.133686556532232),
 (&#39;excel&#39;, 2.132816002271211),
 (&#39;caring&#39;, 2.125961557314729),
 (&#39;stations&#39;, 2.1228517332224617),
 (&#39;extraordinary&#39;, 2.1216418961702126),
 (&#39;pristine&#39;, 2.120263536200091),
 (&#39;reasonably&#39;, 2.1159991374136333),
 (&#39;explore&#39;, 2.1117424864681573),
 (&#39;sleek&#39;, 2.1102132003465894),
 (&#39;ease&#39;, 2.109061789741548),
 (&#39;funky&#39;, 2.108769156774356),
 (&#39;james&#39;, 2.106252799130493),
 (&#39;perfect&#39;, 2.106207604454418),
 (&#39;ben&#39;, 2.1048512572052043),
 (&#39;pleasure&#39;, 2.101629456655198),
 (&#39;shepherd&#39;, 2.097141118779237),
 (&#39;locality&#39;, 2.0918640616783932),
 (&#39;ambiance&#39;, 2.0902007608315754),
 (&#39;100m&#39;, 2.0856720914304723),
 (&#39;marais&#39;, 2.0856720914304723),
 (&#39;love&#39;, 2.0791992642710193),
 (&#39;cava&#39;, 2.0703090581165635),
 (&#39;lyon&#39;, 2.069779630768099),
 (&#39;stadium&#39;, 2.0650528042277365),
 (&#39;prompt&#39;, 2.0642403803477856),
 (&#39;clean&#39;, 2.0639474796802704),
 (&#39;convenience&#39;, 2.0635681925235456),
 (&#39;ample&#39;, 2.0583881324820035),
 (&#39;hesitate&#39;, 2.057323736426217),
 (&#39;david&#39;, 2.05572501506252),
 (&#39;grocery&#39;, 2.0541237336955462),
 (&#39;stones&#39;, 2.0492277630833393),
 (&#39;competent&#39;, 2.044755983691946),
 (&#39;5min&#39;, 2.0436524338282505),
 (&#39;gracious&#39;, 2.03688192726104),
 (&#39;pharmacy&#39;, 2.03688192726104),
 (&#39;thank&#39;, 2.0359400254060716),
 (&#39;st&#39;, 2.0353815518858056),
 (&#39;las&#39;, 2.0319005969108357),
 (&#39;galleria&#39;, 2.030170492673053),
 (&#39;shops&#39;, 2.0275927273326966),
 (&#39;welcoming&#39;, 2.0265837098153914),
 (&#39;theatre&#39;, 2.026202575796198),
 (&#39;historic&#39;, 2.0248985603739436),
 (&#39;chic&#39;, 2.0227155602790585),
 (&#39;authentic&#39;, 2.0149030205422647),
 (&#39;triumph&#39;, 2.0149030205422647),
 (&#39;favorite&#39;, 2.0133514298508457),
 (&#39;enjoyed&#39;, 2.0066471423469916),
 (&#39;confortable&#39;, 2.0056006278799514),
 (&#39;distance&#39;, 2.0039785867128224),
 (&#39;ramblas&#39;, 2.0002599919254127),
 (&#39;goodies&#39;, 1.992430164690206),
 (&#39;heathrow&#39;, 1.9828805799738585),
 (&#39;born&#39;, 1.9810014688665833),
 (&#39;equipped&#39;, 1.979058193374189),
 (&#39;exceptionally&#39;, 1.9742242001936336),
 (&#39;views&#39;, 1.9729488332822323),
 (&#39;wembley&#39;, 1.9669635582531455),
 (&#39;pleasant&#39;, 1.9662661665963699),
 (&#39;notch&#39;, 1.9661128563728327),
 (&#39;stratford&#39;, 1.9636097261547143),
 (&#39;maria&#39;, 1.9629077254238845),
 (&#39;tasty&#39;, 1.9557318873538132),
 (&#39;chilled&#39;, 1.9528546214081244),
 (&#39;eiffel&#39;, 1.9493057380564516),
 (&#39;nice&#39;, 1.9488116516430403),
 (&#39;gifts&#39;, 1.9459101490553132),
 (&#39;imperial&#39;, 1.9459101490553132),
 (&#39;tube&#39;, 1.9449532528055333),
 (&#39;station&#39;, 1.9412405085165496),
 (&#39;knightsbridge&#39;, 1.9399399820688095),
 (&#39;die&#39;, 1.9383629434199305),
 (&#39;silent&#39;, 1.9373447861963902),
 (&#39;shard&#39;, 1.9361221426891504),
 (&#39;highlights&#39;, 1.9348603128687283),
 (&#39;quarter&#39;, 1.93334892318234),
 (&#39;parks&#39;, 1.9315214116032138),
 (&#39;art&#39;, 1.9280325779479073),
 (&#39;panoramic&#39;, 1.927891643552635),
 (&#39;concerts&#39;, 1.9266787871274256),
 (&#39;schiphol&#39;, 1.9252908618525775),
 (&#39;exceeded&#39;, 1.9207515894191585),
 (&#39;treats&#39;, 1.911489925168834),
 (&#39;paul&#39;, 1.9102410728485784),
 (&#39;stores&#39;, 1.9057037285772729),
 (&#39;tower&#39;, 1.9050185917372144),
 (&#39;restaurants&#39;, 1.9047508168756062),
 (&#39;rouge&#39;, 1.9042374526547452),
 (&#39;castle&#39;, 1.9029851043382795),
 (&#39;swift&#39;, 1.9002401122221249),
 (&#39;approachable&#39;, 1.8960555888300947),
 (&#39;sophisticated&#39;, 1.8918429277850375),
 (&#39;bridge&#39;, 1.888318478417287),
 (&#39;luxurious&#39;, 1.8842067784827028),
 (&#39;position&#39;, 1.882819434743685),
 (&#39;historical&#39;, 1.8808872491240625),
 (&#39;des&#39;, 1.8754584881047018),
 (&#39;national&#39;, 1.8744511850731684),
 (&#39;dream&#39;, 1.8718021769015913),
 (&#39;boutique&#39;, 1.8715482731297564),
 (&#39;cloud&#39;, 1.8687205103641833),
 (&#39;fluffy&#39;, 1.8613008870809282),
 (&#39;defiantly&#39;, 1.8601966307812834),
 (&#39;wien&#39;, 1.8597641983421125),
 (&#39;navigli&#39;, 1.8581345381729277),
 (&#39;generous&#39;, 1.855734768723027),
 (&#39;asset&#39;, 1.8551812956655511),
 (&#39;pubs&#39;, 1.8525516654060048),
 (&#39;cosy&#39;, 1.8496891904722275),
 (&#39;routes&#39;, 1.8482716794913974),
 (&#39;earl&#39;, 1.8466003849276411),
 (&#39;fireplace&#39;, 1.8458266904983307),
 (&#39;university&#39;, 1.8439452223986252),
 (&#39;resturants&#39;, 1.8399615710459327),
 (&#39;ealing&#39;, 1.83961549040569),
 (&#39;metro&#39;, 1.8359391368360687),
 (&#39;sites&#39;, 1.834886497423527),
 (&#39;court&#39;, 1.8340618489187444),
 (&#39;rich&#39;, 1.8329697378747178),
 (&#39;markets&#39;, 1.830840819270526),
 (&#39;lively&#39;, 1.829499797210902),
 (&#39;frank&#39;, 1.824549292051046),
 (&#39;enjoyable&#39;, 1.8235316282283922),
 (&#39;thanks&#39;, 1.8229030505963937),
 (&#39;prime&#39;, 1.818606719264243),
 (&#39;west&#39;, 1.8159737273486496),
 (&#39;equiped&#39;, 1.8144877203056111),
 (&#39;sightseeing&#39;, 1.8112195427827673),
 (&#39;furnished&#39;, 1.8108076641987494),
 (&#39;cdg&#39;, 1.8055527913603908),
 (&#39;brill&#39;, 1.80280930541464),
 (&#39;kings&#39;, 1.802341578558592),
 (&#39;newly&#39;, 1.7982487846678048),
 (&#39;stops&#39;, 1.7937475414534412),
 (&#39;supportive&#39;, 1.791759469228055),
 (&#39;destinations&#39;, 1.791759469228055),
 (&#39;boats&#39;, 1.791759469228055),
 (&#39;centrally&#39;, 1.7881297011774764),
 (&#39;arch&#39;, 1.7863686205931786),
 (&#39;canary&#39;, 1.7845392212545679),
 (&#39;efficiency&#39;, 1.784324490740537),
 (&#39;cordial&#39;, 1.7829488395459),
 (&#39;highlight&#39;, 1.7788560643921472),
 (&#39;trendy&#39;, 1.7785142424780345),
 (&#39;close&#39;, 1.7780856885349015),
 (&#39;science&#39;, 1.7730673362159026),
 (&#39;south&#39;, 1.7705272491222808),
 (&#39;o2&#39;, 1.7702260216179322),
 (&#39;market&#39;, 1.7699931927461003),
 (&#39;smart&#39;, 1.7672037799706113),
 (&#39;subway&#39;, 1.7660425812229255),
 (&#39;sweets&#39;, 1.765557096834031),
 (&#39;central&#39;, 1.7651105878418878),
 (&#39;wharf&#39;, 1.7649669522314801),
 (&#39;pantry&#39;, 1.7643604950399405),
 (&#39;50m&#39;, 1.7600107709134747),
 (&#39;fountain&#39;, 1.7594986070098335),
 (&#39;smiling&#39;, 1.758753172759885),
 (&#39;languages&#39;, 1.7578579175523736),
 (&#39;est&#39;, 1.75539182505718),
 (&#39;beach&#39;, 1.7547857185154034),
 (&#39;buses&#39;, 1.7537443782265814),
 (&#39;celebrate&#39;, 1.7537320736388158),
 (&#39;helpfully&#39;, 1.7443572303334711),
 (&#39;library&#39;, 1.7346010553881064),
 (&#39;atmosphere&#39;, 1.7264615969064594),
 (&#39;personable&#39;, 1.7206635475443246),
 (&#39;de&#39;, 1.716101925995371),
 (&#39;pauls&#39;, 1.7125100975739145),
 (&#39;theater&#39;, 1.7122952978738082),
 (&#39;gallery&#39;, 1.7104138297741025),
 (&#39;gatwick&#39;, 1.7086928705294415),
 (&#39;centraal&#39;, 1.7076763520175138),
 (&#39;transport&#39;, 1.7046451321353742),
 (&#39;supermarket&#39;, 1.7034037048524318),
 (&#39;diagonal&#39;, 1.7018112325651154),
 (&#39;5mins&#39;, 1.7016083722337574),
 (&#39;beat&#39;, 1.6966943574313285),
 (&#39;boyfriends&#39;, 1.6952992030404928),
 (&#39;200m&#39;, 1.6945957207744073),
 (&#39;jubilee&#39;, 1.6933193964148026),
 (&#39;eager&#39;, 1.6916760106710724),
 (&#39;rembrandt&#39;, 1.6916760106710724),
 (&#39;remarkable&#39;, 1.6885752329928243),
 (&#39;sunset&#39;, 1.6885752329928243),
 (&#39;good&#39;, 1.6860959826709392),
 (&#39;visiting&#39;, 1.6843392206072183),
 (&#39;willingness&#39;, 1.6843392206072183),
 (&#39;ace&#39;, 1.6817585740137264),
 (&#39;unlimited&#39;, 1.6724127115954888),
 (&#39;george&#39;, 1.6711314814394402),
 (&#39;birthday&#39;, 1.6692258308130736),
 (&#39;plenty&#39;, 1.6663648179965942),
 (&#39;welcome&#39;, 1.6603691060460284),
 (&#39;styled&#39;, 1.6554230256759237),
 (&#39;speedy&#39;, 1.6514021115331325),
 (&#39;remembered&#39;, 1.6506808709681495),
 (&#39;cinema&#39;, 1.6471782404169475),
 (&#39;le&#39;, 1.64696035175719),
 (&#39;jazz&#39;, 1.6458055566049752),
 (&#39;magic&#39;, 1.6451559950361796),
 (&#39;tesco&#39;, 1.6382860667717587),
 (&#39;flower&#39;, 1.6324274306587991),
 (&#39;milano&#39;, 1.6311778990705061),
 (&#39;genuinely&#39;, 1.6304281883259362),
 (&#39;arranging&#39;, 1.6299164437776412),
 (&#39;chelsea&#39;, 1.6288559982912019),
 (&#39;garden&#39;, 1.6283245790525467),
 (&#39;underground&#39;, 1.6255240501857247),
 (&#39;crisp&#39;, 1.6251040291784997),
 (&#39;tapas&#39;, 1.622860932766241),
 (&#39;interesting&#39;, 1.6224300707277532),
 (&#39;touch&#39;, 1.620843212262114),
 (&#39;celebrating&#39;, 1.6204877486206852),
 (&#39;harbour&#39;, 1.6201907042103623),
 (&#39;del&#39;, 1.6199092123013956),
 (&#39;famous&#39;, 1.6177367152487956),
 (&#39;venues&#39;, 1.616818019731723),
 (&#39;definately&#39;, 1.6166408247281583),
 (&#39;walking&#39;, 1.61626567005127),
 (&#39;lancaster&#39;, 1.6160824551527688),
 (&#39;situated&#39;, 1.6157902426147719),
 (&#39;hill&#39;, 1.6143041020852733),
 (&#39;interiors&#39;, 1.612101029853584),
 (&#39;bond&#39;, 1.6094379124341003),
 (&#39;joy&#39;, 1.6094379124341003),
 (&#39;airports&#39;, 1.6094379124341003),
 (&#39;professionalism&#39;, 1.6059836775660128),
 (&#39;presented&#39;, 1.6043831417724763),
 (&#39;reasonable&#39;, 1.601405740736836),
 (&#39;district&#39;, 1.5959013267165671),
 (&#39;sized&#39;, 1.5949774261030463),
 (&#39;staff&#39;, 1.5938070907212465),
 (&#39;rose&#39;, 1.5920461697222312),
 (&#39;hospitable&#39;, 1.590019826576999),
 (&#39;waterloo&#39;, 1.5885312276147867),
 (&#39;comfort&#39;, 1.5857117665320422),
 (&#39;transports&#39;, 1.575536360758419),
 (&#39;canal&#39;, 1.5754136387848958),
 (&#39;design&#39;, 1.5735241319237332),
 (&#39;skyline&#39;, 1.573505903208037),
 (&#39;eateries&#39;, 1.5718999931150353),
 (&#39;smartphone&#39;, 1.5712166996139025),
 (&#39;zuid&#39;, 1.5664205273504097),
 (&#39;transportation&#39;, 1.5562853054563666),
 (&#39;staf&#39;, 1.5553706911638245),
 (&#39;smiley&#39;, 1.5494948764670669),
 (&#39;wimbledon&#39;, 1.5493339883643948),
 (&#39;rai&#39;, 1.547562508716013),
 (&#39;recommended&#39;, 1.5440928645908993),
 (&#39;plush&#39;, 1.5425436776040702),
 (&#39;cheery&#39;, 1.540445040947149),
 (&#39;deco&#39;, 1.539516966634595),
 (&#39;notting&#39;, 1.5353299402803786),
 (&#39;mile&#39;, 1.5351220184582344),
 (&#39;citizenm&#39;, 1.534714366238164),
 (&#39;comprehensive&#39;, 1.5301885407799598),
 (&#39;touring&#39;, 1.5298852807321466),
 (&#39;shoreditch&#39;, 1.5227695297884265),
 (&#39;connections&#39;, 1.5216989981260935),
 (&#39;located&#39;, 1.5200982456848795),
 (&#39;patient&#39;, 1.519825753744413),
 (&#39;discreet&#39;, 1.5173226235262947),
 (&#39;styling&#39;, 1.5079014932146777),
 (&#39;relaxing&#39;, 1.5070099501975518),
 (&#39;hesitation&#39;, 1.5064386729619539),
 (&#39;el&#39;, 1.4987723445465808),
 (&#39;within&#39;, 1.4978565369011716),
 (&#39;zoo&#39;, 1.4947750041139605),
 (&#39;touristic&#39;, 1.4932664806720584),
 (&#39;confort&#39;, 1.4894785973551214),
 (&#39;tours&#39;, 1.4855925821021712),
 (&#39;affordable&#39;, 1.4837927256047683),
 (&#39;anniversary&#39;, 1.482349419915826),
 (&#39;circle&#39;, 1.4816045409242156),
 (&#39;staffs&#39;, 1.4810216204763482),
 (&#39;bus&#39;, 1.4806738455634652),
 (&#39;hip&#39;, 1.4759065198095778),
 (&#39;vienna&#39;, 1.4739999415389962),
 (&#39;locations&#39;, 1.4699085011610242),
 (&#39;pleasing&#39;, 1.4685324593568627),
 (&#39;la&#39;, 1.4678516468943923),
 (&#39;fun&#39;, 1.466337068793427),
 (&#39;concierges&#39;, 1.4619317753255106),
 (&#39;lake&#39;, 1.4610179073158271),
 (&#39;xx&#39;, 1.4604023332736125),
 (&#39;touristy&#39;, 1.4593194961347804),
 (&#39;rue&#39;, 1.4586150226995167),
 (&#39;definitely&#39;, 1.4579130923623482),
 (&#39;prosecco&#39;, 1.455287232606842),
 (&#39;faulted&#39;, 1.455287232606842),
 (&#39;attentiveness&#39;, 1.4539530095937054),
 (&#39;welcomed&#39;, 1.453258148380061),
 (&#39;train&#39;, 1.4508405565895073),
 (&#39;near&#39;, 1.4501985496175398),
 (&#39;ensured&#39;, 1.4469189829363254),
 (&#39;ms&#39;, 1.4469189829363254),
 (&#39;victorian&#39;, 1.4403615823901663),
 (&#39;barcelona&#39;, 1.436994413880989),
 (&#39;marco&#39;, 1.4350845252893227),
 (&#39;perfectly&#39;, 1.4342228276918414),
 (&#39;catalonia&#39;, 1.4335472459704361),
 (&#39;rainfall&#39;, 1.4271163556401458),
 (&#39;printing&#39;, 1.42529651892316),
 (&#39;catered&#39;, 1.420943496533065),
 (&#39;nicest&#39;, 1.4204273674893493),
 (&#39;lives&#39;, 1.4198170531585343),
 (&#39;cafes&#39;, 1.4184072122370093),
 (&#39;minute&#39;, 1.4131140169563776),
 (&#39;books&#39;, 1.4131056185705473),
 (&#39;exhibition&#39;, 1.4092838793445894),
 (&#39;les&#39;, 1.4081134085145304),
 (&#39;kitchenette&#39;, 1.405342556090585),
 (&#39;creative&#39;, 1.405342556090585),
 (&#39;environment&#39;, 1.400346114575541),
 (&#39;bustling&#39;, 1.3971052772241064),
 (&#39;malpensa&#39;, 1.3962446919730587),
 (&#39;church&#39;, 1.3951833085371366),
 (&#39;impressive&#39;, 1.3935495320010627),
 (&#39;queries&#39;, 1.3915994133495837),
 (&#39;quick&#39;, 1.3905370488586806),
 (&#39;upscale&#39;, 1.3862943611198906),
 (&#39;boulevard&#39;, 1.3862943611198906),
 (&#39;waterfall&#39;, 1.3862943611198906),
 (&#39;linate&#39;, 1.3862943611198906),
 (&#39;river&#39;, 1.3813117897754268),
 (&#39;fast&#39;, 1.3799931430431616),
 (&#39;champagne&#39;, 1.3738718411213333),
 (&#39;ideal&#39;, 1.36939411125513),
 (&#39;mr&#39;, 1.3682758556172123),
 (&#39;tram&#39;, 1.3677358988006378),
 (&#39;ultra&#39;, 1.3672461661491961),
 (&#39;gentle&#39;, 1.3639886036055924),
 (&#39;vast&#39;, 1.3609765531356006),
 (&#39;cooperative&#39;, 1.3581234841531944),
 (&#39;responsive&#39;, 1.3548310916641055),
 (&#39;class&#39;, 1.3514005565673164),
 (&#39;suggestions&#39;, 1.3512030413086205),
 (&#39;pleasent&#39;, 1.3507876726629808),
 (&#39;beyond&#39;, 1.3491033327938105),
 (&#39;genuine&#39;, 1.3444472511843901),
 (&#39;greeted&#39;, 1.343514020511036),
 (&#39;cakes&#39;, 1.341936508489493),
 (&#39;dam&#39;, 1.3397743454849977),
 (&#39;willing&#39;, 1.3392489974298367),
 (&#39;rd&#39;, 1.3339263756025748),
 (&#39;avenue&#39;, 1.3322271398496148),
 (&#39;enormous&#39;, 1.3315438463484823),
 (&#39;lines&#39;, 1.3298802718397993),
 (&#39;organic&#39;, 1.32818673031261),
 (&#39;land&#39;, 1.3277981544382822),
 (&#39;bars&#39;, 1.3270943627315683),
 (&#39;accommodations&#39;, 1.3236587901284056),
 (&#39;assisted&#39;, 1.3217558399823195),
 (&#39;recommend&#39;, 1.3206113225355545),
 (&#39;respectful&#39;, 1.3173014896329391),
 (&#39;magazines&#39;, 1.3156767939059373),
 (&#39;large&#39;, 1.314045701556352),
 (&#39;getaway&#39;, 1.3105825393841943),
 (&#39;tour&#39;, 1.3077040865266691),
 (&#39;best&#39;, 1.3057768049244303),
 (&#39;nespresso&#39;, 1.3017592544835241),
 (&#39;considerate&#39;, 1.3011365527795837),
 (&#39;cruise&#39;, 1.2992829841302609),
 (&#39;disappoint&#39;, 1.2992829841302609),
 (&#39;atmospheric&#39;, 1.2992829841302609),
 (&#39;attraction&#39;, 1.2981459743431858),
 (&#39;smooth&#39;, 1.2980537276755313),
 (&#39;traditional&#39;, 1.2964904662585874),
 (&#39;parisian&#39;, 1.2950456896547455),
 (&#39;politeness&#39;, 1.294356865794205),
 (&#39;wishing&#39;, 1.2934006142271943),
 (&#39;milan&#39;, 1.2932725577683495),
 (&#39;busses&#39;, 1.2878542883066382),
 (&#39;honeymoon&#39;, 1.2863090909865718),
 (&#39;express&#39;, 1.284976588479023),
 (&#39;recently&#39;, 1.279913957561319),
 (&#39;40th&#39;, 1.278080776479658),
 (&#39;artwork&#39;, 1.2770950691548986),
 (&#39;decent&#39;, 1.2763571784346526),
 (&#39;vintage&#39;, 1.2755429968271879),
 (&#39;port&#39;, 1.2722757827189497),
 (&#39;enthusiastic&#39;, 1.2718840099421465),
 (&#39;trouble&#39;, 1.2698617645613786),
 (&#39;10min&#39;, 1.267953133989343),
 (&#39;definetly&#39;, 1.264933504115623),
 (&#39;surprises&#39;, 1.2636920390275583),
 (&#39;square&#39;, 1.262829491996076),
 (&#39;perfection&#39;, 1.252762968495368),
 (&#39;golden&#39;, 1.252762968495368),
 (&#39;designer&#39;, 1.2484245668967697),
 (&#39;cleanness&#39;, 1.2469388402093793),
 (&#39;cleanliness&#39;, 1.2443691763668994),
 (&#39;thoroughly&#39;, 1.2431935174792172),
 (&#39;truly&#39;, 1.2390953297667042),
 (&#39;railway&#39;, 1.238427708408986),
 (&#39;faultless&#39;, 1.2359244041325383),
 (&#39;walk&#39;, 1.233534866715915),
 (&#39;surprisingly&#39;, 1.2312104101096337),
 (&#39;team&#39;, 1.2283118726312037),
 (&#39;plaza&#39;, 1.2237754316221157),
 (&#39;venue&#39;, 1.2237754316221157),
 (&#39;tips&#39;, 1.2237754316221157),
 (&#39;concept&#39;, 1.2230209992966306),
 (&#39;boat&#39;, 1.2222913848496206),
 (&#39;tickets&#39;, 1.2178975437944293),
 (&#39;rooftop&#39;, 1.217805264635612),
 (&#39;gift&#39;, 1.21700230461627),
 (&#39;cocktails&#39;, 1.2127255954355307),
 (&#39;decorations&#39;, 1.2100151187818986),
 (&#39;walks&#39;, 1.2091541630679337),
 (&#39;min&#39;, 1.2028758834292992),
 (&#39;freshly&#39;, 1.2026020021921573),
 (&#39;apples&#39;, 1.202332114868476),
 (&#39;style&#39;, 1.201953475787453),
 (&#39;wishes&#39;, 1.199964782928397),
 (&#39;blocks&#39;, 1.1979105096503901),
 (&#39;tourist&#39;, 1.1973938332278935),
 (&#39;comforts&#39;, 1.1968043148473233),
 (&#39;varied&#39;, 1.1936100172903894),
 (&#39;visit&#39;, 1.1894043884976455),
 (&#39;dlr&#39;, 1.1887633856624071),
 (&#39;posh&#39;, 1.1851527449991661),
 (&#39;docklands&#39;, 1.1837700970084166),
 (&#39;tennis&#39;, 1.1786549963416462),
 (&#39;happily&#39;, 1.1761158498229698),
 (&#39;cleaness&#39;, 1.1749852674526837),
 (&#39;features&#39;, 1.1727202608218317),
 (&#39;hospitality&#39;, 1.1707341628502022),
 (&#39;transit&#39;, 1.170585788293199),
 (&#39;interior&#39;, 1.1666540246654518),
 (&#39;terminal&#39;, 1.1655065234981399),
 (&#39;personnel&#39;, 1.1654935380872489),
 (&#39;buzz&#39;, 1.1645702564599072),
 (&#39;surroundings&#39;, 1.1645310722746391),
 (&#39;riverside&#39;, 1.1611326456494435),
 (&#39;def&#39;, 1.1592369104845446),
 (&#39;ferry&#39;, 1.1576208417962197),
 (&#39;pleased&#39;, 1.1561167831483008),
 (&#39;attractive&#39;, 1.1515346901224521),
 (&#39;recommending&#39;, 1.149503895964499),
 (&#39;intimate&#39;, 1.149384614041533),
 (&#39;houses&#39;, 1.148622709242771),
 (&#39;amsterdam&#39;, 1.1468499865419481),
 (&#39;newspapers&#39;, 1.1451323043030026),
 (&#39;gadgets&#39;, 1.1430640512389434),
 (&#39;guided&#39;, 1.1378330018213911),
 (&#39;hub&#39;, 1.1349799328389845),
 (&#39;marble&#39;, 1.1340696005048392),
 (&#39;wide&#39;, 1.1337344236959361),
 (&#39;commute&#39;, 1.133098464739279),
 (&#39;flawless&#39;, 1.132513840343791),
 (&#39;reachable&#39;, 1.1322288994670946),
 (&#39;recomend&#39;, 1.1322288994670946),
 (&#39;appreciated&#39;, 1.1315118267800361),
 (&#39;kind&#39;, 1.1268733003863205),
 (&#39;john&#39;, 1.1249295969854831),
 (&#39;assortment&#39;, 1.122142786078304),
 (&#39;character&#39;, 1.1211484536905227),
 (&#39;excellence&#39;, 1.1198896871153945),
 (&#39;tech&#39;, 1.1192315758708453),
 (&#39;upgraded&#39;, 1.118831335721416),
 (&#39;underfloor&#39;, 1.1180303745252111),
 (&#39;cuisine&#39;, 1.1169614273363062),
 (&#39;breads&#39;, 1.1162338900179292),
 (&#39;30th&#39;, 1.1148728095398899),
 (&#39;overground&#39;, 1.1130010261202095),
 (&#39;17th&#39;, 1.1118575154181303),
 (&#39;metros&#39;, 1.1113513144455394),
 (&#39;assisting&#39;, 1.110882381259924),
 (&#39;designed&#39;, 1.110139793839177),
 (&#39;gig&#39;, 1.1073459686368643),
 (&#39;sweet&#39;, 1.1065646168586047),
 (&#39;silence&#39;, 1.1059923959657323),
 (&#39;metres&#39;, 1.1059115911497213),
 (&#39;value&#39;, 1.1054229611094646),
 (&#39;lots&#39;, 1.1048987934309307),
 (&#39;flowers&#39;, 1.0986122886681098),
 (&#39;everthing&#39;, 1.0986122886681098),
 (&#39;piano&#39;, 1.0986122886681098),
 (&#39;reccomend&#39;, 1.0986122886681098),
 (&#39;games&#39;, 1.0986122886681098),
 (&#39;paris&#39;, 1.0912849392907822),
 (&#39;charm&#39;, 1.0900285449767182),
 (&#39;well&#39;, 1.089934626216377),
 (&#39;london&#39;, 1.0876310372351607),
 (&#39;definite&#39;, 1.0870514662670339),
 (&#39;accessibility&#39;, 1.0868474470885232),
 (&#39;greeting&#39;, 1.0858325620217109),
 (&#39;bargain&#39;, 1.0826119473216687),
 (&#39;celebration&#39;, 1.0818051703517284),
 (&#39;san&#39;, 1.0813704822336037),
 (&#39;penny&#39;, 1.0785111093470223),
 (&#39;decor&#39;, 1.076886015345732),
 (&#39;terrace&#39;, 1.075628986894004),
 (&#39;theme&#39;, 1.07238127651924),
 (&#39;friendliest&#39;, 1.0704414117014134),
 (&#39;provides&#39;, 1.0647107369924282),
 (&#39;seeing&#39;, 1.0608719606852626),
 (&#39;linens&#39;, 1.0605124424358392),
 (&#39;accommodated&#39;, 1.0547604061392601),
 (&#39;crowds&#39;, 1.051544777810124),
 (&#39;neighborhood&#39;, 1.0509686944694996),
 (&#39;engaging&#39;, 1.0414538748281612),
 (&#39;chocolate&#39;, 1.039613947906154),
 (&#39;attending&#39;, 1.0392256389865981),
 (&#39;cons&#39;, 1.039188868197309),
 (&#39;everything&#39;, 1.0384125696290407),
 (&#39;honesty&#39;, 1.0376515888784226),
 (&#39;15th&#39;, 1.0352426747355203),
 (&#39;stop&#39;, 1.0341785132603754),
 (&#39;amenities&#39;, 1.0331030956107412),
 (&#39;bikes&#39;, 1.0278432177799024),
 (&#39;bakery&#39;, 1.0277862360994972),
 (&#39;spec&#39;, 1.0271533246859648),
 (&#39;15min&#39;, 1.0261572094526874),
 (&#39;classical&#39;, 1.0258529343856813),
 (&#39;michelin&#39;, 1.0252810155825602),
 (&#39;wow&#39;, 1.0228184492985761),
 (&#39;surprise&#39;, 1.0195858881915805),
 (&#39;justice&#39;, 1.0147308046874077),
 (&#39;loads&#39;, 1.0146123142553714),
 (&#39;cross&#39;, 1.0124888797699767),
 (&#39;boarding&#39;, 1.0116009116784799),
 (&#39;viennese&#39;, 1.0116009116784799),
 (&#39;airport&#39;, 1.0095939109803127),
 (&#39;spot&#39;, 1.009371256351211),
 (&#39;concert&#39;, 1.008966635312445),
 (&#39;british&#39;, 1.0062808069154452),
 (&#39;bloomsbury&#39;, 1.0055218656020977),
 (&#39;deck&#39;, 1.0045833390198333),
 (&#39;sparkling&#39;, 1.0044250736084086),
 (&#39;huge&#39;, 1.0033268732921612),
 (&#39;nibbles&#39;, 1.0033021088637848),
 (&#39;mood&#39;, 1.002845383576101),
 (&#39;doorman&#39;, 1.001985452979038),
 (&#39;wherever&#39;, 1.001448540214462),
 (&#39;nightlife&#39;, 1.0011139241832319),
 (&#39;grateful&#39;, 1.0003738490846965),
 (&#39;02&#39;, 1.0002672051686308),
 (&#39;50th&#39;, 0.9985288301111273),
 (&#39;beauty&#39;, 0.9963334395476915),
 (&#39;brand&#39;, 0.9960194185057014),
 (&#39;porters&#39;, 0.9926637106587292),
 (&#39;neighbourhood&#39;, 0.9919062893506337),
 (&#39;inexpensive&#39;, 0.990398704027877),
 (&#39;tastes&#39;, 0.9899784476653143),
 (&#39;rare&#39;, 0.987599759578937),
 (&#39;gate&#39;, 0.9808292530117262),
 (&#39;bicycles&#39;, 0.9808292530117262),
 (&#39;maintained&#39;, 0.9801364923328255),
 (&#39;starbucks&#39;, 0.9780782196398363),
 (&#39;cheeses&#39;, 0.9772514316638422),
 (&#39;360&#39;, 0.9772514316638422),
 (&#39;courtesy&#39;, 0.974998332700933),
 (&#39;grand&#39;, 0.9744862212542925),
 (&#39;helped&#39;, 0.9744662300685875),
 (&#39;sea&#39;, 0.9723185633438176),
 (&#39;muffins&#39;, 0.9718605830289658),
 (&#39;hoxton&#39;, 0.9694005571881035),
 (&#39;city&#39;, 0.9664068630886908),
 (&#39;centre&#39;, 0.9651127477420816),
 (&#39;east&#39;, 0.9633156705190179),
 (&#39;professionally&#39;, 0.958523495497428),
 (&#39;engaged&#39;, 0.9578397347870274),
 (&#39;right&#39;, 0.9573963741058568),
 (&#39;catching&#39;, 0.9555114450274363),
 (&#39;supper&#39;, 0.9555114450274363),
 (&#39;secure&#39;, 0.9547181090080405),
 (&#39;treat&#39;, 0.9505239035163974),
 (&#39;tubes&#39;, 0.9478850972923722),
 (&#39;helping&#39;, 0.9466618297504538),
 (&#39;decoration&#39;, 0.9444616088408515),
 (&#39;spread&#39;, 0.9435746908226235),
 (&#39;ports&#39;, 0.9426080401915286),
 (&#39;snacks&#39;, 0.9424430373036036),
 (&#39;special&#39;, 0.9421763544520381),
 (&#39;sight&#39;, 0.9394440368488719),
 (&#39;short&#39;, 0.9378907198441778),
 (&#39;public&#39;, 0.9375014571583892),
 (&#39;concierge&#39;, 0.9354040281074755),
 (&#39;detail&#39;, 0.9326626947435865),
 (&#39;camp&#39;, 0.931994123802605),
 (&#39;link&#39;, 0.9306794693262548),
 (&#39;college&#39;, 0.9295359586241757),
 (&#39;cleaniness&#39;, 0.9287132518727123),
 (&#39;y&#39;, 0.9284612674944103),
 (&#39;partners&#39;, 0.9270849770050356),
 (&#39;wines&#39;, 0.9111493323737364),
 (&#39;personel&#39;, 0.9106674743197929),
 (&#39;tons&#39;, 0.9075570519054004),
 (&#39;mayfair&#39;, 0.9071582483108824),
 (&#39;convention&#39;, 0.9071582483108824),
 (&#39;umbrella&#39;, 0.9044562742271522),
 (&#39;amazed&#39;, 0.903711949667295),
 (&#39;including&#39;, 0.9036199970534771),
 (&#39;exceedingly&#39;, 0.9028677115420144),
 (&#39;18th&#39;, 0.9019019944220555),
 (&#39;eye&#39;, 0.900693535060487),
 (&#39;range&#39;, 0.8992448646011665),
 (&#39;importantly&#39;, 0.8991962985148549),
 (&#39;rental&#39;, 0.8991229282517897),
 (&#39;extremely&#39;, 0.8973696467599976),
 (&#39;useful&#39;, 0.8963338758178616),
 (&#39;fruits&#39;, 0.8915981192837835),
 (&#39;et&#39;, 0.8873031950009027),
 (&#39;big&#39;, 0.8856948311640399),
 (&#39;downtown&#39;, 0.88560899722167),
 (&#39;minded&#39;, 0.8838873078194958),
 (&#39;kindly&#39;, 0.8838052767296668),
 (&#39;14th&#39;, 0.8835009090511642),
 (&#39;assist&#39;, 0.8825437994488784),
 (&#39;romantic&#39;, 0.8822027695352441),
 (&#39;various&#39;, 0.8804633963279904),
 (&#39;12th&#39;, 0.8799230877032802),
 (&#39;gladly&#39;, 0.8797331361403574),
 (&#39;diverse&#39;, 0.8770700187208738),
 (&#39;town&#39;, 0.875723546885155),
 (&#39;breakfasts&#39;, 0.8750224084020585),
 (&#39;accessible&#39;, 0.8744110957957645),
 (&#39;access&#39;, 0.8734289062746033),
 (&#39;kinds&#39;, 0.8727327575350252),
 (&#39;very&#39;, 0.8720478638061469),
 (&#39;home&#39;, 0.8692026957752536),
 (&#39;austrian&#39;, 0.868351269585036),
 (&#39;maps&#39;, 0.8675005677047231),
 (&#39;yards&#39;, 0.8649974374866045),
 (&#39;smoothly&#39;, 0.8649974374866045),
 (&#39;meters&#39;, 0.8639314529490354),
 (&#39;nearby&#39;, 0.8628458767756885),
 (&#39;interest&#39;, 0.8627499649461252),
 (&#39;sushi&#39;, 0.8602012652231116),
 (&#39;skylounge&#39;, 0.8602012652231116),
 (&#39;bike&#39;, 0.8574502318512216),
 (&#39;ritz&#39;, 0.8574502318512216),
 (&#39;culture&#39;, 0.8574502318512216),
 (&#39;ratio&#39;, 0.857035035665062),
 (&#39;sooo&#39;, 0.8567766043417474),
 (&#39;luxury&#39;, 0.8553399699232861),
 (&#39;chill&#39;, 0.8430873278508602),
 (&#39;surrounded&#39;, 0.8429921486759917),
 (&#39;urban&#39;, 0.8404718953168039),
 (&#39;restored&#39;, 0.8383291904044432),
 (&#39;residential&#39;, 0.8375098540210407),
 (&#39;strand&#39;, 0.837396789404492),
 (&#39;destination&#39;, 0.8367381001722013),
 (&#39;omelettes&#39;, 0.8362480242006185),
 (&#39;ride&#39;, 0.8358691645635807),
 (&#39;hammam&#39;, 0.8342257788198509),
 (&#39;japanese&#39;, 0.8340526336371831),
 (&#39;turkish&#39;, 0.8329091229351039),
 (&#39;blackout&#39;, 0.8324607929567358),
 (&#39;extensive&#39;, 0.8322599830226631),
 (&#39;meats&#39;, 0.8306769791511632),
 (&#39;laid&#39;, 0.826395727757607),
 (&#39;places&#39;, 0.8250612106368027),
 (&#39;highway&#39;, 0.8244831826210323),
 (&#39;foods&#39;, 0.822935162313152),
 (&#39;pure&#39;, 0.8215283472081522),
 (&#39;juices&#39;, 0.8191879014553103),
 (&#39;helps&#39;, 0.8183103235139513),
 (&#39;cocktail&#39;, 0.8140997909776078),
 (&#39;husbands&#39;, 0.8140997909776078),
 (&#39;moment&#39;, 0.8138046073876719),
 (&#39;centrum&#39;, 0.8135108628098204),
 (&#39;marathon&#39;, 0.8128116843160345),
 (&#39;10mins&#39;, 0.8109302162163288),
 (&#39;festival&#39;, 0.8109302162163288),
 (&#39;clever&#39;, 0.8109302162163288),
 (&#39;linen&#39;, 0.8016055183067048),
 (&#39;holland&#39;, 0.7972874398125424),
 (&#39;25th&#39;, 0.7969439742415889),
 (&#39;60th&#39;, 0.7969439742415889),
 (&#39;christmas&#39;, 0.7964062530908144),
 (&#39;liked&#39;, 0.7956792972252575),
 (&#39;purposes&#39;, 0.7939518796819108),
 (&#39;overlooking&#39;, 0.7931863001008034),
 (&#39;here&#39;, 0.7917426709719635),
 (&#39;microwave&#39;, 0.790349508516308),
 (&#39;bright&#39;, 0.7875099420082302),
 (&#39;trams&#39;, 0.7829324844323003),
 (&#39;refreshing&#39;, 0.7806064858885313),
 (&#39;doctor&#39;, 0.7777045685880083),
 (&#39;park&#39;, 0.7760402464578382),
 (&#39;north&#39;, 0.7757087812529657),
 (&#39;across&#39;, 0.7748443971466626),
 (&#39;easter&#39;, 0.7748252115742124),
 (&#39;center&#39;, 0.7743133936883122),
 (&#39;films&#39;, 0.7731898882334817),
 (&#39;selection&#39;, 0.7716951196442524),
 ...]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[65]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">list</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">pos_neg_ratios</span><span class="o">.</span><span class="n">most_common</span><span class="p">()))[</span><span class="mi">0</span><span class="p">:</span><span class="mi">30</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[65]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[(&#39;mouldy&#39;, -inf),
 (&#39;unusable&#39;, -5.19295685089021),
 (&#39;unstable&#39;, -4.757891273005756),
 (&#39;powdered&#39;, -4.68213122712422),
 (&#39;inappropriate&#39;, -4.663439094112067),
 (&#39;scratched&#39;, -4.269697449699962),
 (&#39;positive&#39;, -4.2036140943766425),
 (&#39;intermittent&#39;, -4.132496328186477),
 (&#39;sewer&#39;, -4.102643365036796),
 (&#39;flushed&#39;, -4.102643365036796),
 (&#39;repairs&#39;, -4.088773517172645),
 (&#39;vent&#39;, -4.038655656361512),
 (&#39;hopeless&#39;, -4.02535169073515),
 (&#39;skirting&#39;, -4.007333185232471),
 (&#39;damaged&#39;, -3.970291913552122),
 (&#39;loudly&#39;, -3.967592856582957),
 (&#39;untidy&#39;, -3.9415818076696905),
 (&#39;disorganised&#39;, -3.927896354584436),
 (&#39;leaked&#39;, -3.867722746531566),
 (&#39;unreliable&#39;, -3.801091444720864),
 (&#39;flushing&#39;, -3.801091444720864),
 (&#39;bins&#39;, -3.7992275112828016),
 (&#39;rudely&#39;, -3.784189633918261),
 (&#39;chipped&#39;, -3.7545334243353734),
 (&#39;unacceptable&#39;, -3.726401893437026),
 (&#39;torn&#39;, -3.7184382563554808),
 (&#39;patchy&#39;, -3.672072335797555),
 (&#39;mold&#39;, -3.66612246699132),
 (&#39;sewage&#39;, -3.6450768314555435),
 (&#39;erratic&#39;, -3.6375861597263857)]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[66]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">bokeh.models</span> <span class="k">import</span> <span class="n">ColumnDataSource</span><span class="p">,</span> <span class="n">LabelSet</span>
<span class="kn">from</span> <span class="nn">bokeh.plotting</span> <span class="k">import</span> <span class="n">figure</span><span class="p">,</span> <span class="n">show</span><span class="p">,</span> <span class="n">output_file</span>
<span class="kn">from</span> <span class="nn">bokeh.io</span> <span class="k">import</span> <span class="n">output_notebook</span>
<span class="n">output_notebook</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">

    <div class="bk-root">
        <a href="https://bokeh.pydata.org" target="_blank" class="bk-logo bk-logo-small bk-logo-notebook"></a>
        <span id="1001">Loading BokehJS ...</span>
    </div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>





<div id="0df630e1-6e23-42f0-a53f-df9d99f33e6a"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#0df630e1-6e23-42f0-a53f-df9d99f33e6a');

(function(root) {
  function now() {
    return new Date();
  }

  var force = true;

  if (typeof (root._bokeh_onload_callbacks) === "undefined" || force === true) {
    root._bokeh_onload_callbacks = [];
    root._bokeh_is_loading = undefined;
  }

  var JS_MIME_TYPE = 'application/javascript';
  var HTML_MIME_TYPE = 'text/html';
  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';
  var CLASS_NAME = 'output_bokeh rendered_html';

  /**
   * Render data to the DOM node
   */
  function render(props, node) {
    var script = document.createElement("script");
    node.appendChild(script);
  }

  /**
   * Handle when an output is cleared or removed
   */
  function handleClearOutput(event, handle) {
    var cell = handle.cell;

    var id = cell.output_area._bokeh_element_id;
    var server_id = cell.output_area._bokeh_server_id;
    // Clean up Bokeh references
    if (id != null && id in Bokeh.index) {
      Bokeh.index[id].model.document.clear();
      delete Bokeh.index[id];
    }

    if (server_id !== undefined) {
      // Clean up Bokeh references
      var cmd = "from bokeh.io.state import curstate; print(curstate().uuid_to_server['" + server_id + "'].get_sessions()[0].document.roots[0]._id)";
      cell.notebook.kernel.execute(cmd, {
        iopub: {
          output: function(msg) {
            var id = msg.content.text.trim();
            if (id in Bokeh.index) {
              Bokeh.index[id].model.document.clear();
              delete Bokeh.index[id];
            }
          }
        }
      });
      // Destroy server and session
      var cmd = "import bokeh.io.notebook as ion; ion.destroy_server('" + server_id + "')";
      cell.notebook.kernel.execute(cmd);
    }
  }

  /**
   * Handle when a new output is added
   */
  function handleAddOutput(event, handle) {
    var output_area = handle.output_area;
    var output = handle.output;

    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only
    if ((output.output_type != "display_data") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {
      return
    }

    var toinsert = output_area.element.find("." + CLASS_NAME.split(' ')[0]);

    if (output.metadata[EXEC_MIME_TYPE]["id"] !== undefined) {
      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];
      // store reference to embed id on output_area
      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE]["id"];
    }
    if (output.metadata[EXEC_MIME_TYPE]["server_id"] !== undefined) {
      var bk_div = document.createElement("div");
      bk_div.innerHTML = output.data[HTML_MIME_TYPE];
      var script_attrs = bk_div.children[0].attributes;
      for (var i = 0; i < script_attrs.length; i++) {
        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);
      }
      // store reference to server id on output_area
      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE]["server_id"];
    }
  }

  function register_renderer(events, OutputArea) {

    function append_mime(data, metadata, element) {
      // create a DOM node to render to
      var toinsert = this.create_output_subarea(
        metadata,
        CLASS_NAME,
        EXEC_MIME_TYPE
      );
      this.keyboard_manager.register_events(toinsert);
      // Render to node
      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};
      render(props, toinsert[toinsert.length - 1]);
      element.append(toinsert);
      return toinsert
    }

    /* Handle when an output is cleared or removed */
    events.on('clear_output.CodeCell', handleClearOutput);
    events.on('delete.Cell', handleClearOutput);

    /* Handle when a new output is added */
    events.on('output_added.OutputArea', handleAddOutput);

    /**
     * Register the mime type and append_mime function with output_area
     */
    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {
      /* Is output safe? */
      safe: true,
      /* Index of renderer in `output_area.display_order` */
      index: 0
    });
  }

  // register the mime type if in Jupyter Notebook environment and previously unregistered
  if (root.Jupyter !== undefined) {
    var events = require('base/js/events');
    var OutputArea = require('notebook/js/outputarea').OutputArea;

    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {
      register_renderer(events, OutputArea);
    }
  }

  
  if (typeof (root._bokeh_timeout) === "undefined" || force === true) {
    root._bokeh_timeout = Date.now() + 5000;
    root._bokeh_failed_load = false;
  }

  var NB_LOAD_WARNING = {'data': {'text/html':
     "<div style='background-color: #fdd'>\n"+
     "<p>\n"+
     "BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \n"+
     "may be due to a slow or bad network connection. Possible fixes:\n"+
     "</p>\n"+
     "<ul>\n"+
     "<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\n"+
     "<li>use INLINE resources instead, as so:</li>\n"+
     "</ul>\n"+
     "<code>\n"+
     "from bokeh.resources import INLINE\n"+
     "output_notebook(resources=INLINE)\n"+
     "</code>\n"+
     "</div>"}};

  function display_loaded() {
    var el = document.getElementById("1001");
    if (el != null) {
      el.textContent = "BokehJS is loading...";
    }
    if (root.Bokeh !== undefined) {
      if (el != null) {
        el.textContent = "BokehJS " + root.Bokeh.version + " successfully loaded.";
      }
    } else if (Date.now() < root._bokeh_timeout) {
      setTimeout(display_loaded, 100)
    }
  }


  function run_callbacks() {
    try {
      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });
    }
    finally {
      delete root._bokeh_onload_callbacks
    }
    console.info("Bokeh: all callbacks have finished");
  }

  function load_libs(js_urls, callback) {
    root._bokeh_onload_callbacks.push(callback);
    if (root._bokeh_is_loading > 0) {
      console.log("Bokeh: BokehJS is being loaded, scheduling callback at", now());
      return null;
    }
    if (js_urls == null || js_urls.length === 0) {
      run_callbacks();
      return null;
    }
    console.log("Bokeh: BokehJS not loaded, scheduling load and callback at", now());
    root._bokeh_is_loading = js_urls.length;
    for (var i = 0; i < js_urls.length; i++) {
      var url = js_urls[i];
      var s = document.createElement('script');
      s.src = url;
      s.async = false;
      s.onreadystatechange = s.onload = function() {
        root._bokeh_is_loading--;
        if (root._bokeh_is_loading === 0) {
          console.log("Bokeh: all BokehJS libraries loaded");
          run_callbacks()
        }
      };
      s.onerror = function() {
        console.warn("failed to load library " + url);
      };
      console.log("Bokeh: injecting script tag for BokehJS library: ", url);
      document.getElementsByTagName("head")[0].appendChild(s);
    }
  };var element = document.getElementById("1001");
  if (element == null) {
    console.log("Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. ")
    return false;
  }

  var js_urls = ["https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.js", "https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.js", "https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.js", "https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.2.min.js"];

  var inline_js = [
    function(Bokeh) {
      Bokeh.set_log_level("info");
    },
    
    function(Bokeh) {
      
    },
    function(Bokeh) {
      console.log("Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css");
      Bokeh.embed.inject_css("https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css");
      console.log("Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css");
      Bokeh.embed.inject_css("https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css");
      console.log("Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css");
      Bokeh.embed.inject_css("https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css");
    }
  ];

  function run_inline_js() {
    
    if ((root.Bokeh !== undefined) || (force === true)) {
      for (var i = 0; i < inline_js.length; i++) {
        inline_js[i].call(root, root.Bokeh);
      }if (force === true) {
        display_loaded();
      }} else if (Date.now() < root._bokeh_timeout) {
      setTimeout(run_inline_js, 100);
    } else if (!root._bokeh_failed_load) {
      console.log("Bokeh: BokehJS failed to load within specified timeout.");
      root._bokeh_failed_load = true;
    } else if (force !== true) {
      var cell = $(document.getElementById("1001")).parents('.cell').data().cell;
      cell.output_area.append_execute_result(NB_LOAD_WARNING)
    }

  }

  if (root._bokeh_is_loading === 0) {
    console.log("Bokeh: BokehJS loaded, going straight to plotting");
    run_inline_js();
  } else {
    load_libs(js_urls, function() {
      console.log("Bokeh: BokehJS plotting callback run at", now());
      run_inline_js();
    });
  }
}(window));
</script>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[68]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hist</span><span class="p">,</span> <span class="n">edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">pos_neg_ratios</span><span class="o">.</span><span class="n">most_common</span><span class="p">()[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])),</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">normed</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">figure</span><span class="p">(</span><span class="n">tools</span><span class="o">=</span><span class="s2">&quot;pan,wheel_zoom,reset,save&quot;</span><span class="p">,</span>
           <span class="n">toolbar_location</span><span class="o">=</span><span class="s2">&quot;above&quot;</span><span class="p">,</span>
           <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Word Positive/Negative Affinity Distribution&quot;</span><span class="p">)</span>
<span class="n">p</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">top</span><span class="o">=</span><span class="n">hist</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="n">edges</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">right</span><span class="o">=</span><span class="n">edges</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">line_color</span><span class="o">=</span><span class="s2">&quot;#555555&quot;</span><span class="p">)</span>
<span class="n">show</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\vaibh\Anaconda3x\lib\site-packages\ipykernel_launcher.py:1: DeprecationWarning: The normed argument is ignored when density is provided. In future passing both will result in an error.
  &#34;&#34;&#34;Entry point for launching an IPython kernel.
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">






  <div class="bk-root" id="8325ec45-fa62-4fed-bb91-36f1ae8cd875"></div>

</div>

</div>

<div class="output_area">

    <div class="prompt"></div>





<div id="6e6aac62-a868-4443-b26b-737c158860c3"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#6e6aac62-a868-4443-b26b-737c158860c3');
(function(root) {
  function embed_document(root) {
    
  var docs_json = {"5d84ff73-897d-403d-a19d-5e01fb2534ba":{"roots":{"references":[{"attributes":{"below":[{"id":"1013","type":"LinearAxis"}],"left":[{"id":"1018","type":"LinearAxis"}],"renderers":[{"id":"1013","type":"LinearAxis"},{"id":"1017","type":"Grid"},{"id":"1018","type":"LinearAxis"},{"id":"1022","type":"Grid"},{"id":"1035","type":"GlyphRenderer"}],"title":{"id":"1002","type":"Title"},"toolbar":{"id":"1027","type":"Toolbar"},"toolbar_location":"above","x_range":{"id":"1005","type":"DataRange1d"},"x_scale":{"id":"1009","type":"LinearScale"},"y_range":{"id":"1007","type":"DataRange1d"},"y_scale":{"id":"1011","type":"LinearScale"}},"id":"1003","subtype":"Figure","type":"Plot"},{"attributes":{"plot":{"id":"1003","subtype":"Figure","type":"Plot"},"ticker":{"id":"1014","type":"BasicTicker"}},"id":"1017","type":"Grid"},{"attributes":{"formatter":{"id":"1041","type":"BasicTickFormatter"},"plot":{"id":"1003","subtype":"Figure","type":"Plot"},"ticker":{"id":"1019","type":"BasicTicker"}},"id":"1018","type":"LinearAxis"},{"attributes":{},"id":"1019","type":"BasicTicker"},{"attributes":{"dimension":1,"plot":{"id":"1003","subtype":"Figure","type":"Plot"},"ticker":{"id":"1019","type":"BasicTicker"}},"id":"1022","type":"Grid"},{"attributes":{"callback":null,"data":{"left":{"__ndarray__":"TnMQe5bFFMBMagmT1WEUwElhAqsU/hPAR1j7wlOaE8BET/TakjYTwEJG7fLR0hLAQD3mChFvEsA9NN8iUAsSwDsr2DqPpxHAOSLRUs5DEcA2GcpqDeAQwDQQw4JMfBDAMge8mosYEMBe/GlllWkPwFrqW5UTog7AVdhNxZHaDcBQxj/1DxMNwEu0MSWOSwzARqIjVQyEC8BCkBWFirwKwD1+B7UI9QnAOGz55IYtCcA0WusUBWYIwC9I3USDngfAKjbPdAHXBsAlJMGkfw8GwCASs9T9RwXAHAClBHyABMAX7pY0+rgDwBLciGR48QLADsp6lPYpAsAJuGzEdGIBwASmXvTymgDA/iehSOKm/7/0A4Wo3hf+v+zfaAjbiPy/4rtMaNf5+r/YlzDI02r5v9BzFCjQ2/e/xk/4h8xM9r+8K9znyL30v7IHwEfFLvO/qOOjp8Gf8b+gv4cHvhDwvzA31850A+2/GO+ejm3l6b8Ip2ZOZsfmv/BeLg5fqeO/4Bb2zVeL4L+gnXsbodrav3ANC5uSntS/oPo0NQjFzL9A2lM060zAvwDQlZtxpp6/gMzcmp1GsT+ghk/OaxvFP3BTmGfEydA/kOMI6NIF1z/Ac3lo4UHdP/ABdfT3vuE/AEqtNP/c5D8YkuV0BvvnPyjaHbUNGes/QCJW9RQ37j8oNccajqrwPzBZ47qROfI/PH3/WpXI8z9EoRv7mFf1P1DFN5uc5vY/WOlTO6B1+D9gDXDbowT6P2wxjHunk/s/dFWoG6si/T98ecS7rrH+P8RO8C1ZIABAyGD+/drnAEDMcgzOXK8BQNKEGp7edgJA1pYobmA+A0DcqDY+4gUEQOC6RA5kzQRA5MxS3uWUBUDq3mCuZ1wGQPDwbn7pIwdA9AJ9TmvrB0D4FIse7bIIQPwmme5ueglAADmnvvBBCkAES7WOcgkLQAxdw1700AtAEG/RLnaYDEAUgd/+918NQBiT7c55Jw5AHKX7nvvuDkAktwlvfbYPQJTki5//PhBAlu2Sh8CiEECY9plvgQYRQJr/oFdCahFAngioPwPOEUA=","dtype":"float64","shape":[100]},"right":{"__ndarray__":"TGoJk9VhFMBJYQKrFP4TwEdY+8JTmhPARE/02pI2E8BCRu3y0dISwEA95goRbxLAPTTfIlALEsA7K9g6j6cRwDki0VLOQxHANhnKag3gEMA0EMOCTHwQwDIHvJqLGBDAXvxpZZVpD8Ba6luVE6IOwFXYTcWR2g3AUMY/9Q8TDcBLtDEljksMwEaiI1UMhAvAQpAVhYq8CsA9fge1CPUJwDhs+eSGLQnANFrrFAVmCMAvSN1Eg54HwCo2z3QB1wbAJSTBpH8PBsAgErPU/UcFwBwApQR8gATAF+6WNPq4A8AS3IhkePECwA7KepT2KQLACbhsxHRiAcAEpl708poAwP4noUjipv+/9AOFqN4X/r/s32gI24j8v+K7TGjX+fq/2JcwyNNq+b/QcxQo0Nv3v8ZP+IfMTPa/vCvc58i99L+yB8BHxS7zv6jjo6fBn/G/oL+HB74Q8L8wN9fOdAPtvxjvno5t5em/CKdmTmbH5r/wXi4OX6njv+AW9s1Xi+C/oJ17G6Ha2r9wDQubkp7Uv6D6NDUIxcy/QNpTNOtMwL8A0JWbcaaev4DM3JqdRrE/oIZPzmsbxT9wU5hnxMnQP5DjCOjSBdc/wHN5aOFB3T/wAXX0977hPwBKrTT/3OQ/GJLldAb75z8o2h21DRnrP0AiVvUUN+4/KDXHGo6q8D8wWeO6kTnyPzx9/1qVyPM/RKEb+5hX9T9QxTebnOb2P1jpUzugdfg/YA1w26ME+j9sMYx7p5P7P3RVqBurIv0/fHnEu66x/j/ETvAtWSAAQMhg/v3a5wBAzHIMzlyvAUDShBqe3nYCQNaWKG5gPgNA3Kg2PuIFBEDgukQOZM0EQOTMUt7llAVA6t5grmdcBkDw8G5+6SMHQPQCfU5r6wdA+BSLHu2yCED8JpnubnoJQAA5p77wQQpABEu1jnIJC0AMXcNe9NALQBBv0S52mAxAFIHf/vdfDUAYk+3OeScOQByl+5777g5AJLcJb322D0CU5Iuf/z4QQJbtkofAohBAmPaZb4EGEUCa/6BXQmoRQJ4IqD8DzhFAoBGvJ8QxEkA=","dtype":"float64","shape":[100]},"top":{"__ndarray__":"tqleVpeKYT8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC2qV5Wl4phP7apXlaXinE/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAialeVpeKYT+2qV5Wl4pxPyNU9is97YU/61P2Kz3thT+2qV5Wl4phPwdU9is97YU/2Kgl14iyjj/YqCXXiLKOPzspwhaQHpg//6gl14iyjj+iPlyh5gWnP6I+XKHmBac/LOnzdoxoqz+fqV5Wl4qxP+2eERHsFrI/IXTd+z5ItD9uaZC2k9S0Pzt03fs+SLQ/o9NZ7DWBvD9StKubQv7AP5+Jd4aVL8M/4A4eKWvpwj96+YOeFALEP9N+KkHqu8M/yYM0pLgJyj9bKcIWkB7IP3yOgeljfck/L5nOLg/xyD9bKcIWkB7IP6w5Uj4YuNA/APf+bC3b0D/H7jZZaY7UP+Q4Gb8J4M0/QTzXb//e0z+ZwX0S1ZjTP8gOHilr6dI/Y+yxJ4Jn0T8ilMTLQKPSP6VRcfpVxtI/+A4eKWvp0j/p9v5sLdvQP9/zQLw33Mo/r6gl14iyzj9j7LEngmfRPw8vBflsRNE/tRMojDk3yT963qYx4fTLP78+XKHmBcc/61P2Kz3txT87dN37PkjEP9ZeQ3HoYMU/1p4REewWwj8PLwX5bETBP9aeERHsFsI/n4l3hpUvwz9MntiR3T6/P+bo83aMaLs/LOnzdoxouz8dKcIWkB64P1spwhaQHrg/LOnzdoxouz+EPlyh5gW3P78+XKHmBbc/vz5coeYFtz9TaZC2k9S0P4hpkLaT1LQ/1l5DcehgtT+6fipB6ruzPwSfERHsFrI/SZOLTDLLrz9kvr9h35mtP+1+KkHqu6M/HSnCFpAeqD+vqCXXiLKuP1KUxMtAo6I/x9NZ7DWBnD+R/o0B40+aP1spwhaQHpg/tqleVpeKkT+IfipB6ruTP5H+jQHjT3o/tqleVpeKcT+2qV5Wl4pxPwAAAAAAAAAAAAAAAAAAAAC2qV5Wl4qBP7apXlaXimE/AAAAAAAAAAAAAAAAAAAAAFypXlaXimE/tqleVpeKYT8=","dtype":"float64","shape":[100]}},"selected":{"id":"1042","type":"Selection"},"selection_policy":{"id":"1043","type":"UnionRenderers"}},"id":"1032","type":"ColumnDataSource"},{"attributes":{},"id":"1023","type":"PanTool"},{"attributes":{"bottom":{"value":0},"fill_color":{"value":"#1f77b4"},"left":{"field":"left"},"line_color":{"value":"#555555"},"right":{"field":"right"},"top":{"field":"top"}},"id":"1033","type":"Quad"},{"attributes":{},"id":"1024","type":"WheelZoomTool"},{"attributes":{},"id":"1025","type":"ResetTool"},{"attributes":{"plot":null,"text":"Word Positive/Negative Affinity Distribution"},"id":"1002","type":"Title"},{"attributes":{},"id":"1026","type":"SaveTool"},{"attributes":{"active_drag":"auto","active_inspect":"auto","active_multi":null,"active_scroll":"auto","active_tap":"auto","tools":[{"id":"1023","type":"PanTool"},{"id":"1024","type":"WheelZoomTool"},{"id":"1025","type":"ResetTool"},{"id":"1026","type":"SaveTool"}]},"id":"1027","type":"Toolbar"},{"attributes":{"data_source":{"id":"1032","type":"ColumnDataSource"},"glyph":{"id":"1033","type":"Quad"},"hover_glyph":null,"muted_glyph":null,"nonselection_glyph":{"id":"1034","type":"Quad"},"selection_glyph":null,"view":{"id":"1036","type":"CDSView"}},"id":"1035","type":"GlyphRenderer"},{"attributes":{"callback":null},"id":"1007","type":"DataRange1d"},{"attributes":{"callback":null},"id":"1005","type":"DataRange1d"},{"attributes":{"source":{"id":"1032","type":"ColumnDataSource"}},"id":"1036","type":"CDSView"},{"attributes":{"bottom":{"value":0},"fill_alpha":{"value":0.1},"fill_color":{"value":"#1f77b4"},"left":{"field":"left"},"line_alpha":{"value":0.1},"line_color":{"value":"#1f77b4"},"right":{"field":"right"},"top":{"field":"top"}},"id":"1034","type":"Quad"},{"attributes":{},"id":"1039","type":"BasicTickFormatter"},{"attributes":{},"id":"1009","type":"LinearScale"},{"attributes":{},"id":"1041","type":"BasicTickFormatter"},{"attributes":{},"id":"1011","type":"LinearScale"},{"attributes":{},"id":"1042","type":"Selection"},{"attributes":{"formatter":{"id":"1039","type":"BasicTickFormatter"},"plot":{"id":"1003","subtype":"Figure","type":"Plot"},"ticker":{"id":"1014","type":"BasicTicker"}},"id":"1013","type":"LinearAxis"},{"attributes":{},"id":"1043","type":"UnionRenderers"},{"attributes":{},"id":"1014","type":"BasicTicker"}],"root_ids":["1003"]},"title":"Bokeh Application","version":"1.0.2"}};
  var render_items = [{"docid":"5d84ff73-897d-403d-a19d-5e01fb2534ba","roots":{"1003":"8325ec45-fa62-4fed-bb91-36f1ae8cd875"}}];
  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);

  }
  if (root.Bokeh !== undefined) {
    embed_document(root);
  } else {
    var attempts = 0;
    var timer = setInterval(function(root) {
      if (root.Bokeh !== undefined) {
        embed_document(root);
        clearInterval(timer);
      }
      attempts++;
      if (attempts > 100) {
        console.log("Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing");
        clearInterval(timer);
      }
    }, 10, root)
  }
})(window);
</script>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[69]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">frequency_frequency</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>

<span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">cnt</span> <span class="ow">in</span> <span class="n">total_counts</span><span class="o">.</span><span class="n">most_common</span><span class="p">():</span>
    <span class="n">frequency_frequency</span><span class="p">[</span><span class="n">cnt</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[70]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hist</span><span class="p">,</span> <span class="n">edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">frequency_frequency</span><span class="o">.</span><span class="n">most_common</span><span class="p">())),</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">normed</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">figure</span><span class="p">(</span><span class="n">tools</span><span class="o">=</span><span class="s2">&quot;pan,wheel_zoom,reset,save&quot;</span><span class="p">,</span>
           <span class="n">toolbar_location</span><span class="o">=</span><span class="s2">&quot;above&quot;</span><span class="p">,</span>
           <span class="n">title</span><span class="o">=</span><span class="s2">&quot;The frequency distribution of the words in our corpus&quot;</span><span class="p">)</span>
<span class="n">p</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">top</span><span class="o">=</span><span class="n">hist</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="n">edges</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">right</span><span class="o">=</span><span class="n">edges</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">line_color</span><span class="o">=</span><span class="s2">&quot;#555555&quot;</span><span class="p">)</span>
<span class="n">show</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\vaibh\Anaconda3x\lib\site-packages\ipykernel_launcher.py:1: DeprecationWarning: The normed argument is ignored when density is provided. In future passing both will result in an error.
  &#34;&#34;&#34;Entry point for launching an IPython kernel.
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">






  <div class="bk-root" id="89499f8f-4d05-4d8a-9bb8-8b3c45a467b7"></div>

</div>

</div>

<div class="output_area">

    <div class="prompt"></div>





<div id="0820f0c3-9bba-4e38-9166-3d4d05498a1d"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#0820f0c3-9bba-4e38-9166-3d4d05498a1d');
(function(root) {
  function embed_document(root) {
    
  var docs_json = {"1256e7e5-da70-4cff-8daa-41c0f369f979":{"roots":{"references":[{"attributes":{"below":[{"id":"1097","type":"LinearAxis"}],"left":[{"id":"1102","type":"LinearAxis"}],"renderers":[{"id":"1097","type":"LinearAxis"},{"id":"1101","type":"Grid"},{"id":"1102","type":"LinearAxis"},{"id":"1106","type":"Grid"},{"id":"1119","type":"GlyphRenderer"}],"title":{"id":"1086","type":"Title"},"toolbar":{"id":"1111","type":"Toolbar"},"toolbar_location":"above","x_range":{"id":"1089","type":"DataRange1d"},"x_scale":{"id":"1093","type":"LinearScale"},"y_range":{"id":"1091","type":"DataRange1d"},"y_scale":{"id":"1095","type":"LinearScale"}},"id":"1087","subtype":"Figure","type":"Plot"},{"attributes":{"plot":null,"text":"The frequency distribution of the words in our corpus"},"id":"1086","type":"Title"},{"attributes":{"callback":null,"data":{"left":{"__ndarray__":"AAAAAAAA8D8zMzMzM4d6QDMzMzMzf4pAZmZmZmbdk0AzMzMzM3uaQAAAAACAjKBAZmZmZmbbo0DNzMzMTCqnQDMzMzMzeapAmZmZmRnIrUAAAAAAgIuwQDMzMzPzMrJAZmZmZmbas0CZmZmZ2YG1QM3MzMxMKbdAAAAAAMDQuEAzMzMzM3i6QGZmZmamH7xAmZmZmRnHvUDNzMzMjG6/QAAAAAAAi8BAmZmZmblewUAzMzMzczLCQM3MzMwsBsNAZmZmZubZw0AAAAAAoK3EQJmZmZlZgcVAMzMzMxNVxkDNzMzMzCjHQGZmZmaG/MdAAAAAAEDQyECZmZmZ+aPJQDMzMzOzd8pAzczMzGxLy0BmZmZmJh/MQAAAAADg8sxAmZmZmZnGzUAzMzMzU5rOQM3MzMwMbs9AMzMzM+Mg0EAAAAAAwIrQQM3MzMyc9NBAmZmZmXle0UBmZmZmVsjRQDMzMzMzMtJAAAAAABCc0kDNzMzM7AXTQJmZmZnJb9NAZmZmZqbZ00AzMzMzg0PUQAAAAABgrdRAzczMzDwX1UCZmZmZGYHVQGZmZmb26tVAMzMzM9NU1kAAAAAAsL7WQM3MzMyMKNdAmZmZmWmS10BmZmZmRvzXQDMzMzMjZthAAAAAAADQ2EDNzMzM3DnZQJmZmZm5o9lAZmZmZpYN2kAzMzMzc3faQAAAAABQ4dpAzczMzCxL20CZmZmZCbXbQGZmZmbmHtxAMzMzM8OI3EAAAAAAoPLcQM3MzMx8XN1AmZmZmVnG3UBmZmZmNjDeQDMzMzMTmt5AAAAAAPAD30DNzMzMzG3fQJmZmZmp199AMzMzM8Mg4ECZmZmZsVXgQAAAAACgiuBAZmZmZo6/4EDNzMzMfPTgQDMzMzNrKeFAmZmZmVle4UAAAAAASJPhQGZmZmY2yOFAzczMzCT94UAzMzMzEzLiQJmZmZkBZ+JAAAAAAPCb4kBmZmZm3tDiQM3MzMzMBeNAMzMzM7s640CZmZmZqW/jQAAAAACYpONAZmZmZobZ40DNzMzMdA7kQDMzMzNjQ+RAmZmZmVF45EA=","dtype":"float64","shape":[100]},"right":{"__ndarray__":"MzMzMzOHekAzMzMzM3+KQGZmZmZm3ZNAMzMzMzN7mkAAAAAAgIygQGZmZmZm26NAzczMzEwqp0AzMzMzM3mqQJmZmZkZyK1AAAAAAICLsEAzMzMz8zKyQGZmZmZm2rNAmZmZmdmBtUDNzMzMTCm3QAAAAADA0LhAMzMzMzN4ukBmZmZmph+8QJmZmZkZx71AzczMzIxuv0AAAAAAAIvAQJmZmZm5XsFAMzMzM3MywkDNzMzMLAbDQGZmZmbm2cNAAAAAAKCtxECZmZmZWYHFQDMzMzMTVcZAzczMzMwox0BmZmZmhvzHQAAAAABA0MhAmZmZmfmjyUAzMzMzs3fKQM3MzMxsS8tAZmZmZiYfzEAAAAAA4PLMQJmZmZmZxs1AMzMzM1OazkDNzMzMDG7PQDMzMzPjINBAAAAAAMCK0EDNzMzMnPTQQJmZmZl5XtFAZmZmZlbI0UAzMzMzMzLSQAAAAAAQnNJAzczMzOwF00CZmZmZyW/TQGZmZmam2dNAMzMzM4ND1EAAAAAAYK3UQM3MzMw8F9VAmZmZmRmB1UBmZmZm9urVQDMzMzPTVNZAAAAAALC+1kDNzMzMjCjXQJmZmZlpktdAZmZmZkb810AzMzMzI2bYQAAAAAAA0NhAzczMzNw52UCZmZmZuaPZQGZmZmaWDdpAMzMzM3N32kAAAAAAUOHaQM3MzMwsS9tAmZmZmQm120BmZmZm5h7cQDMzMzPDiNxAAAAAAKDy3EDNzMzMfFzdQJmZmZlZxt1AZmZmZjYw3kAzMzMzE5reQAAAAADwA99AzczMzMxt30CZmZmZqdffQDMzMzPDIOBAmZmZmbFV4EAAAAAAoIrgQGZmZmaOv+BAzczMzHz04EAzMzMzaynhQJmZmZlZXuFAAAAAAEiT4UBmZmZmNsjhQM3MzMwk/eFAMzMzMxMy4kCZmZmZAWfiQAAAAADwm+JAZmZmZt7Q4kDNzMzMzAXjQDMzMzO7OuNAmZmZmalv40AAAAAAmKTjQGZmZmaG2eNAzczMzHQO5EAzMzMzY0PkQJmZmZlReORAAAAAAECt5EA=","dtype":"float64","shape":[100]},"top":{"__ndarray__":"3uYXk3s2Yz+U2k5IlzDdPrmRNDC6dcM+uJE0MLp1sz64kTQwunWzPgAAAAAAAAAAAAAAAAAAAAC7kTQwunWzPgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALuRNDC6dbM+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACvkTQwunWzPgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAf5E0MLp1sz4=","dtype":"float64","shape":[100]}},"selected":{"id":"1133","type":"Selection"},"selection_policy":{"id":"1134","type":"UnionRenderers"}},"id":"1116","type":"ColumnDataSource"},{"attributes":{},"id":"1108","type":"WheelZoomTool"},{"attributes":{},"id":"1107","type":"PanTool"},{"attributes":{},"id":"1133","type":"Selection"},{"attributes":{},"id":"1130","type":"BasicTickFormatter"},{"attributes":{"bottom":{"value":0},"fill_color":{"value":"#1f77b4"},"left":{"field":"left"},"line_color":{"value":"#555555"},"right":{"field":"right"},"top":{"field":"top"}},"id":"1117","type":"Quad"},{"attributes":{"dimension":1,"plot":{"id":"1087","subtype":"Figure","type":"Plot"},"ticker":{"id":"1103","type":"BasicTicker"}},"id":"1106","type":"Grid"},{"attributes":{"data_source":{"id":"1116","type":"ColumnDataSource"},"glyph":{"id":"1117","type":"Quad"},"hover_glyph":null,"muted_glyph":null,"nonselection_glyph":{"id":"1118","type":"Quad"},"selection_glyph":null,"view":{"id":"1120","type":"CDSView"}},"id":"1119","type":"GlyphRenderer"},{"attributes":{"bottom":{"value":0},"fill_alpha":{"value":0.1},"fill_color":{"value":"#1f77b4"},"left":{"field":"left"},"line_alpha":{"value":0.1},"line_color":{"value":"#1f77b4"},"right":{"field":"right"},"top":{"field":"top"}},"id":"1118","type":"Quad"},{"attributes":{},"id":"1098","type":"BasicTicker"},{"attributes":{"active_drag":"auto","active_inspect":"auto","active_multi":null,"active_scroll":"auto","active_tap":"auto","tools":[{"id":"1107","type":"PanTool"},{"id":"1108","type":"WheelZoomTool"},{"id":"1109","type":"ResetTool"},{"id":"1110","type":"SaveTool"}]},"id":"1111","type":"Toolbar"},{"attributes":{"plot":{"id":"1087","subtype":"Figure","type":"Plot"},"ticker":{"id":"1098","type":"BasicTicker"}},"id":"1101","type":"Grid"},{"attributes":{},"id":"1110","type":"SaveTool"},{"attributes":{},"id":"1132","type":"BasicTickFormatter"},{"attributes":{"formatter":{"id":"1132","type":"BasicTickFormatter"},"plot":{"id":"1087","subtype":"Figure","type":"Plot"},"ticker":{"id":"1103","type":"BasicTicker"}},"id":"1102","type":"LinearAxis"},{"attributes":{},"id":"1103","type":"BasicTicker"},{"attributes":{"source":{"id":"1116","type":"ColumnDataSource"}},"id":"1120","type":"CDSView"},{"attributes":{"formatter":{"id":"1130","type":"BasicTickFormatter"},"plot":{"id":"1087","subtype":"Figure","type":"Plot"},"ticker":{"id":"1098","type":"BasicTicker"}},"id":"1097","type":"LinearAxis"},{"attributes":{},"id":"1095","type":"LinearScale"},{"attributes":{},"id":"1109","type":"ResetTool"},{"attributes":{},"id":"1093","type":"LinearScale"},{"attributes":{},"id":"1134","type":"UnionRenderers"},{"attributes":{"callback":null},"id":"1091","type":"DataRange1d"},{"attributes":{"callback":null},"id":"1089","type":"DataRange1d"}],"root_ids":["1087"]},"title":"Bokeh Application","version":"1.0.2"}};
  var render_items = [{"docid":"1256e7e5-da70-4cff-8daa-41c0f369f979","roots":{"1087":"89499f8f-4d05-4d8a-9bb8-8b3c45a467b7"}}];
  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);

  }
  if (root.Bokeh !== undefined) {
    embed_document(root);
  } else {
    var attempts = 0;
    var timer = setInterval(function(root) {
      if (root.Bokeh !== undefined) {
        embed_document(root);
        clearInterval(timer);
      }
      attempts++;
      if (attempts > 100) {
        console.log("Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing");
        clearInterval(timer);
      }
    }, 10, root)
  }
})(window);
</script>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[71]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Encapsulate our neural network in a class</span>
<span class="k">class</span> <span class="nc">SentimentNetwork</span><span class="p">:</span>
    <span class="c1">## added min_count and polarity_cutoff parameters</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reviews</span><span class="p">,</span><span class="n">labels</span><span class="p">,</span><span class="n">min_count</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span><span class="n">polarity_cutoff</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span><span class="n">hidden_nodes</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create a SentimenNetwork with the given settings</span>
<span class="sd">        Args:</span>
<span class="sd">            reviews(list) - List of reviews used for training</span>
<span class="sd">            labels(list) - List of POSITIVE/NEGATIVE labels associated with the given reviews</span>
<span class="sd">            min_count(int) - Words should only be added to the vocabulary </span>
<span class="sd">                             if they occur more than this many times</span>
<span class="sd">            polarity_cutoff(float) - The absolute value of a word&#39;s positive-to-negative</span>
<span class="sd">                                     ratio must be at least this big to be considered.</span>
<span class="sd">            hidden_nodes(int) - Number of nodes to create in the hidden layer</span>
<span class="sd">            learning_rate(float) - Learning rate to use while training</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Assign a seed to our random number generator to ensure we get</span>
        <span class="c1"># reproducable results during development </span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># process the reviews and their associated labels so that everything</span>
        <span class="c1"># is ready for training</span>
        <span class="c1">## added min_count and polarity_cutoff arguments to pre_process_data call</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_process_data</span><span class="p">(</span><span class="n">reviews</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">polarity_cutoff</span><span class="p">,</span> <span class="n">min_count</span><span class="p">)</span>
        
        <span class="c1"># Build the network to have the number of hidden nodes and the learning rate that</span>
        <span class="c1"># were passed into this initializer. Make the same number of input nodes as</span>
        <span class="c1"># there are vocabulary words and create a single output node.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_network</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">review_vocab</span><span class="p">),</span><span class="n">hidden_nodes</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>

    <span class="c1">##  added min_count and polarity_cutoff parameters</span>
    <span class="k">def</span> <span class="nf">pre_process_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reviews</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">polarity_cutoff</span><span class="p">,</span> <span class="n">min_count</span><span class="p">):</span>
        
        <span class="c1">## ----------------------------------------</span>
        <span class="c1">## Calculate positive-to-negative ratios for words before</span>
        <span class="c1">#                     building vocabulary</span>
        <span class="c1">#</span>
        <span class="n">positive_counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
        <span class="n">negative_counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
        <span class="n">total_counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">reviews</span><span class="p">)):</span>
            <span class="k">if</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">reviews</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
                    <span class="n">positive_counts</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">total_counts</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">reviews</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
                    <span class="n">negative_counts</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">total_counts</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">pos_neg_ratios</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">term</span><span class="p">,</span><span class="n">cnt</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">total_counts</span><span class="o">.</span><span class="n">most_common</span><span class="p">()):</span>
            <span class="k">if</span><span class="p">(</span><span class="n">cnt</span> <span class="o">&gt;=</span> <span class="mi">50</span><span class="p">):</span>
                <span class="n">pos_neg_ratio</span> <span class="o">=</span> <span class="n">positive_counts</span><span class="p">[</span><span class="n">term</span><span class="p">]</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">negative_counts</span><span class="p">[</span><span class="n">term</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">pos_neg_ratios</span><span class="p">[</span><span class="n">term</span><span class="p">]</span> <span class="o">=</span> <span class="n">pos_neg_ratio</span>

        <span class="k">for</span> <span class="n">word</span><span class="p">,</span><span class="n">ratio</span> <span class="ow">in</span> <span class="n">pos_neg_ratios</span><span class="o">.</span><span class="n">most_common</span><span class="p">():</span>
            <span class="k">if</span><span class="p">(</span><span class="n">ratio</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
                <span class="n">pos_neg_ratios</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">ratio</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">pos_neg_ratios</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">ratio</span> <span class="o">+</span> <span class="mf">0.01</span><span class="p">)))</span>
        <span class="c1">#</span>
        <span class="c1">## </span>
        <span class="c1">## ----------------------------------------</span>

        <span class="c1"># populate review_vocab with all of the words in the given reviews</span>
        <span class="n">review_vocab</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">review</span> <span class="ow">in</span> <span class="n">reviews</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">review</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
                <span class="c1">## only add words that occur at least min_count times</span>
                <span class="c1">#                     and for words with pos/neg ratios, only add words</span>
                <span class="c1">#                     that meet the polarity_cutoff</span>
                <span class="k">if</span><span class="p">(</span><span class="n">total_counts</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">min_count</span><span class="p">):</span>
                    <span class="k">if</span><span class="p">(</span><span class="n">word</span> <span class="ow">in</span> <span class="n">pos_neg_ratios</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
                        <span class="k">if</span><span class="p">((</span><span class="n">pos_neg_ratios</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">polarity_cutoff</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">pos_neg_ratios</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="o">-</span><span class="n">polarity_cutoff</span><span class="p">)):</span>
                            <span class="n">review_vocab</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">review_vocab</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

        <span class="c1"># Convert the vocabulary set to a list so we can access words via indices</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">review_vocab</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">review_vocab</span><span class="p">)</span>
        
        <span class="c1"># populate label_vocab with all of the words in the given labels.</span>
        <span class="n">label_vocab</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">:</span>
            <span class="n">label_vocab</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
        
        <span class="c1"># Convert the label vocabulary set to a list so we can access labels via indices</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_vocab</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">label_vocab</span><span class="p">)</span>
        
        <span class="c1"># Store the sizes of the review and label vocabularies.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">review_vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">review_vocab</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_vocab</span><span class="p">)</span>
        
        <span class="c1"># Create a dictionary of words in the vocabulary mapped to index positions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">review_vocab</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
        
        <span class="c1"># Create a dictionary of labels mapped to index positions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label2index</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_vocab</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">label2index</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>

    <span class="k">def</span> <span class="nf">init_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_nodes</span><span class="p">,</span> <span class="n">hidden_nodes</span><span class="p">,</span> <span class="n">output_nodes</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
        <span class="c1"># Set number of nodes in input, hidden and output layers.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_nodes</span> <span class="o">=</span> <span class="n">input_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_nodes</span> <span class="o">=</span> <span class="n">hidden_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_nodes</span> <span class="o">=</span> <span class="n">output_nodes</span>

        <span class="c1"># Store the learning rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>

        <span class="c1"># Initialize weights</span>

        <span class="c1"># These are the weights between the input layer and the hidden layer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_0_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">input_nodes</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_nodes</span><span class="p">))</span>

        <span class="c1"># These are the weights between the hidden layer and the output layer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_1_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_nodes</span><span class="o">**-</span><span class="mf">0.5</span><span class="p">,</span> 
                                                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_nodes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_nodes</span><span class="p">))</span>
        
        <span class="c1">##  Removed self.layer_0; added self.layer_1</span>
        <span class="c1"># The input layer, a two-dimensional matrix with shape 1 x hidden_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">hidden_nodes</span><span class="p">))</span>
    
    <span class="c1">## Removed update_input_layer function</span>
    
    <span class="k">def</span> <span class="nf">get_target_for_label</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">label</span><span class="p">):</span>
        <span class="k">if</span><span class="p">(</span><span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">return</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
        
    <span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">sigmoid_output_2_derivative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">output</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">output</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">output</span><span class="p">)</span>
    
    <span class="c1">## changed name of first parameter form &#39;training_reviews&#39; </span>
    <span class="c1">#                     to &#39;training_reviews_raw&#39;</span>
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_reviews_raw</span><span class="p">,</span> <span class="n">training_labels</span><span class="p">):</span>

        <span class="c1">##  pre-process training reviews so we can deal </span>
        <span class="c1">#                     directly with the indices of non-zero inputs</span>
        <span class="n">training_reviews</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">review</span> <span class="ow">in</span> <span class="n">training_reviews_raw</span><span class="p">:</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">review</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
                <span class="k">if</span><span class="p">(</span><span class="n">word</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
                    <span class="n">indices</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">])</span>
            <span class="n">training_reviews</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">indices</span><span class="p">))</span>

        <span class="c1"># make sure out we have a matching number of reviews and labels</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">training_reviews</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">training_labels</span><span class="p">))</span>
        
        <span class="c1"># Keep track of correct predictions to display accuracy during training </span>
        <span class="n">correct_so_far</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Remember when we started for printing time statistics</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        
        <span class="c1"># loop through all the given reviews and run a forward and backward pass,</span>
        <span class="c1"># updating weights for every item</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">training_reviews</span><span class="p">)):</span>
            
            <span class="c1"># Get the next review and its correct label</span>
            <span class="n">review</span> <span class="o">=</span> <span class="n">training_reviews</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">label</span> <span class="o">=</span> <span class="n">training_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            
            <span class="c1">#### Implement the forward pass here ####</span>
            <span class="c1">### Forward pass ###</span>

            <span class="c1">## Removed call to &#39;update_input_layer&#39; function</span>
            <span class="c1">#                     because &#39;layer_0&#39; is no longer used</span>

            <span class="c1"># Hidden layer</span>
            <span class="c1">## Add in only the weights for non-zero items</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layer_1</span> <span class="o">*=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">review</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">layer_1</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_0_1</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

            <span class="c1"># Output layer</span>
            <span class="c1">## changed to use &#39;self.layer_1&#39; instead of &#39;local layer_1&#39;</span>
            <span class="n">layer_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_1_2</span><span class="p">))</span>            
            
            <span class="c1">#### Implement the backward pass here ####</span>
            <span class="c1">### Backward pass ###</span>

            <span class="c1"># Output error</span>
            <span class="n">layer_2_error</span> <span class="o">=</span> <span class="n">layer_2</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_target_for_label</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="c1"># Output layer error is the difference between desired target and actual output.</span>
            <span class="n">layer_2_delta</span> <span class="o">=</span> <span class="n">layer_2_error</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid_output_2_derivative</span><span class="p">(</span><span class="n">layer_2</span><span class="p">)</span>

            <span class="c1"># Backpropagated error</span>
            <span class="n">layer_1_error</span> <span class="o">=</span> <span class="n">layer_2_delta</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_1_2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="c1"># errors propagated to the hidden layer</span>
            <span class="n">layer_1_delta</span> <span class="o">=</span> <span class="n">layer_1_error</span> <span class="c1"># hidden layer gradients - no nonlinearity so it&#39;s the same as the error</span>

            <span class="c1"># Update the weights</span>
            <span class="c1">## changed to use &#39;self.layer_1&#39; instead of local &#39;layer_1&#39;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights_1_2</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_1</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">layer_2_delta</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="c1"># update hidden-to-output weights with gradient descent step</span>
            
            <span class="c1">##: Only update the weights that were used in the forward pass</span>
            <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">review</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">weights_0_1</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">-=</span> <span class="n">layer_1_delta</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="c1"># update input-to-hidden weights with gradient descent step</span>

            <span class="c1"># Keep track of correct predictions.</span>
            <span class="k">if</span><span class="p">(</span><span class="n">layer_2</span> <span class="o">&gt;=</span> <span class="mf">0.5</span> <span class="ow">and</span> <span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
                <span class="n">correct_so_far</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">elif</span><span class="p">(</span><span class="n">layer_2</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">and</span> <span class="n">label</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                <span class="n">correct_so_far</span> <span class="o">+=</span> <span class="mi">1</span>
            
            <span class="c1"># For debug purposes, print out our prediction accuracy and speed </span>
            <span class="c1"># throughout the training process. </span>
            <span class="n">elapsed_time</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>
            <span class="n">reviews_per_second</span> <span class="o">=</span> <span class="n">i</span> <span class="o">/</span> <span class="n">elapsed_time</span> <span class="k">if</span> <span class="n">elapsed_time</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
            
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">Progress:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">i</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">training_reviews</span><span class="p">)))[:</span><span class="mi">4</span><span class="p">]</span> \
                             <span class="o">+</span> <span class="s2">&quot;% Speed(reviews/sec):&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">reviews_per_second</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span> \
                             <span class="o">+</span> <span class="s2">&quot; #Correct:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">correct_so_far</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; #Trained:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> \
                             <span class="o">+</span> <span class="s2">&quot; Training Accuracy:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">correct_so_far</span> <span class="o">*</span> <span class="mi">100</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))[:</span><span class="mi">4</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;%&quot;</span><span class="p">)</span>
            <span class="k">if</span><span class="p">(</span><span class="n">i</span> <span class="o">%</span> <span class="mi">2500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">testing_reviews</span><span class="p">,</span> <span class="n">testing_labels</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Attempts to predict the labels for the given testing_reviews,</span>
<span class="sd">        and uses the test_labels to calculate the accuracy of those predictions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="c1"># keep track of how many correct predictions we make</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># we&#39;ll time how many predictions per second we make</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="c1"># Loop through each of the given reviews and call run to predict</span>
        <span class="c1"># its label. </span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">testing_reviews</span><span class="p">)):</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">testing_reviews</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="k">if</span><span class="p">(</span><span class="n">pred</span> <span class="o">==</span> <span class="n">testing_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span>
                <span class="n">correct</span> <span class="o">+=</span> <span class="mi">1</span>
            
            <span class="c1"># For debug purposes, print out our prediction accuracy and speed </span>
            <span class="c1"># throughout the prediction process. </span>

            <span class="n">elapsed_time</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>
            <span class="n">reviews_per_second</span> <span class="o">=</span> <span class="n">i</span> <span class="o">/</span> <span class="n">elapsed_time</span> <span class="k">if</span> <span class="n">elapsed_time</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
            
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">Progress:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">i</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">testing_reviews</span><span class="p">)))[:</span><span class="mi">4</span><span class="p">]</span> \
                             <span class="o">+</span> <span class="s2">&quot;% Speed(reviews/sec):&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">reviews_per_second</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span> \
                             <span class="o">+</span> <span class="s2">&quot; #Correct:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">correct</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; #Tested:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> \
                             <span class="o">+</span> <span class="s2">&quot; Testing Accuracy:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">correct</span> <span class="o">*</span> <span class="mi">100</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))[:</span><span class="mi">4</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;%&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">review</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a POSITIVE or NEGATIVE prediction for the given review.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Run a forward pass through the network, like in the &quot;train&quot; function.</span>
        
        <span class="c1">##  Removed call to update_input_layer function</span>
        <span class="c1">#                     because layer_0 is no longer used</span>

        <span class="c1"># Hidden layer</span>
        <span class="c1">##Identify the indices used in the review and then add</span>
        <span class="c1">#                     just those weights to layer_1 </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_1</span> <span class="o">*=</span> <span class="mi">0</span>
        <span class="n">unique_indices</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">review</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">unique_indices</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">unique_indices</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layer_1</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_0_1</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        
        <span class="c1"># Output layer</span>
        <span class="c1">##  changed to use self.layer_1 instead of local layer_1</span>
        <span class="n">layer_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_1_2</span><span class="p">))</span>
         
        <span class="c1"># Return POSITIVE for values above greater-than-or-equal-to 0.5 in the output layer;</span>
        <span class="c1"># return NEGATIVE for other values</span>
        <span class="k">if</span><span class="p">(</span><span class="n">layer_2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">):</span>
            <span class="k">return</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mlp</span> <span class="o">=</span> <span class="n">SentimentNetwork</span><span class="p">(</span><span class="n">reviews</span><span class="p">[:</span><span class="o">-</span><span class="mi">103000</span><span class="p">],</span><span class="n">labels</span><span class="p">[:</span><span class="o">-</span><span class="mi">103000</span><span class="p">],</span><span class="n">min_count</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">polarity_cutoff</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">mlp</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">reviews</span><span class="p">[:</span><span class="o">-</span><span class="mi">103000</span><span class="p">],</span><span class="n">labels</span><span class="p">[:</span><span class="o">-</span><span class="mi">103000</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Progress:0.0% Speed(reviews/sec):0 #Correct:1 #Trained:1 Training Accuracy:100.%
Progress:0.26% Speed(reviews/sec):6410. #Correct:2497 #Trained:2501 Training Accuracy:99.8%
Progress:0.53% Speed(reviews/sec):5690. #Correct:4980 #Trained:5001 Training Accuracy:99.5%
Progress:0.80% Speed(reviews/sec):5775. #Correct:7472 #Trained:7501 Training Accuracy:99.6%
Progress:1.07% Speed(reviews/sec):5582. #Correct:9962 #Trained:10001 Training Accuracy:99.6%
Progress:1.34% Speed(reviews/sec):5501. #Correct:12439 #Trained:12501 Training Accuracy:99.5%
Progress:1.61% Speed(reviews/sec):5371. #Correct:14935 #Trained:15001 Training Accuracy:99.5%
Progress:1.88% Speed(reviews/sec):5277. #Correct:17432 #Trained:17501 Training Accuracy:99.6%
Progress:2.15% Speed(reviews/sec):5316. #Correct:19929 #Trained:20001 Training Accuracy:99.6%
Progress:2.42% Speed(reviews/sec):5401. #Correct:22427 #Trained:22501 Training Accuracy:99.6%
Progress:2.69% Speed(reviews/sec):5396. #Correct:24926 #Trained:25001 Training Accuracy:99.7%
Progress:2.96% Speed(reviews/sec):5485. #Correct:27419 #Trained:27501 Training Accuracy:99.7%
Progress:3.23% Speed(reviews/sec):5515. #Correct:29912 #Trained:30001 Training Accuracy:99.7%
Progress:3.50% Speed(reviews/sec):5564. #Correct:32406 #Trained:32501 Training Accuracy:99.7%
Progress:3.77% Speed(reviews/sec):5548. #Correct:34902 #Trained:35001 Training Accuracy:99.7%
Progress:4.04% Speed(reviews/sec):5562. #Correct:37391 #Trained:37501 Training Accuracy:99.7%
Progress:4.31% Speed(reviews/sec):5535. #Correct:39889 #Trained:40001 Training Accuracy:99.7%
Progress:4.58% Speed(reviews/sec):5558. #Correct:42384 #Trained:42501 Training Accuracy:99.7%
Progress:4.85% Speed(reviews/sec):5548. #Correct:44875 #Trained:45001 Training Accuracy:99.7%
Progress:4.97% Speed(reviews/sec):5529. #Correct:45989 #Trained:46115 Training Accuracy:99.7%</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>IOPub data rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_data_rate_limit`.

Current values:
NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)
NotebookApp.rate_limit_window=3.0 (secs)

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Progress:5.66% Speed(reviews/sec):5508. #Correct:52358 #Trained:52501 Training Accuracy:99.7%
Progress:5.93% Speed(reviews/sec):5492. #Correct:54850 #Trained:55001 Training Accuracy:99.7%
Progress:6.19% Speed(reviews/sec):5492. #Correct:57346 #Trained:57501 Training Accuracy:99.7%
Progress:6.46% Speed(reviews/sec):5466. #Correct:59840 #Trained:60001 Training Accuracy:99.7%
Progress:6.73% Speed(reviews/sec):5490. #Correct:62333 #Trained:62501 Training Accuracy:99.7%
Progress:7.00% Speed(reviews/sec):5471. #Correct:64820 #Trained:65001 Training Accuracy:99.7%
Progress:7.27% Speed(reviews/sec):5513. #Correct:67279 #Trained:67501 Training Accuracy:99.6%
Progress:7.54% Speed(reviews/sec):5510. #Correct:69742 #Trained:70001 Training Accuracy:99.6%
Progress:7.81% Speed(reviews/sec):5496. #Correct:72230 #Trained:72501 Training Accuracy:99.6%
Progress:8.08% Speed(reviews/sec):5480. #Correct:74722 #Trained:75001 Training Accuracy:99.6%
Progress:8.35% Speed(reviews/sec):5492. #Correct:77210 #Trained:77501 Training Accuracy:99.6%
Progress:8.62% Speed(reviews/sec):5485. #Correct:79705 #Trained:80001 Training Accuracy:99.6%
Progress:8.89% Speed(reviews/sec):5486. #Correct:82194 #Trained:82501 Training Accuracy:99.6%
Progress:9.16% Speed(reviews/sec):5483. #Correct:84688 #Trained:85001 Training Accuracy:99.6%
Progress:9.43% Speed(reviews/sec):5487. #Correct:87182 #Trained:87501 Training Accuracy:99.6%
Progress:9.70% Speed(reviews/sec):5483. #Correct:89682 #Trained:90001 Training Accuracy:99.6%
Progress:9.97% Speed(reviews/sec):5504. #Correct:92166 #Trained:92501 Training Accuracy:99.6%
Progress:10.2% Speed(reviews/sec):5495. #Correct:94665 #Trained:95001 Training Accuracy:99.6%
Progress:10.5% Speed(reviews/sec):5505. #Correct:97158 #Trained:97501 Training Accuracy:99.6%
Progress:10.7% Speed(reviews/sec):5502. #Correct:99652 #Trained:100001 Training Accuracy:99.6%
Progress:11.0% Speed(reviews/sec):5516. #Correct:102146 #Trained:102501 Training Accuracy:99.6%
Progress:11.3% Speed(reviews/sec):5502. #Correct:104634 #Trained:105001 Training Accuracy:99.6%
Progress:11.5% Speed(reviews/sec):5515. #Correct:107124 #Trained:107501 Training Accuracy:99.6%
Progress:11.8% Speed(reviews/sec):5517. #Correct:109609 #Trained:110001 Training Accuracy:99.6%
Progress:12.1% Speed(reviews/sec):5525. #Correct:112096 #Trained:112501 Training Accuracy:99.6%
Progress:12.3% Speed(reviews/sec):5541. #Correct:114576 #Trained:115001 Training Accuracy:99.6%
Progress:12.6% Speed(reviews/sec):5548. #Correct:117052 #Trained:117501 Training Accuracy:99.6%
Progress:12.9% Speed(reviews/sec):5545. #Correct:119548 #Trained:120001 Training Accuracy:99.6%
Progress:13.2% Speed(reviews/sec):5549. #Correct:122044 #Trained:122501 Training Accuracy:99.6%
Progress:13.4% Speed(reviews/sec):5544. #Correct:124533 #Trained:125001 Training Accuracy:99.6%
Progress:13.7% Speed(reviews/sec):5543. #Correct:127031 #Trained:127501 Training Accuracy:99.6%
Progress:14.0% Speed(reviews/sec):5537. #Correct:129519 #Trained:130001 Training Accuracy:99.6%
Progress:14.2% Speed(reviews/sec):5544. #Correct:132000 #Trained:132501 Training Accuracy:99.6%
Progress:14.5% Speed(reviews/sec):5545. #Correct:134492 #Trained:135001 Training Accuracy:99.6%
Progress:14.8% Speed(reviews/sec):5547. #Correct:136974 #Trained:137501 Training Accuracy:99.6%
Progress:15.0% Speed(reviews/sec):5545. #Correct:139468 #Trained:140001 Training Accuracy:99.6%
Progress:15.3% Speed(reviews/sec):5551. #Correct:141964 #Trained:142501 Training Accuracy:99.6%
Progress:15.6% Speed(reviews/sec):5546. #Correct:144459 #Trained:145001 Training Accuracy:99.6%
Progress:15.9% Speed(reviews/sec):5558. #Correct:146951 #Trained:147501 Training Accuracy:99.6%
Progress:16.1% Speed(reviews/sec):5541. #Correct:149444 #Trained:150001 Training Accuracy:99.6%
Progress:16.4% Speed(reviews/sec):5539. #Correct:151941 #Trained:152501 Training Accuracy:99.6%
Progress:16.7% Speed(reviews/sec):5537. #Correct:154433 #Trained:155001 Training Accuracy:99.6%
Progress:16.9% Speed(reviews/sec):5542. #Correct:156920 #Trained:157501 Training Accuracy:99.6%
Progress:17.2% Speed(reviews/sec):5542. #Correct:159412 #Trained:160001 Training Accuracy:99.6%
Progress:17.5% Speed(reviews/sec):5546. #Correct:161901 #Trained:162501 Training Accuracy:99.6%
Progress:17.7% Speed(reviews/sec):5536. #Correct:164389 #Trained:165001 Training Accuracy:99.6%
Progress:18.0% Speed(reviews/sec):5545. #Correct:166887 #Trained:167501 Training Accuracy:99.6%
Progress:18.3% Speed(reviews/sec):5551. #Correct:169378 #Trained:170001 Training Accuracy:99.6%
Progress:18.5% Speed(reviews/sec):5553. #Correct:171873 #Trained:172501 Training Accuracy:99.6%
Progress:18.8% Speed(reviews/sec):5555. #Correct:174354 #Trained:175001 Training Accuracy:99.6%
Progress:19.1% Speed(reviews/sec):5558. #Correct:176776 #Trained:177431 Training Accuracy:99.6%Progress:19.1% Speed(reviews/sec):5558. #Correct:176846 #Trained:177501 Training Accuracy:99.6%
Progress:19.4% Speed(reviews/sec):5548. #Correct:179344 #Trained:180001 Training Accuracy:99.6%
Progress:19.6% Speed(reviews/sec):5545. #Correct:181837 #Trained:182501 Training Accuracy:99.6%
Progress:19.9% Speed(reviews/sec):5529. #Correct:184327 #Trained:185001 Training Accuracy:99.6%
Progress:20.2% Speed(reviews/sec):5534. #Correct:186819 #Trained:187501 Training Accuracy:99.6%
Progress:20.4% Speed(reviews/sec):5526. #Correct:189314 #Trained:190001 Training Accuracy:99.6%
Progress:20.7% Speed(reviews/sec):5533. #Correct:191795 #Trained:192501 Training Accuracy:99.6%
Progress:21.0% Speed(reviews/sec):5534. #Correct:194287 #Trained:195001 Training Accuracy:99.6%
Progress:21.2% Speed(reviews/sec):5536. #Correct:196774 #Trained:197501 Training Accuracy:99.6%
Progress:21.5% Speed(reviews/sec):5522. #Correct:199271 #Trained:200001 Training Accuracy:99.6%
Progress:21.8% Speed(reviews/sec):5530. #Correct:201755 #Trained:202501 Training Accuracy:99.6%
Progress:22.1% Speed(reviews/sec):5528. #Correct:204232 #Trained:205001 Training Accuracy:99.6%
Progress:22.3% Speed(reviews/sec):5527. #Correct:206717 #Trained:207501 Training Accuracy:99.6%
Progress:22.6% Speed(reviews/sec):5527. #Correct:209209 #Trained:210001 Training Accuracy:99.6%
Progress:22.9% Speed(reviews/sec):5527. #Correct:211701 #Trained:212501 Training Accuracy:99.6%
Progress:23.1% Speed(reviews/sec):5528. #Correct:214182 #Trained:215001 Training Accuracy:99.6%
Progress:23.4% Speed(reviews/sec):5532. #Correct:216674 #Trained:217501 Training Accuracy:99.6%
Progress:23.7% Speed(reviews/sec):5526. #Correct:219165 #Trained:220001 Training Accuracy:99.6%
Progress:23.9% Speed(reviews/sec):5523. #Correct:221658 #Trained:222501 Training Accuracy:99.6%
Progress:24.2% Speed(reviews/sec):5522. #Correct:224150 #Trained:225001 Training Accuracy:99.6%
Progress:24.5% Speed(reviews/sec):5526. #Correct:226637 #Trained:227501 Training Accuracy:99.6%
Progress:24.7% Speed(reviews/sec):5520. #Correct:229130 #Trained:230001 Training Accuracy:99.6%
Progress:25.0% Speed(reviews/sec):5520. #Correct:231621 #Trained:232501 Training Accuracy:99.6%
Progress:25.3% Speed(reviews/sec):5514. #Correct:234112 #Trained:235001 Training Accuracy:99.6%
Progress:25.6% Speed(reviews/sec):5514. #Correct:236609 #Trained:237501 Training Accuracy:99.6%
Progress:25.8% Speed(reviews/sec):5515. #Correct:239104 #Trained:240001 Training Accuracy:99.6%
Progress:26.1% Speed(reviews/sec):5515. #Correct:241593 #Trained:242501 Training Accuracy:99.6%
Progress:26.4% Speed(reviews/sec):5521. #Correct:244074 #Trained:245001 Training Accuracy:99.6%
Progress:26.6% Speed(reviews/sec):5516. #Correct:246563 #Trained:247501 Training Accuracy:99.6%
Progress:26.9% Speed(reviews/sec):5525. #Correct:249059 #Trained:250001 Training Accuracy:99.6%
Progress:27.2% Speed(reviews/sec):5522. #Correct:251556 #Trained:252501 Training Accuracy:99.6%
Progress:27.4% Speed(reviews/sec):5526. #Correct:254054 #Trained:255001 Training Accuracy:99.6%
Progress:27.7% Speed(reviews/sec):5515. #Correct:256544 #Trained:257501 Training Accuracy:99.6%
Progress:28.0% Speed(reviews/sec):5511. #Correct:259037 #Trained:260001 Training Accuracy:99.6%
Progress:28.3% Speed(reviews/sec):5510. #Correct:261532 #Trained:262501 Training Accuracy:99.6%
Progress:28.5% Speed(reviews/sec):5515. #Correct:264022 #Trained:265001 Training Accuracy:99.6%
Progress:28.8% Speed(reviews/sec):5515. #Correct:266518 #Trained:267501 Training Accuracy:99.6%
Progress:29.1% Speed(reviews/sec):5520. #Correct:269014 #Trained:270001 Training Accuracy:99.6%
Progress:29.3% Speed(reviews/sec):5510. #Correct:271505 #Trained:272501 Training Accuracy:99.6%
Progress:29.6% Speed(reviews/sec):5511. #Correct:273999 #Trained:275001 Training Accuracy:99.6%
Progress:29.9% Speed(reviews/sec):5507. #Correct:276492 #Trained:277501 Training Accuracy:99.6%
Progress:30.1% Speed(reviews/sec):5507. #Correct:278984 #Trained:280001 Training Accuracy:99.6%
Progress:30.4% Speed(reviews/sec):5500. #Correct:281476 #Trained:282501 Training Accuracy:99.6%
Progress:30.7% Speed(reviews/sec):5498. #Correct:283973 #Trained:285001 Training Accuracy:99.6%
Progress:30.9% Speed(reviews/sec):5496. #Correct:286470 #Trained:287501 Training Accuracy:99.6%
Progress:31.2% Speed(reviews/sec):5498. #Correct:288970 #Trained:290001 Training Accuracy:99.6%
Progress:31.5% Speed(reviews/sec):5495. #Correct:291467 #Trained:292501 Training Accuracy:99.6%
Progress:31.8% Speed(reviews/sec):5496. #Correct:293959 #Trained:295001 Training Accuracy:99.6%
Progress:32.0% Speed(reviews/sec):5492. #Correct:296454 #Trained:297501 Training Accuracy:99.6%
Progress:32.3% Speed(reviews/sec):5497. #Correct:298952 #Trained:300001 Training Accuracy:99.6%
Progress:32.6% Speed(reviews/sec):5494. #Correct:301447 #Trained:302501 Training Accuracy:99.6%
Progress:32.8% Speed(reviews/sec):5496. #Correct:303934 #Trained:305001 Training Accuracy:99.6%
Progress:33.1% Speed(reviews/sec):5495. #Correct:306422 #Trained:307501 Training Accuracy:99.6%
Progress:33.4% Speed(reviews/sec):5493. #Correct:308916 #Trained:310001 Training Accuracy:99.6%
Progress:33.6% Speed(reviews/sec):5480. #Correct:311413 #Trained:312501 Training Accuracy:99.6%
Progress:33.9% Speed(reviews/sec):5482. #Correct:313905 #Trained:315001 Training Accuracy:99.6%
Progress:34.2% Speed(reviews/sec):5478. #Correct:316397 #Trained:317501 Training Accuracy:99.6%
Progress:34.5% Speed(reviews/sec):5479. #Correct:318887 #Trained:320001 Training Accuracy:99.6%
Progress:34.7% Speed(reviews/sec):5479. #Correct:321383 #Trained:322501 Training Accuracy:99.6%
Progress:35.0% Speed(reviews/sec):5482. #Correct:323870 #Trained:325001 Training Accuracy:99.6%
Progress:35.3% Speed(reviews/sec):5482. #Correct:326359 #Trained:327501 Training Accuracy:99.6%
Progress:35.5% Speed(reviews/sec):5480. #Correct:328854 #Trained:330001 Training Accuracy:99.6%
Progress:35.8% Speed(reviews/sec):5474. #Correct:331352 #Trained:332501 Training Accuracy:99.6%
Progress:36.1% Speed(reviews/sec):5481. #Correct:333831 #Trained:335001 Training Accuracy:99.6%
Progress:36.3% Speed(reviews/sec):5482. #Correct:336320 #Trained:337501 Training Accuracy:99.6%
Progress:36.6% Speed(reviews/sec):5479. #Correct:338820 #Trained:340001 Training Accuracy:99.6%
Progress:36.9% Speed(reviews/sec):5471. #Correct:341315 #Trained:342501 Training Accuracy:99.6%
Progress:37.1% Speed(reviews/sec):5476. #Correct:343799 #Trained:345001 Training Accuracy:99.6%
Progress:37.4% Speed(reviews/sec):5473. #Correct:346292 #Trained:347501 Training Accuracy:99.6%
Progress:37.7% Speed(reviews/sec):5473. #Correct:348788 #Trained:350001 Training Accuracy:99.6%
Progress:38.0% Speed(reviews/sec):5473. #Correct:351281 #Trained:352501 Training Accuracy:99.6%
Progress:38.2% Speed(reviews/sec):5476. #Correct:353771 #Trained:355001 Training Accuracy:99.6%
Progress:38.5% Speed(reviews/sec):5475. #Correct:356266 #Trained:357501 Training Accuracy:99.6%
Progress:38.8% Speed(reviews/sec):5477. #Correct:358762 #Trained:360001 Training Accuracy:99.6%
Progress:39.0% Speed(reviews/sec):5478. #Correct:361256 #Trained:362501 Training Accuracy:99.6%
Progress:39.3% Speed(reviews/sec):5483. #Correct:363742 #Trained:365001 Training Accuracy:99.6%
Progress:39.6% Speed(reviews/sec):5482. #Correct:366239 #Trained:367501 Training Accuracy:99.6%
Progress:39.8% Speed(reviews/sec):5481. #Correct:368727 #Trained:370001 Training Accuracy:99.6%
Progress:40.1% Speed(reviews/sec):5483. #Correct:371223 #Trained:372501 Training Accuracy:99.6%
Progress:40.4% Speed(reviews/sec):5483. #Correct:373716 #Trained:375001 Training Accuracy:99.6%
Progress:40.7% Speed(reviews/sec):5484. #Correct:376201 #Trained:377501 Training Accuracy:99.6%
Progress:40.9% Speed(reviews/sec):5486. #Correct:378694 #Trained:380001 Training Accuracy:99.6%
Progress:41.2% Speed(reviews/sec):5487. #Correct:381183 #Trained:382501 Training Accuracy:99.6%
Progress:41.5% Speed(reviews/sec):5491. #Correct:383675 #Trained:385001 Training Accuracy:99.6%
Progress:41.7% Speed(reviews/sec):5490. #Correct:386169 #Trained:387501 Training Accuracy:99.6%
Progress:42.0% Speed(reviews/sec):5491. #Correct:388667 #Trained:390001 Training Accuracy:99.6%
Progress:42.3% Speed(reviews/sec):5491. #Correct:391162 #Trained:392501 Training Accuracy:99.6%
Progress:42.5% Speed(reviews/sec):5491. #Correct:393658 #Trained:395001 Training Accuracy:99.6%
Progress:42.8% Speed(reviews/sec):5487. #Correct:396152 #Trained:397501 Training Accuracy:99.6%
Progress:43.1% Speed(reviews/sec):5490. #Correct:398648 #Trained:400001 Training Accuracy:99.6%
Progress:43.3% Speed(reviews/sec):5487. #Correct:401143 #Trained:402501 Training Accuracy:99.6%
Progress:43.6% Speed(reviews/sec):5485. #Correct:403639 #Trained:405001 Training Accuracy:99.6%
Progress:43.9% Speed(reviews/sec):5488. #Correct:406132 #Trained:407501 Training Accuracy:99.6%
Progress:44.2% Speed(reviews/sec):5492. #Correct:408627 #Trained:410001 Training Accuracy:99.6%
Progress:44.4% Speed(reviews/sec):5488. #Correct:411116 #Trained:412501 Training Accuracy:99.6%
Progress:44.7% Speed(reviews/sec):5487. #Correct:413610 #Trained:415001 Training Accuracy:99.6%
Progress:45.0% Speed(reviews/sec):5486. #Correct:416105 #Trained:417501 Training Accuracy:99.6%
Progress:45.2% Speed(reviews/sec):5488. #Correct:418601 #Trained:420001 Training Accuracy:99.6%
Progress:45.5% Speed(reviews/sec):5487. #Correct:421098 #Trained:422501 Training Accuracy:99.6%
Progress:45.8% Speed(reviews/sec):5490. #Correct:423591 #Trained:425001 Training Accuracy:99.6%
Progress:46.0% Speed(reviews/sec):5489. #Correct:426084 #Trained:427501 Training Accuracy:99.6%
Progress:46.3% Speed(reviews/sec):5489. #Correct:428579 #Trained:430001 Training Accuracy:99.6%
Progress:46.6% Speed(reviews/sec):5488. #Correct:431073 #Trained:432501 Training Accuracy:99.6%
Progress:46.9% Speed(reviews/sec):5489. #Correct:433568 #Trained:435001 Training Accuracy:99.6%
Progress:47.1% Speed(reviews/sec):5488. #Correct:436064 #Trained:437501 Training Accuracy:99.6%
Progress:47.4% Speed(reviews/sec):5492. #Correct:438557 #Trained:440001 Training Accuracy:99.6%
Progress:47.7% Speed(reviews/sec):5490. #Correct:441050 #Trained:442501 Training Accuracy:99.6%
Progress:47.9% Speed(reviews/sec):5495. #Correct:443540 #Trained:445001 Training Accuracy:99.6%
Progress:48.2% Speed(reviews/sec):5495. #Correct:446034 #Trained:447501 Training Accuracy:99.6%
Progress:48.5% Speed(reviews/sec):5491. #Correct:448531 #Trained:450001 Training Accuracy:99.6%
Progress:48.7% Speed(reviews/sec):5490. #Correct:451029 #Trained:452501 Training Accuracy:99.6%
Progress:49.0% Speed(reviews/sec):5493. #Correct:453522 #Trained:455001 Training Accuracy:99.6%
Progress:49.3% Speed(reviews/sec):5492. #Correct:456015 #Trained:457501 Training Accuracy:99.6%
Progress:49.5% Speed(reviews/sec):5488. #Correct:458481 #Trained:459971 Training Accuracy:99.6%Progress:49.5% Speed(reviews/sec):5488. #Correct:458511 #Trained:460001 Training Accuracy:99.6%
Progress:49.8% Speed(reviews/sec):5488. #Correct:461004 #Trained:462501 Training Accuracy:99.6%
Progress:50.1% Speed(reviews/sec):5490. #Correct:463498 #Trained:465001 Training Accuracy:99.6%
Progress:50.4% Speed(reviews/sec):5489. #Correct:465990 #Trained:467501 Training Accuracy:99.6%
Progress:50.6% Speed(reviews/sec):5489. #Correct:468487 #Trained:470001 Training Accuracy:99.6%
Progress:50.9% Speed(reviews/sec):5488. #Correct:470984 #Trained:472501 Training Accuracy:99.6%
Progress:51.2% Speed(reviews/sec):5486. #Correct:473473 #Trained:475001 Training Accuracy:99.6%
Progress:51.2% Speed(reviews/sec):5487. #Correct:473644 #Trained:475172 Training Accuracy:99.6%</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[24]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Encapsulate our neural network in a class</span>
<span class="k">class</span> <span class="nc">SentimentNetwork</span><span class="p">:</span>
    <span class="c1">##  added min_count and polarity_cutoff parameters</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reviews</span><span class="p">,</span><span class="n">labels</span><span class="p">,</span><span class="n">min_count</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span><span class="n">polarity_cutoff</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span><span class="n">hidden_nodes</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create a SentimenNetwork with the given settings</span>
<span class="sd">        Args:</span>
<span class="sd">            reviews(list) - List of reviews used for training</span>
<span class="sd">            labels(list) - List of POSITIVE/NEGATIVE labels associated with the given reviews</span>
<span class="sd">            min_count(int) - Words should only be added to the vocabulary </span>
<span class="sd">                             if they occur more than this many times</span>
<span class="sd">            polarity_cutoff(float) - The absolute value of a word&#39;s positive-to-negative</span>
<span class="sd">                                     ratio must be at least this big to be considered.</span>
<span class="sd">            hidden_nodes(int) - Number of nodes to create in the hidden layer</span>
<span class="sd">            learning_rate(float) - Learning rate to use while training</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Assign a seed to our random number generator to ensure we get</span>
        <span class="c1"># reproducable results during development </span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># process the reviews and their associated labels so that everything</span>
        <span class="c1"># is ready for training</span>
        <span class="c1">## added min_count and polarity_cutoff arguments to pre_process_data call</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_process_data</span><span class="p">(</span><span class="n">reviews</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">polarity_cutoff</span><span class="p">,</span> <span class="n">min_count</span><span class="p">)</span>
        
        <span class="c1"># Build the network to have the number of hidden nodes and the learning rate that</span>
        <span class="c1"># were passed into this initializer. Make the same number of input nodes as</span>
        <span class="c1"># there are vocabulary words and create a single output node.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_network</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">review_vocab</span><span class="p">),</span><span class="n">hidden_nodes</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>

    <span class="c1">## : added min_count and polarity_cutoff parameters</span>
    <span class="k">def</span> <span class="nf">pre_process_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reviews</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">polarity_cutoff</span><span class="p">,</span> <span class="n">min_count</span><span class="p">):</span>
        
        <span class="c1">## ----------------------------------------</span>
        <span class="c1">##  Calculate positive-to-negative ratios for words before</span>
        <span class="c1">#                     building vocabulary</span>
        <span class="c1">#</span>
        <span class="n">positive_counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
        <span class="n">negative_counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
        <span class="n">total_counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">reviews</span><span class="p">)):</span>
            <span class="k">if</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;POSITIVE&#39;</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">reviews</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
                    <span class="n">positive_counts</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">total_counts</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">reviews</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
                    <span class="n">negative_counts</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">total_counts</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">pos_neg_ratios</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">term</span><span class="p">,</span><span class="n">cnt</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">total_counts</span><span class="o">.</span><span class="n">most_common</span><span class="p">()):</span>
            <span class="k">if</span><span class="p">(</span><span class="n">cnt</span> <span class="o">&gt;=</span> <span class="mi">50</span><span class="p">):</span>
                <span class="n">pos_neg_ratio</span> <span class="o">=</span> <span class="n">positive_counts</span><span class="p">[</span><span class="n">term</span><span class="p">]</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">negative_counts</span><span class="p">[</span><span class="n">term</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">pos_neg_ratios</span><span class="p">[</span><span class="n">term</span><span class="p">]</span> <span class="o">=</span> <span class="n">pos_neg_ratio</span>

        <span class="k">for</span> <span class="n">word</span><span class="p">,</span><span class="n">ratio</span> <span class="ow">in</span> <span class="n">pos_neg_ratios</span><span class="o">.</span><span class="n">most_common</span><span class="p">():</span>
            <span class="k">if</span><span class="p">(</span><span class="n">ratio</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
                <span class="n">pos_neg_ratios</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">ratio</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">pos_neg_ratios</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">ratio</span> <span class="o">+</span> <span class="mf">0.01</span><span class="p">)))</span>
        <span class="c1">#</span>
        <span class="c1">##</span>
        <span class="c1">## ----------------------------------------</span>

        <span class="c1"># populate review_vocab with all of the words in the given reviews</span>
        <span class="n">review_vocab</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">review</span> <span class="ow">in</span> <span class="n">reviews</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">review</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
                <span class="c1">##  only add words that occur at least min_count times</span>
                <span class="c1">#                     and for words with pos/neg ratios, only add words</span>
                <span class="c1">#                     that meet the polarity_cutoff</span>
                <span class="k">if</span><span class="p">(</span><span class="n">total_counts</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">min_count</span><span class="p">):</span>
                    <span class="k">if</span><span class="p">(</span><span class="n">word</span> <span class="ow">in</span> <span class="n">pos_neg_ratios</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
                        <span class="k">if</span><span class="p">((</span><span class="n">pos_neg_ratios</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">polarity_cutoff</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">pos_neg_ratios</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="o">-</span><span class="n">polarity_cutoff</span><span class="p">)):</span>
                            <span class="n">review_vocab</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">review_vocab</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

        <span class="c1"># Convert the vocabulary set to a list so we can access words via indices</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">review_vocab</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">review_vocab</span><span class="p">)</span>
        
        <span class="c1"># populate label_vocab with all of the words in the given labels.</span>
        <span class="n">label_vocab</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">:</span>
            <span class="n">label_vocab</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
        
        <span class="c1"># Convert the label vocabulary set to a list so we can access labels via indices</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_vocab</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">label_vocab</span><span class="p">)</span>
        
        <span class="c1"># Store the sizes of the review and label vocabularies.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">review_vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">review_vocab</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_vocab</span><span class="p">)</span>
        
        <span class="c1"># Create a dictionary of words in the vocabulary mapped to index positions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">review_vocab</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
        
        <span class="c1"># Create a dictionary of labels mapped to index positions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label2index</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_vocab</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">label2index</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>

    <span class="k">def</span> <span class="nf">init_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_nodes</span><span class="p">,</span> <span class="n">hidden_nodes</span><span class="p">,</span> <span class="n">output_nodes</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
        <span class="c1"># Set number of nodes in input, hidden and output layers.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_nodes</span> <span class="o">=</span> <span class="n">input_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_nodes</span> <span class="o">=</span> <span class="n">hidden_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_nodes</span> <span class="o">=</span> <span class="n">output_nodes</span>

        <span class="c1"># Store the learning rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>

        <span class="c1"># Initialize weights</span>

        <span class="c1"># These are the weights between the input layer and the hidden layer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_0_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">input_nodes</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_nodes</span><span class="p">))</span>

        <span class="c1"># These are the weights between the hidden layer and the output layer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_1_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_nodes</span><span class="o">**-</span><span class="mf">0.5</span><span class="p">,</span> 
                                                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_nodes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_nodes</span><span class="p">))</span>
        
        <span class="c1">##  Removed self.layer_0; added self.layer_1</span>
        <span class="c1"># The input layer, a two-dimensional matrix with shape 1 x hidden_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">hidden_nodes</span><span class="p">))</span>
    
    <span class="c1">## Removed update_input_layer function</span>
    
    <span class="k">def</span> <span class="nf">get_target_for_label</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">label</span><span class="p">):</span>
        <span class="k">if</span><span class="p">(</span><span class="n">label</span> <span class="o">==</span> <span class="s1">&#39;POSITIVE&#39;</span><span class="p">):</span>
            <span class="k">return</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
        
    <span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">sigmoid_output_2_derivative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">output</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">output</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">output</span><span class="p">)</span>
    
    <span class="c1">##  changed name of first parameter form &#39;training_reviews&#39; </span>
    <span class="c1">#                     to &#39;training_reviews_raw&#39;</span>
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_reviews_raw</span><span class="p">,</span> <span class="n">training_labels</span><span class="p">):</span>

        <span class="c1">## pre-process training reviews so we can deal </span>
        <span class="c1">#                     directly with the indices of non-zero inputs</span>
        <span class="n">training_reviews</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">review</span> <span class="ow">in</span> <span class="n">training_reviews_raw</span><span class="p">:</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">review</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
                <span class="k">if</span><span class="p">(</span><span class="n">word</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
                    <span class="n">indices</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">])</span>
            <span class="n">training_reviews</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">indices</span><span class="p">))</span>

        <span class="c1"># make sure out we have a matching number of reviews and labels</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">training_reviews</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">training_labels</span><span class="p">))</span>
        
        <span class="c1"># Keep track of correct predictions to display accuracy during training </span>
        <span class="n">correct_so_far</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Remember when we started for printing time statistics</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        
        <span class="c1"># loop through all the given reviews and run a forward and backward pass,</span>
        <span class="c1"># updating weights for every item</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">training_reviews</span><span class="p">)):</span>
            
            <span class="c1"># Get the next review and its correct label</span>
            <span class="n">review</span> <span class="o">=</span> <span class="n">training_reviews</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">label</span> <span class="o">=</span> <span class="n">training_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            
            <span class="c1">#### Implement the forward pass here ####</span>
            <span class="c1">### Forward pass ###</span>

            <span class="c1">##  Removed call to &#39;update_input_layer&#39; function</span>
            <span class="c1">#                     because &#39;layer_0&#39; is no longer used</span>

            <span class="c1"># Hidden layer</span>
            <span class="c1">## Add in only the weights for non-zero items</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layer_1</span> <span class="o">*=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">review</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">layer_1</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_0_1</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

            <span class="c1"># Output layer</span>
            <span class="c1">##  changed to use &#39;self.layer_1&#39; instead of &#39;local layer_1&#39;</span>
            <span class="n">layer_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_1_2</span><span class="p">))</span>            
            
            <span class="c1">#### Implement the backward pass here ####</span>
            <span class="c1">### Backward pass ###</span>

            <span class="c1"># Output error</span>
            <span class="n">layer_2_error</span> <span class="o">=</span> <span class="n">layer_2</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_target_for_label</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="c1"># Output layer error is the difference between desired target and actual output.</span>
            <span class="n">layer_2_delta</span> <span class="o">=</span> <span class="n">layer_2_error</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid_output_2_derivative</span><span class="p">(</span><span class="n">layer_2</span><span class="p">)</span>

            <span class="c1"># Backpropagated error</span>
            <span class="n">layer_1_error</span> <span class="o">=</span> <span class="n">layer_2_delta</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_1_2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="c1"># errors propagated to the hidden layer</span>
            <span class="n">layer_1_delta</span> <span class="o">=</span> <span class="n">layer_1_error</span> <span class="c1"># hidden layer gradients - no nonlinearity so it&#39;s the same as the error</span>

            <span class="c1"># Update the weights</span>
            <span class="c1">##  changed to use &#39;self.layer_1&#39; instead of local &#39;layer_1&#39;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights_1_2</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_1</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">layer_2_delta</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="c1"># update hidden-to-output weights with gradient descent step</span>
            
            <span class="c1">## Only update the weights that were used in the forward pass</span>
            <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">review</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">weights_0_1</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">-=</span> <span class="n">layer_1_delta</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="c1"># update input-to-hidden weights with gradient descent step</span>

            <span class="c1"># Keep track of correct predictions.</span>
            <span class="k">if</span><span class="p">(</span><span class="n">layer_2</span> <span class="o">&gt;=</span> <span class="mf">0.5</span> <span class="ow">and</span> <span class="n">label</span> <span class="o">==</span> <span class="s1">&#39;POSITIVE&#39;</span><span class="p">):</span>
                <span class="n">correct_so_far</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">elif</span><span class="p">(</span><span class="n">layer_2</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">and</span> <span class="n">label</span> <span class="o">==</span> <span class="s1">&#39;NEGATIVE&#39;</span><span class="p">):</span>
                <span class="n">correct_so_far</span> <span class="o">+=</span> <span class="mi">1</span>
            
            <span class="c1"># For debug purposes, print out our prediction accuracy and speed </span>
            <span class="c1"># throughout the training process. </span>
            <span class="n">elapsed_time</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>
            <span class="n">reviews_per_second</span> <span class="o">=</span> <span class="n">i</span> <span class="o">/</span> <span class="n">elapsed_time</span> <span class="k">if</span> <span class="n">elapsed_time</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
            
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">Progress:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">i</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">training_reviews</span><span class="p">)))[:</span><span class="mi">4</span><span class="p">]</span> \
                             <span class="o">+</span> <span class="s2">&quot;% Speed(reviews/sec):&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">reviews_per_second</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span> \
                             <span class="o">+</span> <span class="s2">&quot; #Correct:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">correct_so_far</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; #Trained:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> \
                             <span class="o">+</span> <span class="s2">&quot; Training Accuracy:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">correct_so_far</span> <span class="o">*</span> <span class="mi">100</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))[:</span><span class="mi">4</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;%&quot;</span><span class="p">)</span>
            <span class="k">if</span><span class="p">(</span><span class="n">i</span> <span class="o">%</span> <span class="mi">2500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">testing_reviews</span><span class="p">,</span> <span class="n">testing_labels</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Attempts to predict the labels for the given testing_reviews,</span>
<span class="sd">        and uses the test_labels to calculate the accuracy of those predictions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="c1"># keep track of how many correct predictions we make</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># we&#39;ll time how many predictions per second we make</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="c1"># Loop through each of the given reviews and call run to predict</span>
        <span class="c1"># its label. </span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">testing_reviews</span><span class="p">)):</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">testing_reviews</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="k">if</span><span class="p">(</span><span class="n">pred</span> <span class="o">==</span> <span class="n">testing_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span>
                <span class="n">correct</span> <span class="o">+=</span> <span class="mi">1</span>
            
            <span class="c1"># For debug purposes, print out our prediction accuracy and speed </span>
            <span class="c1"># throughout the prediction process. </span>

            <span class="n">elapsed_time</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>
            <span class="n">reviews_per_second</span> <span class="o">=</span> <span class="n">i</span> <span class="o">/</span> <span class="n">elapsed_time</span> <span class="k">if</span> <span class="n">elapsed_time</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
            
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">Progress:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">i</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">testing_reviews</span><span class="p">)))[:</span><span class="mi">4</span><span class="p">]</span> \
                             <span class="o">+</span> <span class="s2">&quot;% Speed(reviews/sec):&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">reviews_per_second</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span> \
                             <span class="o">+</span> <span class="s2">&quot; #Correct:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">correct</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; #Tested:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> \
                             <span class="o">+</span> <span class="s2">&quot; Testing Accuracy:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">correct</span> <span class="o">*</span> <span class="mi">100</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))[:</span><span class="mi">4</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;%&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">review</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a POSITIVE or NEGATIVE prediction for the given review.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Run a forward pass through the network, like in the &quot;train&quot; function.</span>
        
        <span class="c1">## Removed call to update_input_layer function</span>
        <span class="c1">#                     because layer_0 is no longer used</span>

        <span class="c1"># Hidden layer</span>
        <span class="c1">##  Identify the indices used in the review and then add</span>
        <span class="c1">#                     just those weights to layer_1 </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_1</span> <span class="o">*=</span> <span class="mi">0</span>
        <span class="n">unique_indices</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">review</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">unique_indices</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">unique_indices</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layer_1</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_0_1</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        
        <span class="c1"># Output layer</span>
        <span class="c1">## changed to use self.layer_1 instead of local layer_1</span>
        <span class="n">layer_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_1_2</span><span class="p">))</span>
         
        <span class="c1"># Return POSITIVE for values above greater-than-or-equal-to 0.5 in the output layer;</span>
        <span class="c1"># return NEGATIVE for other values</span>
        <span class="k">if</span><span class="p">(</span><span class="n">layer_2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">):</span>

        <span class="k">else</span><span class="p">:</span>
            
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mlp</span> <span class="o">=</span> <span class="n">SentimentNetwork</span><span class="p">(</span><span class="n">reviews</span><span class="p">[:</span><span class="o">-</span><span class="mi">103000</span><span class="p">],</span><span class="n">labels</span><span class="p">[:</span><span class="o">-</span><span class="mi">103000</span><span class="p">],</span><span class="n">min_count</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">polarity_cutoff</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">mlp</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">reviews</span><span class="p">[:</span><span class="o">-</span><span class="mi">103000</span><span class="p">],</span><span class="n">labels</span><span class="p">[:</span><span class="o">-</span><span class="mi">103000</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%
Progress:0.26% Speed(reviews/sec):5349. #Correct:0 #Trained:2501 Training Accuracy:0.0%
Progress:0.53% Speed(reviews/sec):5130. #Correct:0 #Trained:5001 Training Accuracy:0.0%
Progress:0.80% Speed(reviews/sec):5242. #Correct:0 #Trained:7501 Training Accuracy:0.0%
Progress:1.07% Speed(reviews/sec):5104. #Correct:0 #Trained:10001 Training Accuracy:0.0%
Progress:1.34% Speed(reviews/sec):5318. #Correct:0 #Trained:12501 Training Accuracy:0.0%
Progress:1.61% Speed(reviews/sec):5099. #Correct:0 #Trained:15001 Training Accuracy:0.0%
Progress:1.88% Speed(reviews/sec):5069. #Correct:0 #Trained:17501 Training Accuracy:0.0%
Progress:2.15% Speed(reviews/sec):5092. #Correct:0 #Trained:20001 Training Accuracy:0.0%
Progress:2.42% Speed(reviews/sec):5120. #Correct:0 #Trained:22501 Training Accuracy:0.0%
Progress:2.69% Speed(reviews/sec):5108. #Correct:0 #Trained:25001 Training Accuracy:0.0%
Progress:2.96% Speed(reviews/sec):5125. #Correct:0 #Trained:27501 Training Accuracy:0.0%
Progress:3.23% Speed(reviews/sec):5122. #Correct:0 #Trained:30001 Training Accuracy:0.0%
Progress:3.50% Speed(reviews/sec):5176. #Correct:0 #Trained:32501 Training Accuracy:0.0%
Progress:3.77% Speed(reviews/sec):5064. #Correct:0 #Trained:35001 Training Accuracy:0.0%
Progress:4.04% Speed(reviews/sec):5115. #Correct:0 #Trained:37501 Training Accuracy:0.0%
Progress:4.31% Speed(reviews/sec):5118. #Correct:0 #Trained:40001 Training Accuracy:0.0%
Progress:4.58% Speed(reviews/sec):5137. #Correct:0 #Trained:42501 Training Accuracy:0.0%
Progress:4.85% Speed(reviews/sec):5135. #Correct:0 #Trained:45001 Training Accuracy:0.0%
Progress:5.12% Speed(reviews/sec):5170. #Correct:0 #Trained:47501 Training Accuracy:0.0%
Progress:5.39% Speed(reviews/sec):5152. #Correct:0 #Trained:50001 Training Accuracy:0.0%
Progress:5.66% Speed(reviews/sec):5172. #Correct:0 #Trained:52501 Training Accuracy:0.0%
Progress:5.93% Speed(reviews/sec):5182. #Correct:0 #Trained:55001 Training Accuracy:0.0%
Progress:6.19% Speed(reviews/sec):5200. #Correct:0 #Trained:57501 Training Accuracy:0.0%
Progress:6.46% Speed(reviews/sec):5182. #Correct:0 #Trained:60001 Training Accuracy:0.0%
Progress:6.73% Speed(reviews/sec):5202. #Correct:0 #Trained:62501 Training Accuracy:0.0%
Progress:7.00% Speed(reviews/sec):5184. #Correct:0 #Trained:65001 Training Accuracy:0.0%
Progress:7.27% Speed(reviews/sec):5211. #Correct:0 #Trained:67501 Training Accuracy:0.0%
Progress:7.54% Speed(reviews/sec):5228. #Correct:0 #Trained:70001 Training Accuracy:0.0%
Progress:7.81% Speed(reviews/sec):5240. #Correct:0 #Trained:72501 Training Accuracy:0.0%
Progress:8.08% Speed(reviews/sec):5235. #Correct:0 #Trained:75001 Training Accuracy:0.0%
Progress:8.35% Speed(reviews/sec):5237. #Correct:0 #Trained:77501 Training Accuracy:0.0%
Progress:8.62% Speed(reviews/sec):5240. #Correct:0 #Trained:80001 Training Accuracy:0.0%
Progress:8.89% Speed(reviews/sec):5213. #Correct:0 #Trained:82501 Training Accuracy:0.0%
Progress:9.16% Speed(reviews/sec):5208. #Correct:0 #Trained:85001 Training Accuracy:0.0%
Progress:9.43% Speed(reviews/sec):5134. #Correct:0 #Trained:87501 Training Accuracy:0.0%
Progress:9.70% Speed(reviews/sec):5151. #Correct:0 #Trained:90001 Training Accuracy:0.0%
Progress:9.97% Speed(reviews/sec):5141. #Correct:0 #Trained:92501 Training Accuracy:0.0%
Progress:10.2% Speed(reviews/sec):5134. #Correct:0 #Trained:95001 Training Accuracy:0.0%
Progress:10.5% Speed(reviews/sec):5121. #Correct:0 #Trained:97501 Training Accuracy:0.0%
Progress:10.7% Speed(reviews/sec):5108. #Correct:0 #Trained:100001 Training Accuracy:0.0%
Progress:11.0% Speed(reviews/sec):5111. #Correct:0 #Trained:102501 Training Accuracy:0.0%
Progress:11.3% Speed(reviews/sec):5119. #Correct:0 #Trained:105001 Training Accuracy:0.0%
Progress:11.5% Speed(reviews/sec):5120. #Correct:0 #Trained:107501 Training Accuracy:0.0%
Progress:11.8% Speed(reviews/sec):5121. #Correct:0 #Trained:110001 Training Accuracy:0.0%
Progress:12.1% Speed(reviews/sec):5115. #Correct:0 #Trained:112501 Training Accuracy:0.0%
Progress:12.3% Speed(reviews/sec):5119. #Correct:0 #Trained:115001 Training Accuracy:0.0%
Progress:12.6% Speed(reviews/sec):5100. #Correct:0 #Trained:117501 Training Accuracy:0.0%
Progress:12.9% Speed(reviews/sec):5099. #Correct:0 #Trained:120001 Training Accuracy:0.0%
Progress:13.2% Speed(reviews/sec):5070. #Correct:0 #Trained:122501 Training Accuracy:0.0%
Progress:13.4% Speed(reviews/sec):5054. #Correct:0 #Trained:125001 Training Accuracy:0.0%
Progress:13.7% Speed(reviews/sec):5044. #Correct:0 #Trained:127501 Training Accuracy:0.0%
Progress:14.0% Speed(reviews/sec):5042. #Correct:0 #Trained:130001 Training Accuracy:0.0%
Progress:14.2% Speed(reviews/sec):5044. #Correct:0 #Trained:132501 Training Accuracy:0.0%
Progress:14.5% Speed(reviews/sec):5040. #Correct:0 #Trained:135001 Training Accuracy:0.0%
Progress:14.8% Speed(reviews/sec):5041. #Correct:0 #Trained:137501 Training Accuracy:0.0%
Progress:15.0% Speed(reviews/sec):5018. #Correct:0 #Trained:140001 Training Accuracy:0.0%
Progress:15.3% Speed(reviews/sec):5017. #Correct:0 #Trained:142501 Training Accuracy:0.0%
Progress:15.6% Speed(reviews/sec):5025. #Correct:0 #Trained:145001 Training Accuracy:0.0%
Progress:15.9% Speed(reviews/sec):5025. #Correct:0 #Trained:147501 Training Accuracy:0.0%
Progress:16.1% Speed(reviews/sec):5013. #Correct:0 #Trained:150001 Training Accuracy:0.0%
Progress:16.4% Speed(reviews/sec):5005. #Correct:0 #Trained:152501 Training Accuracy:0.0%
Progress:16.7% Speed(reviews/sec):5011. #Correct:0 #Trained:155001 Training Accuracy:0.0%
Progress:16.9% Speed(reviews/sec):5000. #Correct:0 #Trained:157501 Training Accuracy:0.0%
Progress:17.1% Speed(reviews/sec):5000. #Correct:0 #Trained:159359 Training Accuracy:0.0%</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    </div>
  </div>
</body>

 


</html>
