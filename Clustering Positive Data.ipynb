{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA CLEANING AND PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = pd.read_csv('Hotel_Reviews_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = dfm.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm_sub = dfm[['Positive_Review','pos_count','Tags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive_Review</th>\n",
       "      <th>pos_count</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>only the park outside of the hotel was beauti...</td>\n",
       "      <td>1</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no real complaints the hotel was great great ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>location was good and staff were ok it is cut...</td>\n",
       "      <td>1</td>\n",
       "      <td>[' Leisure trip ', ' Family with young childre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great location in nice surroundings the bar a...</td>\n",
       "      <td>1</td>\n",
       "      <td>[' Leisure trip ', ' Solo traveler ', ' Duplex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amazing location and building romantic setting</td>\n",
       "      <td>1</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Suite ', ' St...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Positive_Review  pos_count  \\\n",
       "0   only the park outside of the hotel was beauti...          1   \n",
       "1   no real complaints the hotel was great great ...          1   \n",
       "2   location was good and staff were ok it is cut...          1   \n",
       "3   great location in nice surroundings the bar a...          1   \n",
       "4    amazing location and building romantic setting           1   \n",
       "\n",
       "                                                Tags  \n",
       "0  [' Leisure trip ', ' Couple ', ' Duplex Double...  \n",
       "1  [' Leisure trip ', ' Couple ', ' Duplex Double...  \n",
       "2  [' Leisure trip ', ' Family with young childre...  \n",
       "3  [' Leisure trip ', ' Solo traveler ', ' Duplex...  \n",
       "4  [' Leisure trip ', ' Couple ', ' Suite ', ' St...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaibh\\Anaconda3x\\lib\\site-packages\\pandas\\core\\frame.py:3781: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "dfm_sub.rename(columns={'Positive_Review':'ReviewText',\n",
    "                          'pos_count':'labels','Tags':'tags'}, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfm_sub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewText</th>\n",
       "      <th>labels</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>only the park outside of the hotel was beauti...</td>\n",
       "      <td>1</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no real complaints the hotel was great great ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>location was good and staff were ok it is cut...</td>\n",
       "      <td>1</td>\n",
       "      <td>[' Leisure trip ', ' Family with young childre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great location in nice surroundings the bar a...</td>\n",
       "      <td>1</td>\n",
       "      <td>[' Leisure trip ', ' Solo traveler ', ' Duplex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amazing location and building romantic setting</td>\n",
       "      <td>1</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Suite ', ' St...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          ReviewText  labels  \\\n",
       "0   only the park outside of the hotel was beauti...       1   \n",
       "1   no real complaints the hotel was great great ...       1   \n",
       "2   location was good and staff were ok it is cut...       1   \n",
       "3   great location in nice surroundings the bar a...       1   \n",
       "4    amazing location and building romantic setting        1   \n",
       "\n",
       "                                                tags  \n",
       "0  [' Leisure trip ', ' Couple ', ' Duplex Double...  \n",
       "1  [' Leisure trip ', ' Couple ', ' Duplex Double...  \n",
       "2  [' Leisure trip ', ' Family with young childre...  \n",
       "3  [' Leisure trip ', ' Solo traveler ', ' Duplex...  \n",
       "4  [' Leisure trip ', ' Couple ', ' Suite ', ' St...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaibh\\Anaconda3x\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['tags'] =  df['tags'].apply(lambda x: x.replace('[','').replace(']','')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaibh\\Anaconda3x\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['CombinedText'] = df['tags'].map(str) + df['ReviewText'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaibh\\Anaconda3x\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\vaibh\\Anaconda3x\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df['ReviewTextLower'] = df.ReviewText\n",
    "df['ReviewTextLower'] = df.ReviewTextLower.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing data for modelling using count vectorizer and tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(ngram_range=(1, 3),  \n",
    "                                   stop_words='english', \n",
    "                                   token_pattern=\"\\\\b[a-z][a-z]+\\\\b\",\n",
    "                                   lowercase=True,\n",
    "                                   max_df = 0.6, max_features=4000)\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(2, 3),  \n",
    "                                   stop_words='english', \n",
    "                                   token_pattern=\"\\\\b[a-z][a-z]+\\\\b\",\n",
    "                                   lowercase=True,\n",
    "                                   max_df = 0.6, max_features=4000)\n",
    "\n",
    "cv_data = count_vectorizer.fit_transform(df.ReviewTextLower)\n",
    "tfidf_data = tfidf_vectorizer.fit_transform(df.ReviewTextLower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def functions for topic modelings\n",
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        \n",
    "def display_topics2(model, feature_names, no_top_words=10, topic_names = None):\n",
    "    for index, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[index]:\n",
    "            print(f\"\\nTopic {index}\")\n",
    "        else:\n",
    "            print(f\"\\nTopic {topic_names[index]}:\")\n",
    "        msg = \", \".join([f'{feature_names[i]} ({topic[i]:6.4f})' \n",
    "                             for i in topic.argsort()[:-no_top_words-1:-1]])\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the models to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comp = 20\n",
    "lsa_tfidf = TruncatedSVD(n_components=n_comp)\n",
    "lsa_cv = TruncatedSVD(n_components=n_comp)\n",
    "nmf_tfidf = NMF(n_components=n_comp)\n",
    "nmf_cv = NMF(n_components=n_comp)\n",
    "\n",
    "lsa_tfidf_data = lsa_tfidf.fit_transform(tfidf_data)\n",
    "lsa_cv_data = lsa_cv.fit_transform(cv_data)\n",
    "nmf_tfidf_data = nmf_tfidf.fit_transform(tfidf_data)\n",
    "nmf_cv_data = nmf_cv.fit_transform(cv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 0\n",
      "great location (0.8223), friendly staff (0.3034), staff friendly (0.2000), friendly helpful (0.1818), good location (0.1756), helpful staff (0.1367), staff friendly helpful (0.1131), location friendly (0.1026)\n",
      "\n",
      "Topic 1\n",
      "good location (0.5221), staff friendly (0.4865), friendly helpful (0.3583), staff friendly helpful (0.2701), helpful staff (0.1558), friendly helpful staff (0.1153), friendly staff (0.0802), location good (0.0541)\n",
      "\n",
      "Topic 2\n",
      "good location (0.6311), friendly staff (0.4327), location friendly staff (0.0961), location friendly (0.0880), staff good (0.0505), friendly staff good (0.0382), staff good location (0.0360), good location friendly (0.0359)\n",
      "\n",
      "Topic 3\n",
      "friendly staff (0.7677), location friendly staff (0.1412), location friendly (0.1393), staff friendly (0.0847), excellent location (0.0735), friendly helpful (0.0552), staff friendly helpful (0.0469), helpful friendly staff (0.0438)\n",
      "\n",
      "Topic 4\n",
      "location good (0.6755), staff helpful (0.5661), helpful friendly (0.1199), location staff (0.1193), staff helpful friendly (0.1138), staff friendly (0.1036), location great (0.0886), breakfast good (0.0527)\n",
      "\n",
      "Topic 5\n",
      "helpful staff (0.6548), location good (0.3615), friendly helpful staff (0.3435), friendly helpful (0.2088), excellent location (0.1093), staff helpful (0.0824), good breakfast (0.0597), location friendly helpful (0.0537)\n",
      "\n",
      "Topic 6\n",
      "staff helpful (0.6975), location staff (0.1485), helpful friendly (0.1484), staff helpful friendly (0.1419), helpful staff (0.1262), location great (0.1218), friendly helpful staff (0.0653), location excellent (0.0485)\n",
      "\n",
      "Topic 7\n",
      "location staff (0.9285), excellent location (0.0776), location staff friendly (0.0581), great location staff (0.0572), helpful staff (0.0404), location staff helpful (0.0381), staff excellent (0.0316), excellent location staff (0.0279)\n",
      "\n",
      "Topic 8\n",
      "location great (0.9057), location staff (0.2424), excellent location (0.1302), great staff (0.1133), location great staff (0.0875), great location great (0.0645), great breakfast (0.0397), staff excellent (0.0331)\n",
      "\n",
      "Topic 9\n",
      "excellent location (0.9276), staff excellent (0.1224), location excellent (0.1087), breakfast good (0.0611), staff excellent location (0.0554), excellent location friendly (0.0524), location perfect (0.0517), good breakfast (0.0480)\n",
      "\n",
      "Topic 10\n",
      "location excellent (0.9050), breakfast good (0.2272), bed comfortable (0.1333), excellent staff (0.1208), location excellent staff (0.0863), good breakfast (0.0670), location perfect (0.0585), excellent breakfast (0.0574)\n",
      "\n",
      "Topic 11\n",
      "breakfast good (0.7647), location perfect (0.3415), bed comfortable (0.2785), good breakfast (0.1847), room clean (0.0695), comfortable bed (0.0536), breakfast good location (0.0462), value money (0.0432)\n",
      "\n",
      "Topic 12\n",
      "location perfect (0.8434), bed comfortable (0.2336), location perfect staff (0.0404), perfect staff (0.0402), room clean (0.0257), comfortable room (0.0247), staff location (0.0246), perfect location (0.0206)\n",
      "\n",
      "Topic 13\n",
      "bed comfortable (0.8841), comfortable room (0.0997), bed comfortable room (0.0689), room clean (0.0669), bed comfortable staff (0.0335), comfortable staff (0.0321), clean comfortable (0.0319), clean bed comfortable (0.0317)\n",
      "\n",
      "Topic 14\n",
      "good breakfast (0.8551), comfortable bed (0.1493), staff good (0.1375), value money (0.0978), staff good breakfast (0.0815), location good breakfast (0.0699), staff friendly (0.0698), comfy bed (0.0677)\n",
      "\n",
      "Topic 15\n",
      "staff excellent (0.5136), comfortable bed (0.4656), bed comfy (0.1606), comfy bed (0.1491), staff great (0.1421), value money (0.1077), excellent breakfast (0.0853), helpful staff (0.0821)\n",
      "\n",
      "Topic 16\n",
      "staff excellent (0.7082), good breakfast (0.1666), friendly helpful (0.1659), staff friendly helpful (0.1063), staff excellent location (0.0628), friendly staff excellent (0.0591), excellent breakfast (0.0571), staff excellent breakfast (0.0433)\n",
      "\n",
      "Topic 17\n",
      "bed comfy (0.7894), friendly helpful (0.2436), location friendly (0.1992), location friendly staff (0.1637), staff friendly helpful (0.1448), value money (0.1228), room clean (0.0960), perfect location (0.0786)\n",
      "\n",
      "Topic 18\n",
      "bed comfy (0.5235), helpful staff (0.3287), staff friendly (0.3010), comfy bed (0.0776), friendly staff (0.0668), location helpful (0.0655), location helpful staff (0.0622), helpful friendly (0.0464)\n",
      "\n",
      "Topic 19\n",
      "comfy bed (0.5210), friendly helpful (0.2750), staff friendly helpful (0.1889), staff great (0.1375), friendly staff (0.1261), helpful friendly (0.1001), value money (0.0892), excellent location (0.0820)\n"
     ]
    }
   ],
   "source": [
    "display_topics2(lsa_tfidf, tfidf_vectorizer.get_feature_names(),8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 0\n",
      "staff (0.4331), location (0.3608), room (0.3380), hotel (0.3263), good (0.2494), great (0.2419), friendly (0.2032), helpful (0.1828), breakfast (0.1780), nice (0.1487)\n",
      "\n",
      "Topic 1\n",
      "room (0.5687), hotel (0.3149), good (0.1280), nice (0.1274), bed (0.1060), comfortable (0.1044), clean (0.0932), breakfast (0.0647), bathroom (0.0551), station (0.0393)\n",
      "\n",
      "Topic 2\n",
      "staff (0.4420), friendly (0.2500), helpful (0.2391), hotel (0.1501), friendly helpful (0.0981), staff friendly (0.0961), room (0.0862), staff helpful (0.0528), staff friendly helpful (0.0505), friendly staff (0.0474)\n",
      "\n",
      "Topic 3\n",
      "hotel (0.7402), great (0.2305), stay (0.0684), great location (0.0651), location (0.0595), walk (0.0478), rooms (0.0469), station (0.0461), hotel great (0.0412), just (0.0399)\n",
      "\n",
      "Topic 4\n",
      "good (0.6099), hotel (0.2648), breakfast (0.1552), good location (0.1093), breakfast good (0.0610), good breakfast (0.0586), staff (0.0512), friendly (0.0503), location good (0.0502), rooms (0.0436)\n",
      "\n",
      "Topic 5\n",
      "great (0.6329), breakfast (0.3435), good (0.2657), great location (0.1209), nice (0.0669), rooms (0.0557), good breakfast (0.0526), breakfast good (0.0520), staff great (0.0491), great breakfast (0.0487)\n",
      "\n",
      "Topic 6\n",
      "nice (0.8198), breakfast (0.1724), clean (0.1586), rooms (0.1475), comfortable (0.1021), bed (0.0973), really (0.0655), staff nice (0.0621), close (0.0547), nice staff (0.0487)\n",
      "\n",
      "Topic 7\n",
      "excellent (0.6155), breakfast (0.6095), excellent location (0.1098), service (0.0776), location excellent (0.0698), excellent breakfast (0.0673), staff excellent (0.0640), breakfast excellent (0.0598), lovely (0.0463), excellent staff (0.0427)\n",
      "\n",
      "Topic 8\n",
      "comfortable (0.5893), bed (0.4220), clean (0.3640), rooms (0.1801), comfortable bed (0.1236), bed comfortable (0.1024), excellent (0.0991), friendly (0.0869), clean comfortable (0.0866), comfy (0.0798)\n",
      "\n",
      "Topic 9\n",
      "friendly (0.5812), friendly staff (0.2767), clean (0.2617), breakfast (0.2359), staff friendly (0.1848), room (0.0617), location friendly (0.0512), location friendly staff (0.0463), rooms (0.0421), station (0.0401)\n",
      "\n",
      "Topic 10\n",
      "helpful (0.5025), breakfast (0.3481), station (0.2167), friendly helpful (0.2166), close (0.1661), clean (0.1404), helpful staff (0.1328), walk (0.1155), staff friendly helpful (0.1011), metro (0.1006)\n",
      "\n",
      "Topic 11\n",
      "bed (0.4080), friendly (0.2282), breakfast (0.2274), comfortable (0.1654), location (0.1220), comfy (0.1081), staff friendly (0.0865), comfortable bed (0.0828), bed comfortable (0.0676), really (0.0669)\n",
      "\n",
      "Topic 12\n",
      "excellent (0.4670), friendly (0.2762), station (0.2279), close (0.1905), friendly helpful (0.1788), nice (0.1556), great (0.1338), walk (0.1335), staff friendly (0.1241), helpful (0.1231)\n",
      "\n",
      "Topic 13\n",
      "station (0.4093), close (0.3146), staff (0.3055), walk (0.2206), metro (0.1626), tube (0.1125), train (0.1111), lovely (0.1085), stay (0.1077), just (0.1012)\n",
      "\n",
      "Topic 14\n",
      "lovely (0.4077), comfy (0.3310), bed (0.2827), really (0.2390), stay (0.1802), rooms (0.1799), clean (0.1651), comfy bed (0.1233), amazing (0.0891), perfect (0.0820)\n",
      "\n",
      "Topic 15\n",
      "rooms (0.4805), stay (0.3625), comfortable (0.2932), lovely (0.1617), really (0.1545), perfect (0.1028), beds (0.0892), service (0.0815), bar (0.0786), friendly (0.0770)\n",
      "\n",
      "Topic 16\n",
      "stay (0.4744), really (0.4517), clean (0.1783), perfect (0.1417), definitely (0.0791), staff really (0.0717), london (0.0588), service (0.0584), really nice (0.0571), amazing (0.0565)\n",
      "\n",
      "Topic 17\n",
      "lovely (0.6612), comfortable (0.1868), stay (0.1388), really (0.1086), clean (0.1045), close (0.0732), nice (0.0729), great location (0.0682), staff lovely (0.0676), excellent (0.0628)\n",
      "\n",
      "Topic 18\n",
      "positive (0.9970), rooms (0.0204), staff friendly (0.0188), quiet (0.0148), really (0.0138), comfy (0.0134), close (0.0130), reception (0.0120), beds (0.0111), area (0.0082)\n",
      "\n",
      "Topic 19\n",
      "really (0.7467), rooms (0.1387), staff really (0.1256), really good (0.0971), really nice (0.0947), friendly staff (0.0819), close (0.0753), really friendly (0.0632), really helpful (0.0579), hotel (0.0501)\n"
     ]
    }
   ],
   "source": [
    "display_topics2(lsa_cv, count_vectorizer.get_feature_names(),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 0\n",
      "great location (9.8165), staff great (0.5296), staff great location (0.4866), hotel great (0.4673), hotel great location (0.4615), great location friendly (0.2810), great location great (0.2539), great location close (0.2347), great location good (0.2233), great location staff (0.2192)\n",
      "\n",
      "Topic 1\n",
      "staff friendly (7.5696), staff friendly helpful (3.8216), friendly helpful (3.3562), location staff friendly (0.2897), hotel staff friendly (0.2656), hotel staff (0.2510), friendly helpful room (0.2484), helpful room (0.2322), clean staff friendly (0.2196), clean staff (0.2005)\n",
      "\n",
      "Topic 2\n",
      "good location (7.8591), staff good location (0.3408), staff good (0.3180), hotel good location (0.2913), hotel good (0.2889), good location nice (0.2355), good location close (0.2174), good location good (0.2161), good location friendly (0.2146), location nice (0.2145)\n",
      "\n",
      "Topic 3\n",
      "friendly staff (7.1566), helpful friendly staff (0.4342), friendly staff good (0.3740), helpful friendly (0.3637), friendly staff great (0.3400), staff great (0.3340), staff good (0.3300), friendly staff clean (0.2252), hotel friendly staff (0.2132), staff clean (0.2017)\n",
      "\n",
      "Topic 4\n",
      "location good (9.0869), great location good (0.4531), good location good (0.4265), good staff (0.3908), location good staff (0.3907), location good breakfast (0.3901), excellent location good (0.2033), good value (0.1785), location good value (0.1746), location good close (0.1580)\n",
      "\n",
      "Topic 5\n",
      "helpful staff (6.0518), friendly helpful staff (3.3092), friendly helpful (2.9978), location friendly helpful (0.4671), location helpful staff (0.4139), location helpful (0.4057), staff great (0.3698), helpful staff great (0.3482), helpful staff good (0.3258), staff good (0.2710)\n",
      "\n",
      "Topic 6\n",
      "staff helpful (6.5183), helpful friendly (1.3654), staff helpful friendly (1.3128), location staff helpful (0.2254), reception staff (0.2100), reception staff helpful (0.2011), great staff helpful (0.1923), excellent staff helpful (0.1806), hotel staff helpful (0.1709), hotel staff (0.1672)\n",
      "\n",
      "Topic 7\n",
      "location staff (6.9649), location staff friendly (0.4416), great location staff (0.4379), location staff helpful (0.3152), excellent location staff (0.1948), good location staff (0.1807), location staff excellent (0.1510), location staff breakfast (0.1431), location staff room (0.1291), location staff great (0.1274)\n",
      "\n",
      "Topic 8\n",
      "location great (6.8825), great staff (0.8773), location great staff (0.6787), great location great (0.4952), great breakfast (0.2778), location great breakfast (0.2249), great room (0.1967), location great room (0.1857), excellent location great (0.1724), great hotel (0.1667)\n",
      "\n",
      "Topic 9\n",
      "excellent location (6.6336), excellent location friendly (0.3345), staff excellent location (0.3178), hotel excellent (0.2946), hotel excellent location (0.2825), excellent location good (0.1931), excellent location staff (0.1918), location close (0.1837), excellent location close (0.1767), excellent location great (0.1763)\n",
      "\n",
      "Topic 10\n",
      "location excellent (6.6053), excellent staff (0.8385), location excellent staff (0.6307), excellent breakfast (0.2721), great location excellent (0.2621), location excellent breakfast (0.2306), staff location (0.2087), excellent staff friendly (0.1675), good location excellent (0.1629), location excellent room (0.1541)\n",
      "\n",
      "Topic 11\n",
      "breakfast good (7.0902), breakfast good location (0.4141), good staff (0.3699), breakfast good staff (0.3177), good breakfast good (0.3087), good value (0.2270), excellent breakfast (0.1777), value money (0.1730), excellent breakfast good (0.1693), room clean (0.1651)\n",
      "\n",
      "Topic 12\n",
      "location perfect (5.9008), location perfect staff (0.2823), perfect staff (0.2815), staff location (0.1549), walking distance (0.1328), location perfect close (0.1283), perfect close (0.1263), hotel location (0.1261), hotel location perfect (0.1217), perfect location (0.1165)\n",
      "\n",
      "Topic 13\n",
      "bed comfortable (5.7220), comfortable room (0.5819), bed comfortable room (0.4388), room clean (0.4366), bed comfortable staff (0.2194), comfortable staff (0.2101), clean bed comfortable (0.2059), clean bed (0.2020), comfortable room clean (0.1341), bed comfortable location (0.1331)\n",
      "\n",
      "Topic 14\n",
      "good breakfast (6.0818), staff good (1.1316), staff good breakfast (0.6112), location good breakfast (0.5201), room good (0.4392), friendly staff good (0.3734), good breakfast good (0.3153), room good breakfast (0.3021), nice staff (0.2656), breakfast nice (0.2396)\n",
      "\n",
      "Topic 15\n",
      "comfy bed (9.3389), value money (1.2171), good value (0.6716), room comfy (0.5624), room comfy bed (0.5453), good value money (0.5293), bed great (0.5164), comfy bed great (0.5015), bed good (0.4648), comfy bed good (0.4565)\n",
      "\n",
      "Topic 16\n",
      "staff excellent (5.9908), excellent breakfast (0.6816), staff excellent location (0.5356), friendly staff excellent (0.4911), staff excellent breakfast (0.3836), helpful staff excellent (0.2703), staff excellent helpful (0.2575), excellent helpful (0.2538), reception staff (0.2450), location staff excellent (0.2298)\n",
      "\n",
      "Topic 17\n",
      "comfortable bed (6.2347), room comfortable (1.0141), room comfortable bed (0.6315), clean comfortable (0.4515), bed good (0.3939), comfortable bed good (0.3741), clean room (0.3348), room clean (0.2991), location comfortable (0.2944), location comfortable bed (0.2858)\n",
      "\n",
      "Topic 18\n",
      "bed comfy (5.9499), comfy room (0.3697), room clean (0.3625), bed comfy room (0.3615), bed comfy staff (0.2385), comfy staff (0.2283), comfy location (0.1432), comfy shower (0.1235), bed comfy breakfast (0.1137), comfy breakfast (0.1082)\n",
      "\n",
      "Topic 19\n",
      "location friendly (5.1932), location friendly staff (4.4982), great location friendly (1.7868), good location friendly (1.0112), excellent location friendly (0.7658), location friendly helpful (0.5729), perfect location (0.4830), friendly staff (0.3808), perfect location friendly (0.2138), nice location (0.1497)\n"
     ]
    }
   ],
   "source": [
    "display_topics2(nmf_tfidf, tfidf_vectorizer.get_feature_names(),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 0\n",
      "staff (42.1521), welcoming (1.0889), attentive (1.0682)\n",
      "\n",
      "Topic 1\n",
      "room (20.4011), size (0.7430), small (0.6900)\n",
      "\n",
      "Topic 2\n",
      "location (19.9206), excellent location (0.8731), location great (0.8662)\n",
      "\n",
      "Topic 3\n",
      "hotel (21.1837), hotel staff (0.7900), recommend (0.7165)\n",
      "\n",
      "Topic 4\n",
      "good (20.9916), location good (2.0598), good breakfast (1.5613)\n",
      "\n",
      "Topic 5\n",
      "great (21.4341), location great (2.8553), great staff (1.5603)\n",
      "\n",
      "Topic 6\n",
      "nice (20.0354), staff nice (1.3761), room nice (1.1939)\n",
      "\n",
      "Topic 7\n",
      "breakfast (21.2371), breakfast good (1.6567), good breakfast (1.5585)\n",
      "\n",
      "Topic 8\n",
      "comfortable (18.7343), beds (2.1369), comfortable room (1.8000)\n",
      "\n",
      "Topic 9\n",
      "friendly (14.8236), friendly staff (9.8613), location friendly (1.7178)\n",
      "\n",
      "Topic 10\n",
      "helpful (26.3814), staff helpful (11.9427), helpful friendly (3.9155)\n",
      "\n",
      "Topic 11\n",
      "clean (19.2916), room clean (2.3470), clean comfortable (1.5918)\n",
      "\n",
      "Topic 12\n",
      "excellent (30.5553), excellent location (5.5557), location excellent (3.4969)\n",
      "\n",
      "Topic 13\n",
      "walk (19.9751), minutes (5.3970), minute (4.8508)\n",
      "\n",
      "Topic 14\n",
      "bed (27.6559), comfortable bed (3.9962), bed comfortable (3.3099)\n",
      "\n",
      "Topic 15\n",
      "rooms (22.7595), rooms clean (1.6152), clean rooms (1.4534)\n",
      "\n",
      "Topic 16\n",
      "stay (16.9884), definitely (2.9234), definitely stay (1.8924)\n",
      "\n",
      "Topic 17\n",
      "lovely (14.4910), staff lovely (1.3988), room lovely (1.1308)\n",
      "\n",
      "Topic 18\n",
      "positive (13.8252), experience (0.0425), overall (0.0190)\n",
      "\n",
      "Topic 19\n",
      "really (13.4545), staff really (2.0680), really nice (1.6343)\n",
      "\n",
      "Topic 20\n",
      "close (13.3058), location close (2.6004), restaurants (1.3685)\n",
      "\n",
      "Topic 21\n",
      "staff friendly (19.0933), friendly (18.9954), friendly helpful (9.6515)\n",
      "\n",
      "Topic 22\n",
      "perfect (17.3152), location perfect (4.7817), perfect location (4.0720)\n",
      "\n",
      "Topic 23\n",
      "service (17.8211), room service (2.4720), customer (1.5855)\n",
      "\n",
      "Topic 24\n",
      "walking (9.8502), distance (8.8640), walking distance (8.5161)\n",
      "\n",
      "Topic 25\n",
      "station (18.8867), train (5.6734), train station (4.2745)\n",
      "\n",
      "Topic 26\n",
      "amazing (21.2982), staff amazing (2.4853), amazing staff (1.5237)\n",
      "\n",
      "Topic 27\n",
      "value (9.9641), money (8.5196), value money (7.9660)\n",
      "\n",
      "Topic 28\n",
      "bar (19.0866), restaurant (1.8270), mini (1.6608)\n",
      "\n",
      "Topic 29\n",
      "helpful staff (8.4993), helpful (8.2613), friendly helpful (6.1696)\n",
      "\n",
      "Topic 30\n",
      "london (15.6391), central (5.3605), central london (2.7487)\n",
      "\n",
      "Topic 31\n",
      "quiet (16.6188), quiet room (2.1666), street (1.7735)\n",
      "\n",
      "Topic 32\n",
      "comfy (17.0480), beds (6.6379), comfy bed (4.8696)\n",
      "\n",
      "Topic 33\n",
      "city (15.2926), centre (5.3813), center (4.2236)\n",
      "\n",
      "Topic 34\n",
      "free (15.6253), wifi (3.2844), coffee (3.1302)\n",
      "\n",
      "Topic 35\n",
      "great location (13.0462), great (12.6531), location (11.9509)\n",
      "\n",
      "Topic 36\n",
      "bathroom (18.1672), shower (7.7858), big (3.5284)\n",
      "\n",
      "Topic 37\n",
      "just (15.8710), like (1.9063), location just (1.7030)\n",
      "\n",
      "Topic 38\n",
      "view (17.8694), beautiful (2.6654), tower (2.2020)\n",
      "\n",
      "Topic 39\n",
      "reception (12.8223), reception staff (4.0082), staff reception (1.5896)\n",
      "\n",
      "Topic 40\n",
      "fantastic (17.2849), fantastic location (3.0756), location fantastic (2.0260)\n",
      "\n",
      "Topic 41\n",
      "metro (13.4794), near (6.7055), metro station (4.6076)\n",
      "\n",
      "Topic 42\n",
      "food (12.3028), restaurant (6.2308), good food (0.9821)\n",
      "\n",
      "Topic 43\n",
      "easy (14.4904), access (6.8057), easy access (4.9722)\n",
      "\n",
      "Topic 44\n",
      "modern (13.6712), clean modern (2.3007), modern clean (1.4637)\n",
      "\n",
      "Topic 45\n",
      "spacious (17.9529), room spacious (4.7539), spacious room (3.5416)\n",
      "\n",
      "Topic 46\n",
      "extremely (9.7056), staff extremely (4.7871), extremely helpful (3.6283)\n",
      "\n",
      "Topic 47\n",
      "area (16.0047), restaurants (2.4326), pool (1.6028)\n",
      "\n",
      "Topic 48\n",
      "facilities (13.1124), coffee (2.8582), tea (2.2367)\n",
      "\n",
      "Topic 49\n",
      "good location (11.7308), good (11.1340), location (10.6874)\n"
     ]
    }
   ],
   "source": [
    "display_topics2(nmf_cv, count_vectorizer.get_feature_names(),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize vectorizers\n",
    "count_vectorizer2 = CountVectorizer(ngram_range=(1, 2),  \n",
    "                                   stop_words='english', \n",
    "                                   token_pattern=\"\\\\b[a-z][a-z]+\\\\b\",\n",
    "                                   lowercase=True,\n",
    "                                   max_df = 0.6, max_features=4000)\n",
    "tfidf_vectorizer2 = TfidfVectorizer(ngram_range=(1, 2),  \n",
    "                                   stop_words='english', \n",
    "                                   token_pattern=\"\\\\b[a-z][a-z]+\\\\b\",\n",
    "                                   lowercase=True,\n",
    "                                   max_df = 0.6, max_features=4000)\n",
    "\n",
    "# transfomred my text data using vectorizers\n",
    "cv_data = count_vectorizer2.fit_transform(df.ReviewTextLower)\n",
    "tfidf_data = tfidf_vectorizer2.fit_transform(df.ReviewTextLower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialized reducers with dimensions\n",
    "n_comp = 5\n",
    "lsa_tfidf = TruncatedSVD(n_components=n_comp)\n",
    "lsa_cv = TruncatedSVD(n_components=n_comp)\n",
    "nmf_tfidf = NMF(n_components=n_comp)\n",
    "nmf_cv = NMF(n_components=n_comp)\n",
    "\n",
    "# transformed my vectorizers data using reducers\n",
    "lsa_tfidf_data = lsa_tfidf.fit_transform(tfidf_data)\n",
    "lsa_cv_data = lsa_cv.fit_transform(cv_data)\n",
    "nmf_tfidf_data = nmf_tfidf.fit_transform(tfidf_data)\n",
    "nmf_cv_data = nmf_cv.fit_transform(cv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize standardscaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "SS = StandardScaler()\n",
    "\n",
    "# transform my reducer data using standardscaler\n",
    "lsa_tfidf_data_sclaed = SS.fit_transform(lsa_tfidf_data)\n",
    "lsa_cv_data_sclaed = SS.fit_transform(lsa_cv_data)\n",
    "nmf_tfidf_data_scaled = SS.fit_transform(nmf_tfidf_data)\n",
    "nmf_cv_data_scaled = SS.fit_transform(nmf_cv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 0\n",
      "perfect stay (1.0000), little bit (0.0006), helpful staff excellent (0.0003), spacious breakfast (0.0002), good reception (0.0002), feel comfortable (0.0001), handy location (0.0001), station tram (0.0001)\n",
      "\n",
      "Topic 1\n",
      "little bit (0.9169), spacious breakfast (0.1482), great customer (0.1384), good reception (0.1380), great location excellent (0.0994), gluten free (0.0897), good thing (0.0814), extremely nice (0.0741)\n",
      "\n",
      "Topic 2\n",
      "spacious breakfast (0.4411), gluten free (0.3037), handy location (0.2395), good reception (0.2215), room best (0.2069), great customer (0.1918), breakfast helpful staff (0.1894), helpful staff excellent (0.1693)\n",
      "\n",
      "Topic 3\n",
      "good reception (0.6384), good thing (0.2696), breakfast helpful staff (0.2567), location business (0.1499), room best (0.1361), breakfast really good (0.1114), good selection (0.1107), beds excellent (0.0986)\n",
      "\n",
      "Topic 4\n",
      "great customer (0.6215), great location excellent (0.3792), room best (0.1615), location center (0.1388), beds excellent (0.1278), helpful staff excellent (0.1112), comfortable bed staff (0.1108), clean room comfortable (0.0782)\n"
     ]
    }
   ],
   "source": [
    "display_topics2(lsa_tfidf, tfidf_vectorizer.get_feature_names(),8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic0:\n",
      "['metro easy', 'bathroom really', 'clean room comfortable', 'breakfast helpful staff', 'extremely nice', 'great customer', 'gluten free', 'room best', 'station tram', 'handy location', 'feel comfortable', 'good reception', 'spacious breakfast', 'helpful staff excellent', 'little bit']\n",
      "Topic1:\n",
      "['location business', 'metro easy', 'good clean', 'clean room comfortable', 'breakfast helpful staff', 'helpful staff excellent', 'handy location', 'room best', 'extremely nice', 'good thing', 'gluten free', 'great location excellent', 'good reception', 'great customer', 'spacious breakfast']\n",
      "Topic2:\n",
      "['beds excellent', 'good breakfast friendly', 'extremely nice', 'comfortable bed staff', 'staff awesome', 'metro easy', 'clean room comfortable', 'good clean', 'helpful staff excellent', 'breakfast helpful staff', 'great customer', 'room best', 'good reception', 'handy location', 'gluten free']\n",
      "Topic3:\n",
      "['hot chocolate', 'comfortable large', 'staff beautiful', 'room decent size', 'helpful staff excellent', 'clean room comfortable', 'comfortable bed staff', 'metro easy', 'beds excellent', 'good selection', 'breakfast really good', 'room best', 'location business', 'breakfast helpful staff', 'good thing']\n",
      "Topic4:\n",
      "['breakfast helpful staff', 'great facilities', 'hot cold', 'location loved', 'great location wonderful', 'comfortable large', 'staff bed', 'metro easy', 'clean room comfortable', 'comfortable bed staff', 'helpful staff excellent', 'beds excellent', 'location center', 'room best', 'great location excellent']\n",
      "Topic5:\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 0 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-ffb701d21066>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mword_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Topic%d:\"\u001b[0m\u001b[1;33m%\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlsa_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mword_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 5 is out of bounds for axis 0 with size 5"
     ]
    }
   ],
   "source": [
    "#lsa = TruncatedSVD(n_components=50)\n",
    "#lsa_tfidf_data = lsa.fit_transform(tfidf_data)\n",
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "for cv in range(0,10):\n",
    "    word_list=[]\n",
    "    print(\"Topic%d:\"% cv)\n",
    "    for j in lsa_tfidf.components_.argsort()[cv, -16:-1]:\n",
    "        word_list.append(terms[j])\n",
    "    print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SSEs = []\n",
    "Sil_coefs = []\n",
    "for k in range(2,10):\n",
    "    km = KMeans(n_clusters=k, random_state=42)\n",
    "    km.fit(lsa_tfidf_data_sclaed)\n",
    "    labels = km.labels_\n",
    "    Sil_coefs.append(silhouette_score(lsa_tfidf_data_sclaed, labels, metric='euclidean'))\n",
    "    SSEs.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15,5), sharex=True, dpi=200)\n",
    "k_clusters = range(2,10)\n",
    "ax1.plot(k_clusters, Sil_coefs)\n",
    "ax1.set_xlabel('number of clusters')\n",
    "ax1.set_ylabel('silhouette coefficient')\n",
    "\n",
    "# plot here on ax2\n",
    "ax2.plot(k_clusters, SSEs)\n",
    "ax2.set_xlabel('number of clusters')\n",
    "ax2.set_ylabel('SSE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = [0,0]\n",
    "\n",
    "for n_clusters in range(2, 25):\n",
    "    km = KMeans(n_clusters = n_clusters)\n",
    "    km.fit(lsa_tfidf_data_sclaed)\n",
    "    msg = f\"\"\"# clusters: {n_clusters:2d}   Inertia: {km.inertia_:8.6f}\"\"\"\n",
    "    inertia.append(km.inertia_)\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(inertia)\n",
    "plt.xlabel('# of clusters')\n",
    "plt.xlim((2,25))\n",
    "plt.ylabel('inertia scores')\n",
    "#plt.ylim((650,1200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "kmeans = KMeans(n_clusters=k, random_state=1)\n",
    "kmeans.fit(lsa_tfidf_data_sclaed)\n",
    "centers = kmeans.cluster_centers_.argsort()[:,::-1]\n",
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "for i in range(0,k):\n",
    "    word_list=[]\n",
    "    print(\"cluster%d:\"% i)\n",
    "    for j in centers[i,:15]:\n",
    "        word_list.append(terms[j])\n",
    "    print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, verbose=1, perplexity=92, n_iter=300)\n",
    "X_ne = tsne.fit_transform(lsa_tfidf_data_sclaed[2000:])\n",
    "\n",
    "figsize=(20,15)\n",
    "plt.figure(dpi=300)\n",
    "sns.scatterplot(X_ne[:, 0], X_ne[:, 1], hue=kmeans.labels_[2000:], alpha=0.5, size = 0.5, palette='rainbow', legend='full');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,k):\n",
    "    word_list=[]\n",
    "    print(\"cluster%d:\"% i)\n",
    "    for j in centers[i,:15]:\n",
    "        word_list.append(terms[j])\n",
    "    print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_max = [index for index, value in enumerate(kmeans.labels_) if value==0]\n",
    "for rev_index in indices_max[:5]:\n",
    "    print(rev_index, str(df.ReviewText[rev_index]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_max = [index for index, value in enumerate(kmeans.labels_) if value==1]\n",
    "for rev_index in indices_max[:5]:\n",
    "    print(rev_index, str(df.ReviewText[rev_index]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_max = [index for index, value in enumerate(kmeans.labels_) if value==2]\n",
    "for rev_index in indices_max[:5]:\n",
    "    print(rev_index, str(df.ReviewText[rev_index]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSEs = []\n",
    "Sil_coefs = []\n",
    "for k in range(2,10):\n",
    "    km = KMeans(n_clusters=k, random_state=42)\n",
    "    km.fit(nmf_tfidf_data_scaled)\n",
    "    labels = km.labels_\n",
    "    Sil_coefs.append(silhouette_score(nmf_tfidf_data_scaled, labels, metric='euclidean'))\n",
    "    SSEs.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15,5), sharex=True, dpi=200)\n",
    "k_clusters = range(2,10)\n",
    "ax1.plot(k_clusters, Sil_coefs)\n",
    "ax1.set_xlabel('number of clusters')\n",
    "ax1.set_ylabel('silhouette coefficient')\n",
    "\n",
    "# plot here on ax2\n",
    "ax2.plot(k_clusters, SSEs)\n",
    "ax2.set_xlabel('number of clusters')\n",
    "ax2.set_ylabel('SSE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = [0,0]\n",
    "\n",
    "for n_clusters in range(2, 25):\n",
    "    km = KMeans(n_clusters = n_clusters)\n",
    "    km.fit(nmf_tfidf_data_scaled)\n",
    "    msg = f\"\"\"# clusters: {n_clusters:2d}   Inertia: {km.inertia_:8.6f}\"\"\"\n",
    "    inertia.append(km.inertia_)\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(inertia)\n",
    "plt.xlabel('# of clusters')\n",
    "plt.xlim((2,25))\n",
    "plt.ylabel('inertia scores')\n",
    "#plt.ylim((650,1200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kmeans = KMeans(n_clusters=k, random_state=1)\n",
    "kmeans.fit(nmf_tfidf_data_scaled)\n",
    "centers = kmeans.cluster_centers_.argsort()[:,::-1]\n",
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "for i in range(0,k):\n",
    "    word_list=[]\n",
    "    print(\"cluster%d:\"% i)\n",
    "    for j in centers[i,:15]:\n",
    "        word_list.append(terms[j])\n",
    "    print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, verbose=1, perplexity=92, n_iter=300)\n",
    "X_ne = tsne.fit_transform(nmf_tfidf_data_scaled[2000:])\n",
    "\n",
    "figsize=(20,15)\n",
    "plt.figure(dpi=300)\n",
    "sns.scatterplot(X_ne[:, 0], X_ne[:, 1], hue=kmeans.labels_[2000:], alpha=0.5, size = 0.5, palette='rainbow', legend='full');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running cluster\n",
    "k = 6\n",
    "kmeans = KMeans(n_clusters=k, random_state=1)\n",
    "kmeans.fit(nmf_tfidf_data_scaled)\n",
    "centers = kmeans.cluster_centers_.argsort()[:,::-1]\n",
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "for i in range(0,k):\n",
    "    word_list=[]\n",
    "    print(\"cluster%d:\"% i)\n",
    "    for j in centers[i,:15]:\n",
    "        word_list.append(terms[j])\n",
    "    print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, verbose=1, perplexity=92, n_iter=300)\n",
    "X_ne = tsne.fit_transform(nmf_tfidf_data_scaled[2000:])\n",
    "\n",
    "figsize=(20,15)\n",
    "plt.figure(dpi=300)\n",
    "sns.scatterplot(X_ne[:, 0], X_ne[:, 1], hue=kmeans.labels_[2000:], alpha=0.5, size = 0.5, palette='rainbow', legend='full');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_max = [index for index, value in enumerate(kmeans.labels_) if value==3]\n",
    "for rev_index in indices_max[:5]:\n",
    "    print(rev_index, str(df.ReviewText[rev_index]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize vectorizers\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1, 3),  \n",
    "                                   stop_words='english', \n",
    "                                   token_pattern=\"\\\\b[a-z][a-z]+\\\\b\",\n",
    "                                   lowercase=True,\n",
    "                                   max_df = 0.6, max_features=4000)\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 3),  \n",
    "                                   stop_words='english', \n",
    "                                   token_pattern=\"\\\\b[a-z][a-z]+\\\\b\",\n",
    "                                   lowercase=True,\n",
    "                                   max_df = 0.6, max_features=4000)\n",
    "\n",
    "# transfomred my text data using vectorizers\n",
    "cv_data = count_vectorizer.fit_transform(df.ReviewTextLower)\n",
    "tfidf_data = tfidf_vectorizer.fit_transform(df.ReviewTextLower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialized reducers with dimensions\n",
    "n_comp = 5\n",
    "lsa_tfidf = TruncatedSVD(n_components=n_comp)\n",
    "lsa_cv = TruncatedSVD(n_components=n_comp)\n",
    "nmf_tfidf = NMF(n_components=n_comp)\n",
    "nmf_cv = NMF(n_components=n_comp)\n",
    "\n",
    "# transformed my vectorizers data using reducers\n",
    "lsa_tfidf_data = lsa_tfidf.fit_transform(tfidf_data)\n",
    "lsa_cv_data = lsa_cv.fit_transform(cv_data)\n",
    "nmf_tfidf_data = nmf_tfidf.fit_transform(tfidf_data)\n",
    "nmf_cv_data = nmf_cv.fit_transform(cv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize standardscaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "SS = StandardScaler()\n",
    "\n",
    "# transform my reducer data using standardscaler\n",
    "lsa_tfidf_data_sclaed = SS.fit_transform(lsa_tfidf_data)\n",
    "lsa_cv_data_sclaed = SS.fit_transform(lsa_cv_data)\n",
    "nmf_tfidf_data_scaled = SS.fit_transform(nmf_tfidf_data)\n",
    "nmf_cv_data_scaled = SS.fit_transform(nmf_cv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSEs = []\n",
    "Sil_coefs = []\n",
    "for k in range(2,10):\n",
    "    km = KMeans(n_clusters=k, random_state=42)\n",
    "    km.fit(nmf_tfidf_data_scaled)\n",
    "    labels = km.labels_\n",
    "    Sil_coefs.append(silhouette_score(nmf_tfidf_data_scaled, labels, metric='euclidean'))\n",
    "    SSEs.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15,5), sharex=True, dpi=200)\n",
    "k_clusters = range(2,10)\n",
    "ax1.plot(k_clusters, Sil_coefs)\n",
    "ax1.set_xlabel('number of clusters')\n",
    "ax1.set_ylabel('silhouette coefficient')\n",
    "\n",
    "# plot here on ax2\n",
    "ax2.plot(k_clusters, SSEs)\n",
    "ax2.set_xlabel('number of clusters')\n",
    "ax2.set_ylabel('SSE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = [0,0]\n",
    "\n",
    "for n_clusters in range(2, 25):\n",
    "    km = KMeans(n_clusters = n_clusters)\n",
    "    km.fit(nmf_tfidf_data_scaled)\n",
    "    msg = f\"\"\"# clusters: {n_clusters:2d}   Inertia: {km.inertia_:8.6f}\"\"\"\n",
    "    inertia.append(km.inertia_)\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(inertia)\n",
    "plt.xlabel('# of clusters')\n",
    "plt.xlim((2,25))\n",
    "plt.ylabel('inertia scores')\n",
    "#plt.ylim((650,1200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "kmeans.fit(nmf_tfidf_data_scaled)\n",
    "centers = kmeans.cluster_centers_.argsort()[:,::-1]\n",
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "for i in range(0,k):\n",
    "    word_list=[]\n",
    "    print(\"cluster%d:\"% i)\n",
    "    for j in centers[i,:15]:\n",
    "        word_list.append(terms[j])\n",
    "    print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, verbose=1, perplexity=92, n_iter=300, random_state=42)\n",
    "X_ne = tsne.fit_transform(nmf_tfidf_data_scaled[2000:])\n",
    "\n",
    "figsize=(20,15)\n",
    "plt.figure(dpi=300)\n",
    "sns.scatterplot(X_ne[:, 0], X_ne[:, 1], hue=kmeans.labels_[2000:], alpha=0.5, size = 0.5, palette='rainbow', legend='full');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_max = [index for index, value in enumerate(kmeans.labels_) if value==0]\n",
    "for rev_index in indices_max[:5]:\n",
    "    print(rev_index, str(df.ReviewText[rev_index]))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_max = [index for index, value in enumerate(kmeans.labels_) if value==0]\n",
    "for rev_index in indices_max[:5]:\n",
    "    print(rev_index, str(df.ReviewText[rev_index]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
